<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CJ&#39;s Blog</title>
    <link>https://cjting.me/</link>
    <description>Recent content on CJ&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 29 Jul 2019 14:52:50 +0800</lastBuildDate>
    
        <atom:link href="https://cjting.me/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        <item>
          <title>从图片优化说起</title>
          <link>https://cjting.me/2019/07/29/image-optimization/</link>
          <pubDate>Mon, 29 Jul 2019 14:52:50 +0800</pubDate>
          

          <guid>https://cjting.me/2019/07/29/image-optimization/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/Fk_kBecsmewI-l6GwB9HsQBNQqsW.jpeg" class="webfeedsFeaturedVisual">

            <p>图片是大部分网页的重要组成部分，一般情况下，我们不会太关注这方面的问题，需要显示图片直接一个 <code>img</code> 标签搞定。</p>

<p>但实际上，无论是对于提高加载速度，还是对于优化用户体验，优化图片都是一个重要的手段。</p>

<p>图片优化分成两个方面：</p>

<p>第一，图片压缩。在保证视觉效果的情况下，减少图片的体积。这个很有效，1M 和 100K 的图片，肉眼看起来几乎差不多，但却省了 90% 的流量，大大提高了加载速度。</p>

<p>第二，响应式图片。根据客户端的情况，选择最合适的图片返回给用户。用户是一个 500px 的设备，那么返回 1000px 的图给他就是浪费（假设物理像素和 CSS 像素是一比一）。</p>

<p>我们先来看图片压缩。</p>

<h2 id="图片压缩">图片压缩</h2>

<p>压缩的第一步是筛选出需要压缩的图片。如果图片本身就已经足够小了，那么再压缩的意义就不大。</p>

<p>我一般使用如下的脚本筛选项目中需要压缩的图片。脚本会列出所有的图片并根据尺寸降序排列。</p>

<pre><code class="language-bash"># fd 是现代化的 find
# bat 是现代化的 cat
fd -e png -e jpeg -e jpg -e svg |\
xargs ls -l |\
sort -nk5 -r |\
awk '{print $9,$5}' |\
numfmt --field=2 --to=iec |\
column -t | bat
</code></pre>

<p><img src="http://asset.cjting.cn/9b85365dgy1g5i03r4vdnj20h7051wfj.jpg" alt="" /></p>

<p>筛选出需要压缩的图片以后，接下来就是压缩、比对、调整参数。图片压缩的工具实在是太多了，Google <em>image compression tool</em> 选择会多得你眼花缭乱。</p>

<p>这里顺口提一下 Google 出品的 <a href="https://squoosh.app/">squoosh</a> 在线图片压缩服务，看起来不错，虽然我没怎么用过。</p>

<p>这里我选择使用 <a href="https://github.com/imagemin/imagemin">imagemin</a>，相比于一些在线工具或者 App，自己写脚本更灵活一些。</p>

<p>程序很简单，分别针对 JPG、PNG、SVG 加载相应的插件就好。</p>

<pre><code class="language-js">const imagemin = require(&quot;imagemin&quot;)
const imageminMozjpeg = require(&quot;imagemin-mozjpeg&quot;)
const imageminPngquant = require(&quot;imagemin-pngquant&quot;)
const imageminSvgo = require(&quot;imagemin-svgo&quot;)

;(async () =&gt; {
  const files = await imagemin(process.argv.slice(2), {
    destination: &quot;dist&quot;,
    plugins: [
      imageminMozjpeg({
        quality: 70,
      }),
      imageminPngquant({
        quality: [0.65, 0.8],
      }),
      imageminSvgo({
        plugins: [
          {removeViewBox: false},
        ],
      }),
    ],
  })
})()
</code></pre>

<p>注意，<code>quality</code> 参数需要自己测试去确定，怎样在质量和尺寸中权衡，每个团队有自己的标准。</p>

<h3 id="progressive-jpeg-vs-baseline-jpeg">Progressive JPEG VS Baseline JPEG</h3>

<p>JPEG 根据显示方式的不同，分为两种。Progressive JPEG 会先加载模糊的整张图片，然后变的越来越清晰。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1g5hw2y2pipj21900u0kjq.jpg" alt="" /></p>

<p><img src="http://asset.cjting.cn/9b85365dgy1g5hw3pr599j20lc07ngu4.jpg" alt="" /></p>

<p>而 Baseline JPEG 会先清晰地加载图片的一部分，然后慢慢显示剩余的部分。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1g5hw2y2pipj21900u0kjq.jpg" alt="" /></p>

<p><img src="http://asset.cjting.cn/9b85365dgy1g5hw39pw5bj20lc07n7b9.jpg" alt="" /></p>

<p>从视觉效果来说，Progressive JPEG 自然更好一些。但它也有一些缺点，比如它的解码速度比 Baseline JPEG 要慢，占用的 CPU 时间更多。</p>

<p>如果是桌面浏览器，这点性能问题自然无所谓，但是如果是移动端，就不得不考虑。工程本来就是权衡的艺术。</p>

<p>默认情况下，MozJPEG 生成的是 Progressive JPEG，可以通过 <a href="https://github.com/imagemin/imagemin-mozjpeg#progressive">选项</a> 调整。</p>

<h3 id="webp">WebP</h3>

<p>WebP 是谷歌新提出的一个图片格式，拥有质量好尺寸小的特点。在客户端支持的情况下，我们应该尽可能地使用 WebP 格式。</p>

<p>有很多工具可以将 JPG/PNG 转换成 WebP，这里还是使用 imagemin 为例。</p>

<pre><code class="language-js">const imageminWebp = require('imagemin-webp')

const webps = await imagemin(images, {
  destination: &quot;dist&quot;,
  plugins: [
    imageminWebp({
      quality: 80,
    }),
  ],
})
</code></pre>

<h3 id="oimg">oimg</h3>

<p><a href="https://github.com/cj1128/oimg">oimg</a> 是我在 imagemin 的基础上封装的一个命令行小工具，毕竟压缩图片是经常要做的事情，不能每次都等到需要的时候再去写脚本。</p>

<p>oimg 使的流程是这样的：</p>

<ul>
<li>首先，我们找到尺寸比较大的需要压缩的图片</li>
<li>然后，使用 oimg 压缩</li>
<li>最后，肉眼对比一下原图片和压缩图片，如果没有问题，替换就好</li>
<li>如果效果不满意，调整参数，再压缩</li>
</ul>

<p>这个过程没法完全自动化，因为压缩过后的图片究竟在视觉上能不能替换原图，这个过程需要人来判别，全部交给机器是不太放心的。毕竟只有在保证质量的情况下减小体积才有意义。</p>

<p>oimg 的输出如下，可以很方便地看出压缩的效果如何。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1g5i0rjw4qpj20n402qaak.jpg" alt="" /></p>

<h2 id="响应式图片">响应式图片</h2>

<p>图片压缩的问题解决完了，现在我们来看看响应式图片。</p>

<p>所谓响应式图片，关键就一点：<strong>根据客户端的情况返回最适合客户端的图片</strong>。</p>

<p>那么，可能会存在哪些情况？在准备部署响应式图片的时候，我们可以问自己如下四个问题。</p>

<ul>
<li>是否希望根据客户端情况返回不同的图片 <strong>内容</strong>?</li>
<li>是否希望根据客户端情况返回不同的图片 <strong>格式</strong>？</li>
<li>是否希望根据客户端情况返回不同的图片 <strong>尺寸</strong> ？</li>
<li>是否希望优化高 <strong>分辨率</strong> 设备的体验？</li>
</ul>

<p>在 <code>picture</code> 标签出来之前，这些只能通过 JS 来实现，不仅代码而且丑陋能力也不全。但是现在，针对这些问题，我们有了一个完整的优雅的解决方案。</p>

<h3 id="picture-标签">picture 标签</h3>

<p><code>picture</code> 是 HTML5 新引入的标签，基本用法如下。</p>

<pre><code class="language-html">&lt;picture&gt;
  &lt;source srcset=&quot;a.jpg&quot;&gt;
  &lt;source srcset=&quot;b.jpg&quot;&gt;
  &lt;img src=&quot;c.jpg&quot; &gt;
&lt;/picture&gt;
</code></pre>

<p>我们可以这样理解，<code>picture</code> 标签会从 <code>source</code> 中选择最合适的一个，然后将它的 URL 赋值给 <code>img</code>。对于不认识 <code>picture</code> 的旧浏览器，他们会忽略 <code>picture</code>，只渲染 <code>img</code>，一切都不会有问题。</p>

<p>注意：<strong><code>picture</code> 标签最后一定要包含一个 <code>img</code> 标签，否则，什么都不会显示。</strong></p>

<p>现在我们逐一来看 <code>picture</code> 怎样解决上面的四个问题。</p>

<h3 id="动态内容">动态内容</h3>

<p>根据客户端的情况，我们来返回完全不同的两张图。这个很简单，使用 <code>source</code> 标签的 <code>media</code> 属性即可。</p>

<p>如下代码会在小于 1024px 的时候显示 <code>img-center.jpg</code>，而在大于等于 1024px 的时候显示 <code>img-full.jpg</code>。</p>

<pre><code class="language-html">&lt;picture&gt;
  &lt;source
    media=&quot;(min-width: 1024px)&quot;
    srcset=&quot;img-full.jpg&quot;
  &gt;

  &lt;img
    src=&quot;img-center.jpg&quot; 
  &gt;
&lt;/picture&gt;
</code></pre>

<h3 id="动态格式">动态格式</h3>

<p>这个问题也很简单，使用 <code>source</code> 标签的 <code>type</code> 属性即可。</p>

<p>如下代码会在支持 WebP 的浏览器上使用 <code>img.webp</code>，在不支持 WebP 的浏览器上使用 <code>img.jpg</code>。</p>

<pre><code class="language-html">&lt;picture&gt;
  &lt;source
    srcset=&quot;img.webp&quot;
    type=&quot;image/webp&quot;
  &gt;

  &lt;img
    src=&quot;img.jpg&quot; 
  &gt;
&lt;/picture&gt;
</code></pre>

<h3 id="动态尺寸">动态尺寸</h3>

<p>如果希望浏览器能根据情况去请求不同尺寸的图片，我们需要提供两个信息：</p>

<ul>
<li>有哪些尺寸的图片</li>
<li>图片显示的时候是什么尺寸</li>
</ul>

<p>下面的代码中，我们首先使用 <code>srcset</code> 属性指定有哪些图片，分别是图片名和图片的尺寸，这里注意单位不用 <code>px</code> 而是 <code>w</code>，用于表示图片的固有宽度。</p>

<p><code>sizes</code> 属性告诉浏览器，这个图片在不同的条件下会是什么样的宽度。这个属性用于给到浏览器提示，并不会真正的指定 <code>img</code> 的宽度，我们还是需要另外使用 CSS 来指定。</p>

<p>这样，给定一个视口宽度，浏览器可以得知图片需要的宽度，然后根据 DPI 情况，在所有可选图片中选择最合适的一个。</p>

<pre><code class="language-html">&lt;img
  src=&quot;img-400.jpg&quot;
  sizes=&quot;(min-width: 640px) 60vw, 100vw&quot;
  srcset=&quot;img-200.jpg 200w,
      img-400.jpg 400w,
      img-800.jpg 800w,
      img-1200.jpg 1200w&quot;
&gt;
</code></pre>

<h3 id="动态分辨率">动态分辨率</h3>

<p>动态分辨率其实是动态尺寸的一种简化情况。</p>

<p>根据显示器的 DPI 返回同一张图片的不同分辨率版本可以直接利用 <code>img</code> 标签的 <code>srcset</code> 属性。</p>

<p>使用了如下的代码，浏览器会自动根据显示器的 DPI 来决定下载图片的哪个版本。</p>

<p>在低 DPI 设备上，例如桌面显示器，浏览器会使用 img-200.jpg，而在高 DPI 设备上，例如手机，浏览器会使用 img-400.jpg。</p>

<pre><code class="language-html">&lt;img
  srcset=&quot;img-200.jpg, 
          img-300.jpg 1.5x,
          img-400.jpg 2x&quot;
  src=&quot;img-400.jpg&quot; 
&gt;

&lt;style type=&quot;text/css&quot;&gt;
  img {
    width: 200px;
  }
&lt;/style&gt;
</code></pre>

<p>当然，我们也可以组合这几个选项。</p>

<p>如下的代码会</p>

<ul>
<li>视口 &gt;= 1280px 时

<ul>
<li>根据视口的具体宽度，返回不同尺寸的 <em>img-full</em> 图片</li>
<li>如果客户端支持 WebP，返回 WebP 格式</li>
</ul></li>
<li>视口 &lt; 1280px 时

<ul>
<li>根据视口的具体宽度，返回不同尺寸的 <em>img</em> 图片</li>
<li>如果客户端支持 WebP，返回 WebP 格式</li>
</ul></li>
</ul>

<pre><code class="language-html">&lt;picture&gt;
  &lt;source
    media=&quot;(min-width: 1280px)&quot;
    sizes=&quot;50vw&quot;
    srcset=&quot;img-full-200.webp 200w,
        img-full-400.webp 400w,
        img-full-800.webp 800w,
        img-full-1200.webp 1200w,
        img-full-1600.webp 1600w,
        img-full-2000.webp 2000w&quot;
    type=&quot;image/webp&quot;
  &gt;
  &lt;source
    media=&quot;(min-width: 1280px)&quot;
    sizes=&quot;50vw&quot;
    srcset=&quot;img-full-200.jpg 200w,
        img-full-400.jpg 400w,
        img-full-800.jpg 800w,
        img-full-1200.jpg 1200w,
        img-full-1600.jpg 1800w,
        img-full-2000.jpg 2000w&quot;
  &gt;

  &lt;source
    sizes=&quot;(min-width: 640px) 60vw, 100vw&quot;
    srcset=&quot;img-200.webp 200w,
        img-400.webp 400w,
        img-800.webp 800w,
        img-1200.webp 1200w,
        img-1600.webp 1600w,
        img-2000.webp 2000w&quot;
    type=&quot;image/webp&quot;
  &gt;
  &lt;img
    src=&quot;img-400.jpg&quot;
    sizes=&quot;(min-width: 640px) 60vw, 100vw&quot;
    srcset=&quot;img-200.jpg 200w,
        img-400.jpg 400w,
        img-800.jpg 800w,
        img-1200.jpg 1200w,
        img-1600.jpg 1600w,
        img-2000.jpg 2000w&quot;
  &gt;
&lt;/picture&gt;
</code></pre>

<p>这里强烈建议自己动手，结合 <a href="https://placeholder.com/">placeholder.com</a> 网站，生成一些图片来测试，毕竟，纸上得来终觉浅。</p>

<h2 id="参考">参考</h2>

<ul>
<li><a href="https://dev.opera.com/articles/responsive-images">Responsive Images: Use Cases and Documented Code Snippets to Get You Started</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images">MDN: Responsive images</a></li>
<li><a href="https://images.guide">images.guide</a></li>
</ul>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>正向代理与反向代理</title>
          <link>https://cjting.me/2018/08/11/forward-proxy-and-reverse-proxy/</link>
          <pubDate>Sat, 11 Aug 2018 18:08:00 +0800</pubDate>
          

          <guid>https://cjting.me/2018/08/11/forward-proxy-and-reverse-proxy/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/Fly_Jp2zD-BbHRl-97_m7PqwbTvX.jpeg" class="webfeedsFeaturedVisual">

            <p>代理的英文叫做 *Proxy*，是计算机中的常用软件。</p>

<p>简单来说，代理的功能犹如它的名字所示：代替某人来处理某事。</p>

<p>常见的代理分两种，正向代理和反向代理。不管哪种代理，它们都位于客户端和服务器之间，将我们传统的 <code>客户端 &lt;-&gt; 服务器</code> 通信变成了 <code>客户端 &lt;-&gt; 代理 &lt;-&gt; 服务器</code> 通信。</p>

<h2 id="正向代理">正向代理</h2>

<p>正向代理用于代理客户端，此时在服务器看来，代理就是客户端，服务器不知道真正客户端的存在。</p>

<p>一般情况下，代理和客户端位于一个内网中，<code>(客户端 &lt;-&gt; 代理) &lt;-&gt; 服务器</code>。客户端不需要直接将请求发给服务器，而是发给代理，由代理代为请求服务器并返回结果。</p>

<p>看起来似乎是多了一道手续，没什么好处，但是实际上，正向代理有很多用处：</p>

<ul>
<li><p>突破限制。</p>

<p>比如有五台服务器，位于一个内网中，但是只有一台可以访问公网。那么此时通过配置这台服务器作为正向代理，其他四台服务器便也都可以访问公网，这个场景在云服务器中很常见。</p>

<p>再比如我们的科学上网软件，实际上也是一个正向代理。由于我们的计算机无法直接访问敏感网站，但是代理服务器可以，而我们的计算机访问代理服务器又是没问题的。因此，通过使用代理服务器，我们便可以间接访问到我们感兴趣的网站。</p></li>

<li><p>流量控制与流量统计。</p>

<p>由于所有的流量都经过代理，通过配置代理，我们可以对流量进行任意控制。比如，不允许访问淘宝等，很多公司会对员工的网络访问进行限制，便是通过正向代理实现。</p>

<p>除了控制之外，使用正向代理也可以对流量进行统计。通过解析代理的访问日志，使用一些类似 <a href="https://github.com/eldy/awstats">awstats</a> 的工具，便可以得到流量的详细统计信息。</p></li>

<li><p>提升性能。</p>

<p>正向代理可以缓存经常被访问的网站，从而大幅提升访问速度。</p></li>
</ul>

<h2 id="反向代理">反向代理</h2>

<p>反向代理用于代理服务器，此时在客户端看来，代理就是服务器，客户端不知道真正服务器的存在。</p>

<p>一般情况下，代理和服务器位于一个内网中，<code>客户端 &lt;-&gt; (代理 &lt;-&gt; 服务器)</code>。服务器不需要直接和客户端沟通，而是通过代理，由代理接收客户端的请求，再发送给服务器。</p>

<p>反向代理有如下几个用处：</p>

<ul>
<li><p>突破限制。</p>

<p>比如内网中的某个服务器，如果想要在公网访问，我们可以配置内网中拥有公网IP的机器作为反向代理，从而实现对内网服务的访问。</p></li>

<li><p>负载均衡。</p>

<p>我们可以部署多台服务器，配置代理将请求转发给不同的服务器。这里有很多算法可以使用，比如最简单的轮流转发 (Round Robin)。这样，当负载增大的时候，客户端无需做任何修改，服务端通过简单的增加服务器便可以应对。</p>

<p>负载均衡的另一个好处是可以实现容灾容错。如果某台服务器宕机了，代理服务器会将请求转发到其他服务器上，客户端不会受到任何影响。</p></li>

<li><p>访问加速。</p>

<p>对于某些大型服务，他们的服务器遍布各地，通过使用反向代理，当请求到来时，代理可以将请求转发给最近的服务器，从而让用户在最短时间内获得响应，这一点其实和 CDN 的工作方式是一样的。</p></li>
</ul>

<h2 id="透明代理和显示代理">透明代理和显示代理</h2>

<p><em>透明代理</em> 这个概念只有正向代理才有，因为所有的反向代理在客户端看来都是透明的，客户端不知道请求对象是反向代理还是真正的服务器。</p>

<p>当使用正向代理的时候，有两种方式：</p>

<ol>
<li>客户端显示配置使用代理，此时客户端知道正向代理的存在，所以是显示代理</li>
<li>客户端没有进行任何配置，但所有流量还是经过了代理，因为客户端不知道代理的存在，所以是透明代理</li>
</ol>

<p>很多软件都提供设置代理选项，比如 Chrome，当我们在设置完代理以后，Chrome 就会使用代理进行通信，此时是显示代理。</p>

<p>设置代理的时候需要设置代理协议，常见的代理协议有 <code>http</code>，<code>https</code>，<code>socks4</code>，<code>socks5</code>。</p>

<h3 id="http-connect">HTTP CONNECT</h3>

<p>之前我一直有个误解，认为使用 HTTP 协议是无法代理 HTTPS 流量的，其实不然。</p>

<p>HTTP 有一个 <code>CONNECT</code> 方法，可以创建一条 HTTP 隧道，用来转发任意的 TCP 流量。</p>

<p>通过使用 CONNECT 方法，HTTP 协议可以代理任意的基于 TCP 的协议，当然也包括 HTTPS。</p>

<p>假设我们配置 Chrome 使用一个 HTTP 代理，当 Chrome 遇到 HTTP 请求时，直接转发给代理，不做任何处理。</p>

<p>当遇到 HTTPS 请求时，Chrome 会首先使用 CONNECT 方法请求代理，请求中含有目标地址的的域名和端口，代理收到以后，会创建一条到目标地址的 TCP 链接，创建成功以后，返回 <code>200 Connection established</code> 给 Chrome。之后，Chrome 会将 HTTPS 数据包发给代理，而代理会原封不动的发给目标地址，代理此时就像隧道一样，沟通目标地址和客户端。</p>

<h3 id="so-original-dst">SO_ORIGINAL_DST</h3>

<p>显示代理必须要手动配置，如果有很多客户端的话就很不方便。这个时候，我们可以使用透明代理技术。</p>

<p>通过在路由器层将数据包直接转发给代理软件，实现客户端无需配置，但是仍然使用代理来访问网络。</p>

<p>这个时候有一个问题，即代理如何知道数据包的原始目标地址？</p>

<p>假设我们访问百度，浏览器构建一个 HTTP 数据包，目标地址为百度 IP 和 80 端口，经过路由器的时候，路由器转发给到了代理，此时，数据包的目标地址被修改为代理 IP 和代理端口。</p>

<p>当代理收到数据包以后，如何知道数据包下一步该发送给谁呢？</p>

<p>这个问题目前我不知道确切的答案，网上有两种说法：</p>

<ol>
<li>因为 HTTP/1.1 要求所有的请求必须包含 <code>HOST</code> 头，代理可以通过解析 HOST 得到目标地址</li>
<li>通过使用 <code>SO_ORIGINAL_DST</code> 选项获取数据包原始地址</li>
</ol>

<p>暂时没有空去验证这个问题，这个问题的准确答案留待以后进一步明确。</p>

<h2 id="一个恶作剧代理">一个恶作剧代理</h2>

<p>最后，我们使用 <a href="http://www.squid-cache.org/">Squid</a> 来搭建一个恶作剧代理，这个代理会将所有的图片翻转过来。</p>

<p>Squid 是一个很常用的正向代理软件，可以用来做访问控制，网站缓存等等。这里我们使用 Squid 的 <em>URL Rewrite</em> 功能，对于所有的图片请求，将图片下载到本地，然后调用 <code>mogrify</code> 翻转图片，最后将翻转以后的图片返回给客户端。</p>

<p>这样做的效果就是，当你上网浏览时，所有的图片都是倒过来的😉，效果如下：</p>

<p><img src="http://asset.cjting.cn/FkC-GZsJPKErvn7WW3GVdhfhB9aE.jpg" alt="" /></p>

<p>想象这样一个场景：在一个阳光明媚的午后，你发现你的邻居在蹭你的网，你并没有选择修改密码，而是默默地启动这个恶作剧代理，配置你的路由器，使用 iptables 将蹭网流量转发到这个代理。于此同时，你的邻居发现，前一刻还十分精彩的互联网世界，突然颠倒了，他苦苦思索，他不知所措，他深深地被这个世界的恶意所伤害。</p>

<p>关于恶作剧代理的具体代码可以去 GitHub 仓库 <a href="https://github.com/cj1128/squid-trick-proxy-demo">squid-trick-proxy-demo</a> 上查看。</p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>JavaScript 与 Unicode</title>
          <link>https://cjting.me/2018/07/22/js-and-unicode/</link>
          <pubDate>Sun, 22 Jul 2018 09:45:12 +0800</pubDate>
          

          <guid>https://cjting.me/2018/07/22/js-and-unicode/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/FgUXmK5q8oVb8ZKJStDsqVtd_PXj.jpg" class="webfeedsFeaturedVisual">

            <p>字符串是任何一个编程语言中的重要概念，同时也是一个非常复杂的问题。</p>

<p>日常编码中可能并不一定能见到它的复杂性，下面是几个字符串操作，使用你最熟悉的编程语言，看看结果如何。</p>

<ul>
<li>逆转字符串 <code>&quot;noël&quot;</code>，正确结果应该是 <code>&quot;lëon&quot;</code></li>
<li>获取字符串 <code>&quot;noël&quot;</code> 前三个字符，正确结果应该是 <code>&quot;noë&quot;</code></li>
<li>获取字符串 <code>&quot;😸😾&quot;</code> 的长度，正确答案应该是 2</li>
<li>字符串 <code>&quot;noël&quot;</code> 和字符串 <code>&quot;noël&quot;</code> 规整化以后应该相等（他们看起来一样，但是内部表示不一样，一个 6 字节，一个 5 字节，这里涉及到 Unicode 的规整化）</li>
</ul>

<p>对于大部分编程语言，包括 Ruby，Python，JS，C#，Java 等，上面的问题都无法全部返回正确结果（但是，拥有超强 Unicode 支持的 <a href="https://elixir-lang.org/">Elixir</a> 可以）。</p>

<h2 id="基本概念">基本概念</h2>

<p>首先来看关于字符串的几个基本概念。</p>

<ul>
<li><code>字符集（Character Set）</code>：定义了有哪些字符，任何一段字符串，里面的字符都属于某个字符集，比如经典的 ASCII 字符集以及目前最为常用的 Unicode 字符集。</li>
<li><code>码点（Code Point）</code>：字符集中的每个字符，都有一个唯一的编号，叫做码点，比如 <code>A</code> 在 ASCII 字符集中的码点是 65。</li>
<li><code>字符编码（Character Encoding）</code>：将字符转换为字节的方式。对于某些字符集，比如 ASCII，字符编码很简单，直接存储码点即可，比如 <code>A</code>，计算机中存储就是 65 的二进制补码，<code>0b01000001</code>。但是对于 Unicode，字符编码就有很多种，后文我们再详细介绍。</li>
<li><code>编码单元（Code Unit）</code>：UTF16 中的一个概念，每两个字节称为一个编码单元，一个字符可能使用一个或两个编码单元进行编码</li>
</ul>

<h2 id="unicode">Unicode</h2>

<p>Unicode 是一项了不起的发明，这个字符集诞生的初衷很简单，我们需要有一个大的字符集囊括地球上的所有语言中的所有文字。</p>

<p>在 Unicode 诞生之前，每个语言有自己的字符集，比如英语的 ASCII，繁体中文的 Big Five，简体中文的 GB2312 等等。这就使得计算机处理多语言的文档变得十分麻烦，同时，跨语言交流也非常不便，A 语言的文档发给 B 语言的计算机，B 不知道该如何解码，说不定都没有安装 A 语言对应的字符集。</p>

<p>Unicode 项目诞生于 1987 年，1.0 版本于 1991 年发布，目前最新版是 11.0。</p>

<p>Unicode 字符集目前一共分为 17 个平面（Plane），编号为 0 - 16，每个平面由 16 位构成，也就是每个平面可以编码 2^16 = 65536 个字符。</p>

<p>其中，第一个平面叫做基本平面，*BMP, Basic Multilingual Plane*，里面编码了最为常用的一些字符。</p>

<p>剩下 16 个平面都叫做补充平面，*Supplementary Plane*。</p>

<p>Unicode 的码点从 0 开始，也就是说，目前，Unicode 的字符码点范围为 0x0000 - 0x10FFFF。当然，这中间很多码点没有定义。</p>

<h2 id="unicode-encoding">Unicode Encoding</h2>

<p>有了字符集，剩下的问题就是字符编码，即怎样将码点编码成字节。常见的方式有 UTF32，UTF16 以及 UTF8。我们来分别看看每个编码的方式和优缺点。</p>

<h3 id="utf32">UTF32</h3>

<p>因为目前 Unicode 只用了三个字节就可以完全表示，最为简单的做法是：使用三个字节直接编码码点。</p>

<p>这种思路对应的编码方式是 *UTF32*，使用四个字节直接编码码点。这里可能有的同学会问，为什么不使用三个字节？有两个原因：</p>

<ol>
<li>为了以后扩充性考虑，虽然目前三个字节够用，但是以后可能不够用</li>
<li>计算机处理四字节对齐数据会更快，使用三字节，虽然节省了内存，但是处理起来效率很低。这就和我们编程语言中一般有 <code>int8</code>，<code>int16</code>，<code>int32</code>，但是没有 <code>int24</code> 是一个道理。</li>
</ol>

<p>UTF32 的优点是编码和解码都非常简单。缺点也非常明显：<strong>对于英文文本（互联网上绝大部分信息是英文），体积要比 ASCII 大4倍</strong>。这是一个无法接受的缺点，因此 UTF32 基本上是不使用的，HTML5 规范就明确规定网页不得使用 UTF32 进行编码。</p>

<h3 id="utf16-ucs-2">UTF16 &amp;&amp; UCS-2</h3>

<p>UCS-2 (2-byte Universal Character Set)是一个已经废弃的定长编码，始终使用两个字节编码 BMP中 的字符。对于非 BMP 中的字符，UCS-2 无法编码。</p>

<p>UTF16 是 UCS-2 的一个扩展，是一个变长编码，结果可能为两个字节，也可能为四个字节。其中每两个字节叫做 *Code Unit*，编码单元。对于 BMP 中的字符，UTF16 的编码和 UCS-2 一样，使用一个编码单元直接编码字符的码点，对于非 BMP 中的字符，UTF16 使用一个叫做 <code>Surrogate Pair</code> 的技术来进行编码。</p>

<p>在 BMP 中，并不是所有的码点都定义了字符，存在一个空白区，<code>0xD800 - 0xDFFF</code>这个范围内的码点不定义任何字符。</p>

<p>除了 BMP，剩下的码点一共是 <code>0x10FFFF - 0xFFFF = 1048576 = 2^20</code> 个，也就是需要 20 位进行编码。</p>

<p>Surrogate Pair 使用两个编码单元来编码一个非 BMP 字符。第一个编码单元的范围为 <code>0xD800 - 0xDBFF</code>，换成二进制为<code>0b1101_10xx_xxxx_xxxx</code>，叫做 <code>Lead Surrogate</code>，正好可以编码 10 位。</p>

<p>第二个编码单元的范围为 <code>0xDC00 - 0xDFFF</code>，换成二进制为 <code>0b1101_11xx_xxxx_xxxx</code>，叫做 <code>Tail Surrogate</code>，正好也可以用来编码 10 位。</p>

<p>这样，通过使用两个编码单元，UTF16 就可以将非 BMP 字符的偏移码点值（减去 0x10000 以后的码点值），使用 Surrogate Pair 进行存储，从而编码非 BMP 字符。同时，由于编码单元的范围都在 BMP 未定义字符的区间中，解码也不会产生任何歧义。</p>

<p>以 emoji <code>😜</code> 为例，码点为 <code>0x1F61C</code>，减去 0x10000，结果为 <code>0xF61C</code>，换成二进制，填充为 20 位，结果是 <code>0000_1111_0110_0001_1100</code>。将这 20 位填充到 Surrogate Pair 中，得到的结果是，Lead Surrogate：<code>1101_1000_0011_1101</code>，Tail Surrogate：<code>1101_1110_0001_1100</code>，换成 16 进制便是 <code>0xD83D 0xDE1C</code>，这就是 <code>😜</code> 的 UTF16 编码。</p>

<h3 id="utf8">UTF8</h3>

<p>UTF8 是目前使用最多也是最为灵活的一种变长编码，同 UTF16 一样，UTF8 的编码结果是不定长的，在 1 到 4 个字节之间。</p>

<p>具体规则如下，左边为码点范围，右边为二进制编码形式。</p>

<ul>
<li><code>0x0000 – 0x007F</code>: <code>0xxx_xxxx</code>，使用一个字节，编码 7 位。</li>
<li><code>0x0080 – 0x07FF</code>: <code>110x_xxxx</code>, <code>10xx_xxxx</code>，使用两个字节，编码 11 位。</li>
<li><code>0x0800 – 0xFFFF</code>: <code>1110_xxxx</code>, <code>10xx_xxxx</code>, <code>10xx_xxxx</code>，使用三个字节编码 16 位。</li>
<li><code>0x10000 – 0x1FFFFF</code>: <code>1111_0xxx</code>, <code>10xx_xxxx</code>, <code>10xx_xxxx</code>, <code>10xx_xxxx</code>，使用四个字节，编码 21 位</li>
</ul>

<p>还是以 emoji <code>😜</code> 为例，码点为 <code>0x1F61C</code>，在区间 <code>0x10000 - 0x1FFFFF</code> 之中，需要使用四个字节进行编码。首先将其转换为二进制，填充为 21 位，结果是 <code>0_0001_1111_0110_0001_1100</code>，然后将这 21 位按照上述说明填入，结果是 <code>1111_0000</code>，<code>1001_1111</code>，<code>1001_1000</code>，<code>1001_1100</code>，换成 16 进制便是 <code>0xF0 0x9F 0x98 0x9C</code>，这就是 <code>😜</code> 的 UTF8 编码。</p>

<p>UTF8 因为它的灵活性，尤其是与 ASCII 的兼容性，目前已经成为事实上的标准。对于编码问题的处理很简单，<strong>一律选择使用 UTF8 即可</strong>。</p>

<h2 id="js-中的字符串问题和解决方法">JS 中的字符串问题和解决方法</h2>

<h3 id="js-的字符串和字符">JS 的字符串和字符</h3>

<p>JS 中的字符串，我们可以认为是 <strong>理解 Surrogate Pair 的 UCS-2</strong>。</p>

<p>这是因为，JS 中的字符串，我们可以使用 Surrogate Pair 来编码非 BMP 字符，这是 UTF16 的特性，单纯的 UCS-2 是不能理解 Surrogate Pair 的。</p>

<p>但是 JS 中的字符允许无效的 Surrogate Pair，比如 <code>&quot;\uDFFF\uD800&quot;</code>，或者单个 Surrogate，比如 <code>&quot;\uD800&quot;</code> 。因此 JS 中的字符也不是 UTF16，单纯的 UTF16 是不允许上面的字符串的。</p>

<p>另一个问题是，在 JS 看来，什么样的东西是一个字符？因为 JS 是理解 Surrogate Pair 的 UCS-2，因此，<strong>在 JS 眼中，一个编码单元是一个字符</strong>。</p>

<p>这就给 JS 中的 Unicode 处理带来了很多问题，基本上所有的字符串操作函数在处理非 BMP 字符时都是错误的。</p>

<h3 id="length">length</h3>

<p>最基本的问题就是，非 BMP 的字符，由于使用了 Surrogate Pair，含有两个编码单元，导致 JS 认为字符的长度为 2，这显然不是我们要的结果。</p>

<pre><code class="language-js">&quot;😜&quot;.length // 2
</code></pre>

<p>解决这个问题，可以自己编写一个 <code>strLength</code> 函数，特别处理码点范围在 <code>0xD800 - 0xDFFF</code> 中的字符，当然这比较麻烦，简单的方案是使用 <a href="https://github.com/bestiejs/punycode.js/">Punycode</a> 库。</p>

<pre><code class="language-js">var puny = require(&quot;punycode&quot;)
puny.ucs2.decode(&quot;😜&quot;).length // 1
</code></pre>

<p>或者利用 ES6 的新特性：ES6 中的 <code>for of</code> 循环可以正确识别 Unicode，这也就使得和 for of 循环使用相同机制的 <code>...</code> 操作符可以正确识别 Unicode。</p>

<pre><code class="language-js">// 这个做法很浪费内存
[...&quot;😜&quot;].length // 1
</code></pre>

<h3 id="charat-charcodeat">charAt &amp;&amp; charCodeAt</h3>

<p><code>charAt</code> 以及 <code>charCodeAt</code> 两个方法用于返回某个偏移量的字符和字符码点，对于非 BMP 字符，返回结果是错的，返回的是 Lead Surrogate 的字符和码点。</p>

<pre><code class="language-js">&quot;😜&quot;.charAt(0) // &quot;�&quot;
&quot;😜&quot;.charCodeAt(0) // 55357
</code></pre>

<p>可以使用 ES6 的 <code>String.prototype.codePointAt</code> 和 <code>String.fromCodePoint</code> 两个方法来解决这个问题。</p>

<pre><code class="language-js">&quot;😜&quot;.codePointAt(0) // 128540
String.fromCodePoint(&quot;a😜b&quot;.codePointAt(1)) // &quot;😜&quot;
</code></pre>

<h3 id="unicode-escape">Unicode Escape</h3>

<p>JS 中允许使用 <code>\udddd</code> 以及 <code>\xdd</code> 的形式指定十六进制的数字插入字符。但是对于非 BMP 的字符，使用这个方式插入，需要首先得到 Surrogate Pair 才行，不能直接根据码点插入，比较麻烦。</p>

<pre><code class="language-js">&quot;\u1F61C&quot; // &quot;ὡC&quot;
</code></pre>

<p>ES6新提供了 <code>\u{}</code> 方式，使得根据码点插入字符变得非常简单。注意 escape 中填写的都是码点的十六进制值。</p>

<pre><code class="language-js">&quot;\u{1F61C}&quot; // &quot;😜&quot;
</code></pre>

<h3 id="substring-substr-slice">Substring, Substr, Slice</h3>

<p>这三个函数的行为很类似，参数的含义以及是否允许负数索引上有一些细微的不同。他们同样也都不能正确处理非 BMP 字符。</p>

<pre><code class="language-js">&quot;😜&quot;.substr(0, 1) // &quot;�&quot;
&quot;😜&quot;.substring(0, 1) // &quot;�&quot;
&quot;😜&quot;.slice(0, 1) // &quot;�&quot;
</code></pre>

<p>我们可以利用 ES6 的 <code>for of</code> 实现重新编写这三个函数，下面的实现只用来说明思路，并不完全。</p>

<pre><code class="language-js">String.prototype.newSubstr = function(start, length) {
  return [...this].slice(start, start + length).join(&quot;&quot;)
}
String.prototype.newSubstring = function(start, end) {
  return [...this].slice(start, end).join(&quot;&quot;)
}
String.prototype.newSlice = function(start, end) {
  return [...this].slice(start, end).join(&quot;&quot;)
}
&quot;😜&quot;.newSubstr(0, 1) // &quot;😜&quot;
&quot;😜&quot;.newSubstring(0, 1) // &quot;😜&quot;
&quot;😜&quot;.newSlice(0, 1) // &quot;😜&quot;
</code></pre>

<p>其他的一些函数都可以用类似的思路解决，不在赘述了。</p>

<h3 id="regexp-dot">Regexp Dot</h3>

<p>JS 中的正则，在处理非 BMP 字符时同样存在问题。</p>

<p>我们首先来看 <code>.</code> 字符。<code>.</code> 字符在正则中的含义是匹配非换行符以外的任意字符。但是在 JS 中，<code>.</code> 只能匹配一个编码单元，对于使用两个编码单元的非 BMP 字符，则无法匹配。</p>

<pre><code class="language-js">/./.test(&quot;😜&quot;) // false
</code></pre>

<p>这个问题的解决方案有两个。第一，自己编写范围来匹配非 BMP 字符。</p>

<pre><code class="language-js">/[\u0000-\uD7FF][\uE000-\uFFFF]|[\uD800-\uDBFF][\uDC00-\uDFFF]/.test(&quot;😜&quot;) // true
</code></pre>

<p>第二，使用 ES6 引入的 <code>u</code> 标志。</p>

<pre><code class="language-js">/./u.test(&quot;😜&quot;) // true
</code></pre>

<h3 id="regexp-range">Regexp Range</h3>

<p>第二个问题是正则中的范围。范围中如果使用了非 BMP 字符，JS 会报错。</p>

<pre><code class="language-js">/[😆-😜]/.test(&quot;😜&quot;)
Uncaught SyntaxError: Invalid regular expression: /[😆-😜]/: Range out of order in character class
    at &lt;anonymous&gt;:1:1
</code></pre>

<p>出错的原因在于 <code>/[😆-😜]/</code> 在 JS 中等价于 <code>/[\uD83D\uDE06-\uD83D\uDE1C]/</code>，而 <code>\uDE06-\uD83D</code> 会被解释为一个范围，而这个范围的起始值比结束值要大，因此错误。</p>

<p>解决方法同样有两个。第一，改写正则。</p>

<pre><code class="language-js">/\uD83D[\uDE06-\uDE1C]/.test(&quot;😆&quot;) // true
</code></pre>

<p>第二，还是使用 ES6 引入的 <code>u</code> 标志。</p>

<pre><code class="language-js">/[😆-😜]/u.test(&quot;😜&quot;) // true
/[\u{1F606}-\u{1F61C}]/u.test(&quot;😜&quot;) // true
</code></pre>

<h2 id="unicode-normalization">Unicode Normalization</h2>

<p>最后，我们来谈谈 Unicode 的规整化。这个问题和 JS 没关系，是 Unicode 字符集本身的问题。</p>

<p>根据 Unicode 定义，有些字符属于 *修饰字符*，也就是和别的字符一起出现的时候会修饰别的字符，两个合在一起构成一个我们人眼中的字符。</p>

<p>比如，<code>ë</code> 这个字符，由两个 Unicode 码点构成，分别是 <code>U+0065</code> 和 <code>U+0308</code>。这两个都是 Unicode 中的合法字符，拥有自己的码点，但他们合在一起的时候，构成一个我们人类眼中的字符。</p>

<p>同时，在 Unicode 中，还有一个单独的字符 <code>ë</code>，码点为 <code>U+00EB</code>。</p>

<p><code>ë</code> 和 <code>ë</code> 在我们眼中是一样的字符，但在 Unicode 中却是不同的表现，一个是由两个字符拼接而成，另一个是独立的字符，因此，如果直接比较的话，肯定是不相等的。</p>

<pre><code class="language-js">&quot;ë&quot; === &quot;ë&quot; // false
</code></pre>

<p>这时候就需要引入规整化，将字符转变为某种特定的形式。Unicode 中定义了四种形式，常用的两种是：</p>

<ol>
<li><code>NFD</code>: Normalization Form Canonical Decomposition，将所有的单个的复合字符转换为多个字符拼接而成的形式</li>
<li><code>NFC</code>: Normalization Form Canonical Composition，将所有的拼接而成的符合字符转换为单个字符的形式</li>
</ol>

<p>因此，在比较 Unicode 字符串之前，我们需要对两边的字符串规整化到相同的形式，这样结果才是准确的。ES6 中引入的 <code>String.prototype.normalize</code> 方法可以用于字符串的规整化。</p>

<pre><code class="language-js">&quot;ë&quot;.normalize(&quot;NFC&quot;) === &quot;ë&quot;.normalize(&quot;NFC&quot;) // true
</code></pre>

<h2 id="reverse-the-string">Reverse the String</h2>

<p>由于存在修饰字符，使得字符串取反变成了一个复杂的操作。</p>

<p>如果不考虑非 BMP 字符，在 JS 中，对字符串取反的一般方式为 <code>str.split(&quot;&quot;).reverse().join(&quot;&quot;)</code>。</p>

<p>考虑到非 BM 字符，我们可以使用 <code>[...str].reverse().join(&quot;&quot;)</code>。</p>

<p>但是，如果含有修饰字符的话，使用 <code>...</code> 一样无法返回正确的结果。</p>

<pre><code class="language-js">[...&quot;mañana&quot;].reverse().join(&quot;&quot;) // &quot;anãnam&quot;
</code></pre>

<p>这里的问题在于对于 <code>&quot;mañana&quot;</code> 使用 <code>...</code> 产生的字符数组为 <code>[&quot;m&quot;, &quot;a&quot;, &quot;n&quot;, &quot;̃&quot;, &quot;a&quot;, &quot;n&quot;, &quot;a&quot;]</code>，取反以后，修饰字符会跟在 <code>a</code> 的后面，从而产生 <code>ã</code>。</p>

<p>这个问题需要做手动做一些的处理，在取反之前，将修饰字符和被修饰的字符颠倒一下顺序，然后再取反就行了。我们可以直接使用 <a href="https://github.com/mathiasbynens/esrever">esrever</a> 库来处理。</p>

<p>esrever 的 <code>reverse</code> 函数具体实现可以看<a href="https://github.com/mathiasbynens/esrever/blob/14b34013dad49106ca08c0e65919f1fc8fea5331/src/esrever.js#L23">这里</a>。</p>

<pre><code class="language-js">esrever.reverse(&quot;mañana&quot;) // &quot;anañam&quot;
</code></pre>
          ]]>
          </description>

        </item>
      
    
      
    
      
        <item>
          <title>DNS 101</title>
          <link>https://cjting.me/2018/05/01/dns-101/</link>
          <pubDate>Tue, 01 May 2018 15:32:08 +0800</pubDate>
          

          <guid>https://cjting.me/2018/05/01/dns-101/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/FiDsImkj3TOme4jW4eezs3b-n2Uw.jpeg" class="webfeedsFeaturedVisual">

            <p>DNS 全称 <code>Domain Name System</code>，是我们每天都在使用的基础互联网设施。</p>

<p>它被发明出来的原因很简单，计算机之间的通信用的是 IP 地址，是一串数字，人类记忆起来十分不方便，因此，我们给地址起个名字，然后将名字和 IP 之间的关系记录起来，这样，我们只用记住名字就行了。</p>

<p>从上面可以看出，DNS 系统类似我们日常使用的电话本，只不过里面存储的是域名和 IP 之间的关系。和人与电话之间的关系一样，一个域名可以有多个 IP，一个 IP 也可以有多个域名。</p>

<h2 id="基本概念">基本概念</h2>

<p>现在我们来介绍几个 DNS 系统的概念。</p>

<p><strong>DNS Server</strong>: DNS 服务器，这是我们获取 DNS 服务的入口。每台上网的计算机都需要配置 DNS 服务器的 IP 地址，之后所有的域名查询，就通过询问这个服务器完成。</p>

<p><strong>Record</strong>: 记录，域名在 DNS 系统的一条配置，称为一条记录。最常见的记录就是域名对应的 IP 是什么。</p>

<p><strong>Record Type</strong>: 记录类型，除了域名对应的 IP，域名还有别的信息，比如域名对应的邮件服务器是什么等等，也就是，记录有不同的类型。</p>

<p>常见的记录类型如下：</p>

<ul>
<li><code>A</code>: Address 记录，域名对应的 IPv4 地址</li>
<li><code>AAAA</code>: 域名对应的 IPv6 地址</li>
<li><code>MX</code>: 域名对应的电子邮件服务器地址</li>
<li><code>NS</code>: 域名对应的域名服务器域名，有点绕，简单来说，你想知道 A 域名的信息，需要去问 A 域名的 NS 记录对应的域名</li>
<li><code>CNAME</code>: 域名的 <code>Canonical Name</code>，类似于文件系统中的链接</li>
</ul>

<p>这里是<a href="https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-2">完整的记录列表</a>。</p>

<p>当我们购买了域名以后，就可以在服务商提供的配置系统中设置域名的相关记录。一般来说，服务商会默认配置两条 <code>NS</code> 记录到他们的域名服务器，当然，我们也可以修改这个记录，使用第三方域名服务器，比如 <a href="https://www.dnspod.cn/">DNSPod</a>。</p>

<h2 id="分级结构">分级结构</h2>

<p>互联网的规模太大，域名数量更是数不胜数，一台 DNS Server 将这些数据都存储下来是不现实的，因此 DNS 在设计的时候，采用的是分级结构，每一部分存储下一级的相关信息。</p>

<p>举个例子，我们想知道 <code>www.example.com</code> 的 IP 地址是什么，将这个请求发送给了我们的 DNS Server。</p>

<p>DNS Server 需要先问根域名服务器，谁负责管理 <code>.com</code>？然后再问 <code>.com</code> 域名服务器，谁负责管理 <code>example.com</code>？最后，再问 <code>example.com</code> 域名服务器，<code>www.example.com</code> 的 IP 地址是什么，从而获得答案返回给我们。</p>

<p>这就是域名的分级结构，域名查询需要从根开始，一级一级的向下，直到获得答案。</p>

<p>当然，因为域名查询是一个高频词的动作，无时无刻都在发生，如果每次都是这样一层一层获取，效率将十分低下，因此，<strong>DNS 系统中大量使用缓存</strong>，每一个中间环节都会缓存相关结果来节省时间提高效率。</p>

<h2 id="根域名服务器">根域名服务器</h2>

<p>上面的描述引入了一个问题。因为我们每次查询（不考虑缓存）都需要询问根域名服务器，那么 DNS Server 是如何得知根域名服务器的地址呢？</p>

<p>答案是 <strong>使用配置文件写死</strong>，就是这么简单。</p>

<p>目前全世界一共有 13 组根域名服务器，分别是 <code>[a-m].root-servers.net</code>。</p>

<p>IANA 提供了<a href="https://www.iana.org/domains/root/files">根域名服务器配置文件</a>，下载下来配置相关的 DNS 软件就行了。</p>

<h2 id="常用工具">常用工具</h2>

<p>DNS 相关的常用工具有两个，一个是 <code>dig</code>，功能强大，十分灵活。</p>

<p>用法是 <code>dig &lt;记录类型&gt; &lt;查询名称&gt;</code>。</p>

<p>例如，我想知道根域名服务器的相关信息。</p>

<pre><code class="language-bash">$ dig ns . # 注意，`.`代表根域名，这条指令表示查询根域名的NS记录
; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; ns .
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 12846
;; flags: qr rd ra; QUERY: 1, ANSWER: 13, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;.        IN  NS

;; ANSWER SECTION:
.     40368 IN  NS  h.root-servers.net.
.     40368 IN  NS  m.root-servers.net.
.     40368 IN  NS  f.root-servers.net.
.     40368 IN  NS  c.root-servers.net.
.     40368 IN  NS  e.root-servers.net.
.     40368 IN  NS  l.root-servers.net.
.     40368 IN  NS  k.root-servers.net.
.     40368 IN  NS  a.root-servers.net.
.     40368 IN  NS  i.root-servers.net.
.     40368 IN  NS  b.root-servers.net.
.     40368 IN  NS  d.root-servers.net.
.     40368 IN  NS  g.root-servers.net.
.     40368 IN  NS  j.root-servers.net.

;; Query time: 10 msec
;; SERVER: 116.228.111.118#53(116.228.111.118)
;; WHEN: Tue May  1 16:53:16 2018
;; MSG SIZE  rcvd: 228
</code></pre>

<p>从返回的结果可以看出，根域名有 13 条 <code>NS</code> 记录，对应 13 组域名服务器。</p>

<p>使用 <code>dig</code> 获取 <code>cjting.me</code> 的 IPv4 地址。</p>

<pre><code class="language-bash">$ dig cjting.me # 记录类型默认为 `A`
; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; cjting.me
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 25983
;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;cjting.me.     IN  A

;; ANSWER SECTION:
cjting.me.    598 IN  A 192.30.252.153
cjting.me.    598 IN  A 192.30.252.154

;; Query time: 10 msec
;; SERVER: 116.228.111.118#53(116.228.111.118)
;; WHEN: Tue May  1 16:55:06 2018
;; MSG SIZE  rcvd: 59
</code></pre>

<p>可以看到，<code>cjting.me</code> 这个域名有两条 <code>A</code> 记录，即查询到了两条 IP 地址。</p>

<p>第二个指令是 <code>host</code> 指令，相比 <code>dig</code> 指令，功能比较简单，输出也比较简洁。</p>

<p>使用 <code>host</code> 获取 <code>cjting.me</code> 的相关信息。</p>

<pre><code class="language-bash">$ host cjting.me
cjting.me has address 192.30.252.154
cjting.me has address 192.30.252.153
</code></pre>

<h2 id="一次完整的查询">一次完整的查询</h2>

<p><code>dig</code> 有一个很高级的功能，叫做 <code>trace</code>，即可以追踪输出每一级查询的具体信息，而不是只给一个最终结果。</p>

<p>下面我们来看一个完整的例子，<code>dig +trace cjting.me</code>，看看到底发生了哪些请求，最终的IP地址是如何得到的。</p>

<pre><code class="language-bash">$ dig +trace cjting.me
; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; +trace cjting.me @8.8.8.8
;; global options: +cmd
.                       209918  IN      NS      a.root-servers.net.
.                       209918  IN      NS      m.root-servers.net.
.                       209918  IN      NS      b.root-servers.net.
.                       209918  IN      NS      l.root-servers.net.
.                       209918  IN      NS      f.root-servers.net.
.                       209918  IN      NS      d.root-servers.net.
.                       209918  IN      NS      j.root-servers.net.
.                       209918  IN      NS      i.root-servers.net.
.                       209918  IN      NS      g.root-servers.net.
.                       209918  IN      NS      k.root-servers.net.
.                       209918  IN      NS      e.root-servers.net.
.                       209918  IN      NS      h.root-servers.net.
.                       209918  IN      NS      c.root-servers.net.
;; Received 228 bytes from 8.8.8.8#53(8.8.8.8) in 117 ms

me.                     172800  IN      NS      a2.nic.me.
me.                     172800  IN      NS      a0.nic.me.
me.                     172800  IN      NS      c0.nic.me.
me.                     172800  IN      NS      b0.nic.me.
me.                     172800  IN      NS      b2.nic.me.
;; Received 336 bytes from 199.9.14.201#53(199.9.14.201) in 768 ms

cjting.me.              86400   IN      NS      f1g1ns2.dnspod.net.
cjting.me.              86400   IN      NS      f1g1ns1.dnspod.net.
;; Received 81 bytes from 199.253.60.1#53(199.253.60.1) in 361 ms

cjting.me.              600     IN      A       192.30.252.154
cjting.me.              600     IN      A       192.30.252.153
cjting.me.              86400   IN      NS      f1g1ns1.dnspod.net.
cjting.me.              86400   IN      NS      f1g1ns2.dnspod.net.
;; Received 123 bytes from 180.163.19.15#53(180.163.19.15) in 8 ms
</code></pre>

<p><code>dig</code> 会输出每一步的关键信息，但并不完整。例如，第二段中，<code>dig</code> 询问 <code>199.9.14.201</code> 获取到了 <code>.me</code> 域名的相关信息，但是 <code>199.9.14.201</code> 这个 IP 是如何来的呢？</p>

<p>下面我列出这中间发生的完整步骤，假设我的本机 IP 是 192.168.0.100，DNS Server 的 IP 是 192.168.0.1。</p>

<ol>
<li>192.168.0.100 -&gt; 192.168.0.1: <code>.</code>的 NS 记录是什么？</li>
<li>192.168.0.1 -&gt; 192.168.0.100: 是 <code>a.root-servers.net</code>, <code>b.root-servers.net</code>&hellip;
3.

<ul>
<li>192.168.0.100 -&gt; 192.168.0.1: <code>a.root-servers.net</code> 的 A 记录是什么？</li>
<li>192.168.0.1 -&gt; 192.168.0.100: 是 198.41.0.4</li>
<li>192.168.0.100 -&gt; 192.168.0.1: <code>b.root-servers.net</code> 的 A 记录是什么？</li>
<li>192.168.0.1 -&gt; 192.168.0.100: 是 199.9.14.201</li>
<li>&hellip;</li>
<li>dig 会选择一个 IP 进行下一步，同时该地址对应的 IP 会被缓存起来，此时选中的是 199.9.14.201</li>
</ul></li>
<li>192.168.0.100 -&gt; 199.9.14.201: <code>.me</code> 的 A 记录是什么？</li>
<li>199.9.14.201 -&gt; dig: <code>.me</code> 的 NS 记录是 <code>a2.nic.me</code>, <code>b0.nic.me</code>&hellip;
6.

<ul>
<li>192.168.0.100 -&gt; 192.168.0.1: <code>b0.nic.me</code> 的 A 记录是什么？</li>
<li>192.168.0.1 -&gt; 192.168.0.100: 是 <code>199.253.60.1</code></li>
<li>192.168.0.100 -&gt; 192.168.0.1: <code>a2.nic.me</code> 的 A 记录是什么？</li>
<li>192.168.0.1 -&gt; 192.168.0.100: 是 <code>199.253.59.1</code></li>
<li>&hellip;</li>
<li>dig 会选择一个 IP 进行下一步，同时该地址对应的 IP 会被缓存，此时选中的是 199.253.60.1</li>
</ul></li>
<li>192.168.0.100 -&gt; 199.253.60.1: <code>cjting.me</code> 的 A 记录是什么？</li>
<li>199.253.60.1 -&gt; dig: <code>cjting.me</code> 的 NS 记录是 <code>f1g1ns1.dnspod.net</code> 和 <code>f1g1ns2.dnspod.net</code>
9.

<ul>
<li>192.168.0.100 -&gt; 192.168.0.1: <code>f1g1ns2.dnspod.net</code> 的 A 记录是什么？</li>
<li>192.168.0.1 -&gt; 192.168.0.100: 是 182.140.167.188, 101.226.220.16, &hellip;</li>
<li>192.168.0.100 -&gt; 192.168.0.1: <code>f1g1ns1.dnspod.net</code> 的 A 记录是什么？</li>
<li>192.168.0.1 -&gt; 192.168.0.100: 是 61.151.180.44, 58.247.212.36, &hellip;</li>
<li>dig 会选择一个 IP 进行下一步，同时该地址对应的 IP 会被缓存，此时选中的是 180.163.19.15</li>
</ul></li>
<li>192.168.0.100 -&gt; 180.163.19.15: <code>cjting.me</code> 的 A 记录是什么？</li>
<li>180.163.19.15 -&gt; 192.168.0.100: A 记录是 192.30.252.154 和 192.30.252.153, NS 记录是 f1g1ns1.dnspod.net 和 f1g1ns2.dnspod.net</li>
<li>至此整个过程结束</li>
</ol>

<p>可以看出，一共进行了 <code>1 + 1 + 13 * 2 + 1 + 1 + 5 * 2 + 1 + 1 + 2 * 2 + 1 + 1 = 48</code> 次通信（请求+响应），可见，如果不进行缓存的话，DNS 是多么地浪费资源。</p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>HTTP Basic Auth 是怎么样工作的</title>
          <link>https://cjting.me/2018/03/31/how-http-basic-auth-work/</link>
          <pubDate>Sat, 31 Mar 2018 19:40:48 +0800</pubDate>
          

          <guid>https://cjting.me/2018/03/31/how-http-basic-auth-work/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/FtsKJCGdjEVMPYYiuCucEfkwa3pn.jpeg" class="webfeedsFeaturedVisual">

            <p><code>HTTP Basic Auth</code> 是 HTTP 提供的一种验证方式，因为明文传输用户名和密码，非 HTTPS 环境下很不安全，一般用的非常少。但是在某些情况下用一用还是非常方便的，比如，一些静态站点例如文档系统可以使用 HTTP Basic Auth 进行简单的权限验证。</p>

<h2 id="流程">流程</h2>

<p>HTTP Basic Auth 使用两个 HTTP Header 实现，分别是 <code>WWW-Authenticate</code> 和 <code>Authorization</code>。</p>

<p>流程如下：</p>

<ol>
<li>客户端请求服务器页面，服务器返回 <code>401</code> 以及 <code>WWW-Authenticate: Basic realm=&quot;site&quot;</code>。</li>
<li>浏览器弹出对话框，提示用户输入用户名和密码。</li>
<li>浏览器再次请求页面，携带 <code>Authorization: Basic &lt;str&gt;</code>，其中，<code>str=base64(username:password)</code>。</li>
<li>服务器返回正常页面。</li>
</ol>

<p>base64 只是一个编码过程，而不是加密过程，因此，HTTP Basic Auth 是在明文传输用户名和密码，中间设备很容易通过检查数据包获取用户名和密码。</p>

<h2 id="realm">Realm</h2>

<p>我们可以发现，<code>WWW-Authenticate</code> 这个头携带了一个 <code>realm</code> 属性，这个属性用来标注页面所属的区域，具体定义见 <a href="https://tools.ietf.org/html/rfc7235#section-2.2">RFC 7235</a>。一般情况下不用在意，随便填写或者不填写都可以。</p>

<p>但是，如果你的网站有两个子目录，每个子目录有自己的用户名和密码的话，<code>realm</code> 属性就比较重要了，这个属性会影响浏览器的密码自动填充过程。</p>

<p>我们知道，访问一个 HTTP Basic Auth 的网站，第一次输入密码以后，之后访问就不再需要输入密码了，这是因为浏览器缓存了用户名和密码并且自动替我们填充了。</p>

<p>关于浏览器在 HTTP Basic Auth 时的密码填充算法，我没有找到明确的描述，自己基于 Chrome 做了一些实验，总结如下。</p>

<p>考虑下面的网站，有两个 URL，每个 URL 的用户名和密码不相同。</p>

<ul>
<li><code>/a</code>: <code>username: a, password: a, realm: whatever</code></li>
<li><code>/b</code>: <code>username: b, password b, realm: whatever</code></li>
</ul>

<ol>
<li>用户访问 <code>/a</code>，浏览器提示输密码，成功进入，浏览器将密码和 <code>realm=whatever</code> 关联</li>
<li>用户访问 <code>/b</code>，浏览器请求，发现 401，同时 <code>realm=whatever</code>，默认使用上一次输入的密码填充</li>
<li>还是 401，浏览器弹框提示用户输入，然后更新 <code>realm=whatever</code> 的密码关联</li>
<li>用户访问 <code>/a</code>，浏览器自动使用 <code>realm=whatever</code>的密码进行填充（应该是缓存了相关信息，知道 <code>/a</code> 需要密码），收到 401，弹框提示用户输入，更新 <code>realm=whatever</code> 的密码关联</li>
<li>用户访问 <code>/b</code>，和上面的流程一样，还是会导致弹框提示用户输入用户名和密码</li>
</ol>

<p>也就是说，如果两个子目录的用户名和密码不一样，但是 <code>realm</code> 一样的话，会导致在两个子目录进行切换时，不停地输入用户民和密码。</p>

<p>如果 <code>realm</code> 不一样的话，就没有这个问题了，因为浏览器使用 <code>realm</code> 来关联用户名和密码。</p>

<h2 id="如何清除用户名和密码">如何清除用户名和密码</h2>

<p>因为浏览器会记住用户名和密码，然后替我们做“自动登录”，那么该怎么样才能“登出”呢？</p>

<p>考虑这样一个场景，网站设置了多套用户名和密码，下发了部分给客户，结果客户反应说用户名和密码不对，那么此时，因为我已经登录成功了，无法再看到输入框，自然也无法测试。这个时候我们需要就是“登出”，清空浏览器的 “HTTP Basic Auth 缓存”。</p>

<p>在 Chrome 中，我们只要在 URL 前面加上 <code>user@</code> 即可强制浏览器刷新它的缓存，弹出对话框。</p>

<p>例如，网站为 <code>http://www.a.com</code>，访问输入了密码以后，再使用 <code>http://user@www.a.com</code> 访问，就会重新弹出弹框。</p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>从 Jekyll 迁移到 Hugo，Hugo 不完全指南</title>
          <link>https://cjting.me/2017/06/04/migrate-to-hugo-from-jekyll/</link>
          <pubDate>Sun, 04 Jun 2017 15:46:33 +0800</pubDate>
          

          <guid>https://cjting.me/2017/06/04/migrate-to-hugo-from-jekyll/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/FlKmTvbJZO1j12pQzImT2EbtVgac.jpeg" class="webfeedsFeaturedVisual">

            <p>最近这段时间一直在忙着迁移博客，把原本基于 Jekyll 的博客迁移到了 Hugo 上。</p>

<p>之所以从 Jekyll 迁移的原因并不复杂，就是一个字：<strong>慢</strong>。Jekyll 的速度实在是太慢了，我只有几十篇文章，在 Watch 模式下，每次改动，重新生成都要花费 3 秒钟，实在是太慢了。</p>

<pre><code class="language-bash">Regenerating: 1 file(s) changed at 2017-05-14 10:37:16 ...done in 3.085089 seconds.
Regenerating: 1 file(s) changed at 2017-05-14 10:37:20 ...done in 3.121783 seconds.
</code></pre>

<p>我的机器是 i7 的 CPU，16G 的内存外加 256G 的 SSD。如此强的配置，如此简单的操作，竟然花费了 3 秒钟，我不知道这是 Ruby 的原因还是和 Jekyll 本身的实现有关系，我也不关心了。慢成这样，我只能换掉它了。</p>

<p>这里要插一句，如果你的 Jekyll 站点中使用了 npm 来管理 JS 依赖，一定要记得配置 Jekyll 让它忽略 <code>node_modules</code> 文件夹，否则会慢到你怀疑人生。</p>

<h2 id="静态站点生成器">静态站点生成器</h2>

<p>Jekyll 是目前最为流行的静态站点生成器 (Static Site Generator，后面简称为 SSG)，流行的原因我想一大半归功于 GitHub 的推广，Jekyll 是 GitHub Pages 默认的 SSG。</p>

<p>在我看来，SSG 是一个十分有用的东西，因为它可以帮助我们快速生成静态网站。静态网站有很多优点，最为关键的是：</p>

<ol>
<li>开发部署维护简单，省时省力，精力可以专注在内容上。</li>
<li>访问速度快，还有什么比直接返回已经渲染好的网页更快的呢？</li>
</ol>

<p>并不是每一个网站都需要一个 Server 来动态生成内容，也不是每一个网站都需要数据库。博客系统，文档系统，企业官网等等，都是静态网站的好用例。</p>

<p>SSG 简单来说，就是根据配置和内容，生成静态网站。配置一般由全局配置，模板，以及 <code>FrontMatter</code> 构成。</p>

<p>FrontMatter 指的是文章最前面的一段区域，一般由 <code>---</code> 分开，我们可以在这段区域中添加这篇文章携带的数据，数据格式一般是 YAML，如下所示。</p>

<pre><code class="language-markdown">---
name: CJ
date: 2017-06-09T11:01:08+08:00
---
从这里开始是正文的内容。
</code></pre>

<p>后续在模板中，我们可以将这些数据读取出来做一些操作，比如，所有 <code>name</code> 属性为 <code>CJ</code> 的文章我们可以添加特别的 class 进行高亮，这就大大增加了渲染的灵活性。</p>

<p>目前，最为流行的 SSG 是 <a href="https://jekyllrb.com/">Jekyll</a>，<a href="https://github.com/spf13/hugo">Hugo</a>，<a href="https://hexo.io/">Hexo</a> 这三个，不太流行的数不胜数，具体可以去看 <a href="https://www.staticgen.com/">Static Gen</a> 网站。</p>

<p>不管是什么型号，工作原理都是一样的，掌握了一个，剩下的学习起来也很容易。鉴于我对 Golang 的喜爱，简单了解 Hugo 以后，就选择使用 Hugo 作为新的博客引擎了。</p>

<p>Hugo 的优点很多，最为重要的自然是：<strong>快</strong>。相比于 Jekyll 要花费 3 秒钟，我的博客在 Hugo 下重新生成只要花费 30ms，足足快了 100 倍。</p>

<p>下面，我们使用 Hugo 来做一个简单的博客系统 (My Blog)，了解一下 Hugo 的基本使用，最终项目在 <a href="https://github.com/cj1128/hugo-demo">hugo-demo</a> 仓库中。</p>

<h2 id="安装">安装</h2>

<p>首先，自然是安装 Hugo，如果你是 Mac,<code>brew install hugo</code>。</p>

<p>如果你安装了 Go，<code>go get -u github.com/spf13/hugo</code>。</p>

<p>其他情况，可以直接去 <a href="https://github.com/spf13/hugo/releases">Hugo Release</a> 页面，下载对应平台的二进制程序即可。</p>

<h2 id="骨架">骨架</h2>

<p>我们先使用 Hugo 生成我们的博客站点。</p>

<pre><code class="language-bash"># hugo 支持多种配置格式，默认为 toml，使用 `-f` 来修改
hugo new site -f yaml my-blog 
tree my-blog
my-blog
├── archetypes
├── config.yaml
├── content
├── data
├── layouts
├── static
└── themes

6 directories, 1 file
</code></pre>

<p>一共六个文件夹，外加一个全局配置文件 <code>config.yaml</code>。</p>

<ul>
<li><code>archetypes</code>：给不同的类型定义默认 FrontMatter，一般用不上</li>
<li><code>content</code>：源文件</li>
<li><code>data</code>：数据文件，一般也用不上</li>
<li><code>layouts</code>：模板</li>
<li><code>static</code>：静态资源，也就是不需要 Hugo 处理的静态资源，比如图片等</li>
<li><code>themes</code>：第三方主题，将第三方主题拷贝到这个文件夹下即可使用</li>
</ul>

<p>比较常用的就是 content 和 layouts，一个存放内容，一个存放模板。</p>

<p>Hugo 使用的模板为 Go 标准库中的 <code>text/template</code>，和所有其他模板系统一样，看看文档 <a href="https://gohugo.io/templates/go-templates/">Go Template Primer</a> 掌握基本函数即可。</p>

<p><code>config.yaml</code> 中是全局配置，默认情况下，文章的 FrontMatter 数据格式为 TOML，我们将其改为 YAML，添加如下配置到 <code>config.yaml</code> 中。</p>

<pre><code class="language-yaml">metaDataFormat: yaml
</code></pre>

<h2 id="内容">内容</h2>

<p>在 Hugo 中，所有的内容存放在 <code>content</code> 目录中，其中每一个目录称为一个 <code>section</code>，我们先来生成一些内容用于后面测试我们的模板。</p>

<p>假设我们博客有两个分类，<code>c1</code> 和 <code>c2</code>，每个分类下有 1 篇文章。</p>

<pre><code class="language-bash"># 使用 `hugo new` 指令来生成文章
# 会自动替我们添加必需的 FrontMatter，比如 `date` 和 `title`
# `hugo new` 指令会自动添加 `content` 路径前缀
hugo new c1/_index.md
echo &quot;# this is c1&quot; &gt;&gt; content/c1/_index.md
hugo new c1/p1.md
echo &quot;# this is post 1 for cat 1&quot; &gt;&gt; content/c1/p1.md
hugo new c2/_index.md
echo &quot;# this is c2&quot; &gt;&gt; content/c2/_index.md
hugo new c2/p1.md
echo &quot;# this is post 1 for cat 2&quot; &gt;&gt; content/c2/p1.md
</code></pre>

<p>在 Hugo 中，一切东西都是 <code>Page</code>（页面），而每一个页面都对应一个源文件。比如，当我们访问 <code>/c1/</code> 时，对应的源文件是 <code>content/c1/_index.md</code>，当我们访问 <code>/c1/p1/</code> 时，对应的源文件则是 <code>content/c1/p1.md</code>。</p>

<h2 id="模板">模板</h2>

<p>现在，我们可以启动 Hugo 开发服务器来预览我们的站点了。</p>

<pre><code class="language-bash"># 默认生成的文章都有 `draft: true` 属性，表示文章为草稿，Hugo 默认情况下忽略 drafts
# `--buildDrafts` 告诉 Hugo 我们要渲染 Drafts
hugo server --buildDrafts
</code></pre>

<p>打开 1313 端口，我们会看到，什么都没有，嗯，这就对了。</p>

<p>为什么什么都没有呢，因为到目前为止，我们什么模板都没有编写，Hugo 要是能展现内容，那就奇怪了。</p>

<p>这里提一下，别的教程可能都会让新手直接安装 Hugo 的某个主题，主题是别人写好的模板系统封装起来了。我觉得掌握 Hugo 的一个关键就是要弄清楚它的模板系统，因此，这里我们不使用任何主题，自己来编写每一个模板。</p>

<p>在 Hugo 的模板系统中，页面分为两种类型，第一是列表型页面，这种页面对应的源文件是某个目录的 <code>_index.md</code>，比如，当我们访问 <code>/c1/</code> 时，Hugo 默认会使用 <code>list.html</code> 模板来渲染 <code>content/c1/_index.md</code> 文件。</p>

<p>还有一种就是单纯的内容页面，这种页面对应的源文件是某个目录的普通文件。比如，当我们访问 <code>/c1/p1/</code> 时，Hugo 默认会使用 <code>single.html</code> 模板来渲染 <code>content/c1/p1.md</code> 文件。</p>

<p>首页比较特殊，使用的模板名叫做 <code>index.html</code>。除此之外，我们还可以定义一个叫做 <code>baseof.html</code> 的模板，看名字就知道了，它是根模板。</p>

<p>Hugo 的模板全部存放在 <code>layouts</code> 目录中，默认模板存放在 <code>_default</code> 文件夹中。每一个源文件可以通过 FrontMatter 来指定使用什么模板，如果不指定就使用默认模板。渲染模板时，都会自动绑定源文件对应的 <code>Page</code> 变量，我们可以通过这个变量获取我们需要的信息。</p>

<p>先来编写 <code>baseof.html</code> 模板，新建 <code>layouts/_default/baseof.html</code> 文件。</p>

<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;UTF-8&quot;&gt;
  &lt;title&gt;My Blog&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
{{ block &quot;main&quot; . }}
{{ end }}
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>Hugo 的模板有一个叫做 <code>block</code> 的机制，具体见 <a href="https://gohugo.io/templates/blocks/">Hugo Block</a>，简单来说，父模板可以定义渲染什么 block，然后子模板中可以定义 block 的内容。</p>

<p>接下来编写 <code>index.html</code>，新建 <code>layouts/index.html</code> 文件。</p>

<pre><code class="language-html">{{ define &quot;main&quot; }}
  {{ .Content }}
{{ end }}
</code></pre>

<p>首页的模板首先定义 <code>baseof.html</code> 中渲染的 <code>main</code> block，然后直接渲染 Page 变量的 <code>Content</code> 属性，也就是对应的源文件的内容。</p>

<p>首页对应的源文件是 <code>content/_index.md</code>，我们来创建这个文件。</p>

<pre><code class="language-bash">hugo new _index.md
echo &quot;# This is index page&quot; &gt;&gt; content/_index.md
</code></pre>

<p>回到浏览器，可以看到页面自动刷新了。</p>

<blockquote>
<p>git checkout skeleton</p>
</blockquote>

<p><img src="http://asset.cjting.cn/9b85365dgy1fgesi9dqzwj20lz0ay0ss.jpg" alt="" /></p>

<p>这里来梳理一下，当 Hugo 编译我们站点时，发现 <code>content/_index.md</code> 文件，Hugo 会使用 <code>layouts/index.html</code> 和 <code>layouts/_default/baseof.html</code> 模板来渲染这个文件，并将得到的 HTML 文件放在结果文件夹的根目录下，当我们访问首页时，就会看到这个文件。</p>

<p>现在，我们要规划一下博客的结构，然后一一实现。</p>

<ul>
<li>首页和分类页都需要一个顶部导航栏，显示所有的分类，点击跳转到对应的分类页。</li>
<li>分类页根据时间列出所有的博文，点击跳转到对应的博文页。</li>
<li>博文页展示博文内容。</li>
</ul>

<h2 id="导航栏">导航栏</h2>

<p>由于首页和分类页都要用到导航栏，所以我们使用 Hugo 的 <code>Partial</code> 来做，Partial 简单来说，就是一个片段，可以在不同的模板中引用它。</p>

<p>我们打算直接将 <code>content</code> 目录中的子目录（叫做 <code>section</code>）作为分类，首先，在全局配置中添加如下配置。</p>

<pre><code class="language-yaml">SectionPagesMenu: main
</code></pre>

<p>Hugo 提供了一套复杂的菜单系统，这个配置告诉 Hugo，将所有的 section 都放入 <code>main</code> 这个菜单中，在模板中通过遍历 main 菜单，便可以渲染出所有的分类。</p>

<p>新建文件，<code>layouts/partials/header.html</code>。</p>

<pre><code class="language-html">&lt;header&gt;
  &lt;nav&gt;
    {{ range .Site.Menus.main }}
      &lt;a class=&quot;{{if eq $.URL .URL}}active{{end}}&quot; href=&quot;{{ .URL }}&quot;&gt;
        {{ .Name }}
      &lt;/a&gt;
    {{ end }}
  &lt;/nav&gt;
&lt;/header&gt;
</code></pre>

<p>先把这个应用到首页上看看，编辑文件 <code>layouts/index.html</code>。</p>

<pre><code class="language-html">{{ define &quot;main&quot; }}
  &lt;main&gt;
    {{ partial &quot;header&quot; . }}
    &lt;article&gt;
      {{ .Content }}
    &lt;/article&gt;
  &lt;/main&gt;
{{ end }}
</code></pre>

<p>浏览器页面如下。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1fgeslx5j0ij20ly0bgglo.jpg" alt="" /></p>

<p>看起来，header 生效了，但是，为什么两个分类的名称叫做 <code>_index</code> 呢？这是因为，默认情况下，Hugo 会使用分类对应的源文件的 <code>title</code>属性，这个属性默认是文件名。</p>

<p>编辑 <code>content/c1/_index.md</code> 文件和 <code>content/c2/_index.md</code> 文件的 <code>title</code> 属性，改为 <code>分类1</code> 和 <code>分类2</code>，这次就正确了。</p>

<h2 id="分类页">分类页</h2>

<p>点击这两个分类，发现内容是空白的，当然，分类页用的模板是 <code>list.html</code>，我们还没有编写。</p>

<p>新建 <code>layouts/_default/list.html</code> 文件。</p>

<pre><code class="language-html">{{ define &quot;main&quot; }}
  {{ partial &quot;header&quot; . }}
  &lt;div class=&quot;list&quot;&gt;
    {{ range .Data.Pages.GroupByDate &quot;2006-01&quot; }}
      &lt;div class=&quot;list__item&quot;&gt;
        &lt;h3 class=&quot;list__title&quot;&gt;{{ .Key }}&lt;/h3&gt;
        &lt;ul&gt;
          {{ range .Pages }}
            &lt;li class=&quot;list__post&quot;&gt;
              &lt;span&gt;&lt;/span&gt;
              &lt;a href=&quot;{{ .Permalink }}&quot;&gt;{{ .Title }}&lt;/a&gt;
              &lt;div&gt;{{ .Date.Format &quot;2006.01.02&quot; }}&lt;/div&gt;
            &lt;/li&gt;
          {{ end }}
        &lt;/ul&gt;
      &lt;/div&gt;
    {{ end }}
  &lt;/div&gt;
{{ end }}
</code></pre>

<p>模板代码的含义是根据日期和时间来渲染分类下的博文，效果如下。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1fgetkmelx0j20nl0azq30.jpg" alt="" /></p>

<h2 id="博文页">博文页</h2>

<p>最后，便是展示单篇博文的博文页，使用的模板是 <code>single.html</code>，新建文件 <code>layouts/_default/single.html</code> 如下。</p>

<pre><code class="language-html">{{ define &quot;main&quot; }}
  &lt;article&gt;
    {{ .Content }}
  &lt;/article&gt;
{{ end }}
</code></pre>

<p>很简单，直接渲染博文内容，<code>http://localhost:1313/c1/p1/</code> 页面如下。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1fgetqxr6fhj20nl078mx4.jpg" alt="" /></p>

<p>目前为止，我们的博客基本结构就搭建好了。</p>

<blockquote>
<p>git checkout basic</p>
</blockquote>

<h2 id="css-js-及其他静态资源">CSS，JS 及其他静态资源</h2>

<p>现在剩下的工作便是使用 CSS 来美化我们的博客了。</p>

<p>Hugo 根目录中的 <code>static</code> 目录用于存储各种静态文件，包括 CSS 和 JS，里面的内容在 Hugo 生成站点时会被原封不动拷贝到目标目录中（默认是 public）。</p>

<p>新建 <code>static/main.css</code> 文件，修改 <code>layouts/_default/baseof.html</code> 基础模板引入这个文件。</p>

<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;UTF-8&quot;&gt;
  &lt;title&gt;My Blog&lt;/title&gt;
  &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/main.css&quot;&gt;
&lt;/head&gt;
&lt;body&gt;
{{ block &quot;main&quot; . }}
{{ end }}
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>引入 JS 的道理同上。至于具体的样式代码，这里就不再赘述了。最终效果如下。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1fgfz1ofshej20sj0e33ys.jpg" alt="" /></p>

<blockquote>
<p>git checkout final</p>
</blockquote>

<h2 id="发布">发布</h2>

<p>最后一步便是发布，在项目根目录下运行 <code>hugo</code> 就可以将站点生成在 <code>public</code>文件夹中，丢给 Nginx 或者传到 Github 上随便你了。</p>

<p>Hugo 官方有一篇文档 <a href="https://gohugo.io/tutorials/github-pages-blog#building-and-deployment">Hosting on GitHub Pages</a> 说明如何部署在 GitHub 上，说的很详细，这里就不再赘述了。</p>

<p>最后，Hugo 确实是一个非常好用的 SSG，拥有速度快，模板灵活，结构清晰等各种优点，如果大家有兴趣，下一个静态站点项目可以试试用 Hugo 来构建。当然，再好的工具也不能解决人的懒惰，我要加油坚持写博客了~😉</p>
          ]]>
          </description>

        </item>
      
    
      
    
      
        <item>
          <title>Git 是怎样生成 diff 的：Myers 算法</title>
          <link>https://cjting.me/2017/05/13/how-git-generate-diff/</link>
          <pubDate>Sat, 13 May 2017 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2017/05/13/how-git-generate-diff/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/FvSatw-mAY94H60cISWGryzrCODq.jpeg" class="webfeedsFeaturedVisual">

            <p>diff 是我们每天都要使用的一个功能，每次提交时，我都习惯先用 <code>git diff --cached</code> 看看这次提交更改了些什么，确定没问题，然后再 <code>git commit</code>。git 生成的 diff 非常直观，直观到我从来都没有去思考过 diff 是怎么生成的，觉得这应该是很简单的一件事，两个文件做个对比，不就行了。</p>

<h2 id="什么是直观的-diff">什么是直观的 diff</h2>

<p>我们先简单定义一下什么是 diff：diff 就是目标文本和源文本之间的区别，也就是将源文本变成目标文本所需要的操作。</p>

<p>git 为我们生成的 diff 是很直观易懂的，一看就知道我们对文件进行了哪些改动。但是，实际上，diff 生成是一个非常复杂的问题。</p>

<p>举个简单的例子，源文本为 <code>ABCABBA</code>，目标文本为 <code>CBABAC</code>，他们之间的 diff 其实有无穷多种（我们以字符为单位，一般情况下是以行为单位）。比如</p>

<pre><code class="language-text">1.  - A       2.  - A       3.  + C
    - B           + C           - A
      C             B             B
    - A           - C           - C
      B             A             A
    + A             B             B
      B           - B           - B
      A             A             A
    + C           + C           + C
</code></pre>

<p>上面三种都是有效的 diff，都可以将源文本变成目标文本，但是第二种和第三种没有第一种看起来“直观”。</p>

<p>所以，我们需要个算法，生成“直观”的 diff，怎么样才叫“直观”呢？</p>

<ul>
<li>删除后新增，比新增后删除要好，也就是说，上面的例子 2 比例子 3 看起来要直观</li>

<li><p>当修改一块代码时，整块的删除然后新增，比删除新增交叉在一起要好，例如：</p>

<pre><code class="language-text">  Good: - one            Bad: - one
        - two                 + four
        - three               - two
        + four                + five
        + five                + six
        + six                 - three
</code></pre>

<ul>
<li>新增或删除的内容应该和代码结构相呼应，例如下面的例子，左边我们可以很直观地看出新增了一个inspect 方法。</li>
</ul>

<pre><code class="language-text">  Good: class Foo                   Bad:    class Foo
          def initialize(name)                def initialize(name)
            @name = name                        @name = name
          end                             +   end
      +                                   +
      +   def inspect                     +   def inspect
      +     @name                         +     @name
      +   end                                 end
        end                                 end
</code></pre></li>
</ul>

<p>除了直观以外，diff 还需要短，这一点是好理解的，我们希望 diff 反应的是把源文本变成目标文本需要用的最少的操作。</p>

<p>那么，现在的问题就是：怎样寻找最短的直观的 diff？</p>

<h2 id="diff-与图搜索">diff 与图搜索</h2>

<p>”寻找最短的直观的 diff” 是一个非常模糊的问题，首先，我们需要把这个问题抽象为一个具体的数学问题，然后再来寻找算法解决。</p>

<p>抽象的过程交给算法科学家了，抽象的结果是：<strong>寻找 diff 的过程可以被表示为图搜索</strong>。</p>

<p>什么意思呢？还是以两个字符串，src=<strong>ABCABBA</strong>，dst=<strong>CBABAC</strong> 为例，根据这两个字符串我们可以构造下面一张图，横轴是 src 内容，纵轴是 dst 内容。</p>

<p>那么，图中每一条从左上角到右下角的路径，都表示一个 diff。向右表示“删除”，向下表示”新增“，对角线则表示“原内容保持不动“。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1ffjxfo7r42j20lm0nudhx.jpg" alt="" /></p>

<p>比如，我们选择这样一条路径：</p>

<ol>
<li>(0, 0) -&gt; (1, 0)</li>
<li>(1, 0) -&gt; (2, 0) -&gt; (3, 1)</li>
<li>(3, 1) -&gt; (3, 2) -&gt; (4, 3) -&gt; (5, 4)</li>
<li>(5, 4) -&gt; (6, 4) -&gt; (7, 5)</li>
<li>(7, 5) -&gt; (7, 6)</li>
</ol>

<p>这条路径代表的 diff 如下。</p>

<pre><code class="language-text">- A
- B
  C
+ B
  A
  B
- B
  A
+ C
</code></pre>

<p>现在，“寻找 diff” 这件事，被抽象成了“寻找图的路径”了。那么，“最短的直观的” diff 对应的路径有什么特点呢？</p>

<ul>
<li>路径长度最短（对角线不算长度）</li>
<li>先向右，再向下（先删除，后新增）</li>
</ul>

<h2 id="myers-算法">Myers 算法</h2>

<p>Myers 算法就是一个能在大部分情况产生”最短的直观的“ diff 的一个算法，算法原理如下。</p>

<p>首先，定义参数 <code>d</code> 和 <code>k</code>，d 代表路径的长度，<code>k</code> 代表当前坐标 <code>x - y</code> 的值。定义一个”最优坐标“的概念，最优坐标表示 d 和 k 值固定的情况下，x 值最大的坐标。x 大，表示向右走的多，表示优先删除。</p>

<p>还是用上面那张图为例。我们从坐标 <code>(0, 0)</code> 开始，此时，<code>d=0</code>，<code>k=0</code>，然后逐步增加 <code>d</code>，计算每个 <code>k</code> 值下对应的最优坐标。</p>

<p>因为每一步要么向右（x + 1），要么向下（y + 1），对角线不影响路径长度，所以，当 d=1 时，k 只可能有两个取值，要么是 <code>1</code>，要么是 <code>-1</code>。</p>

<p>当 <code>d=1</code>，<code>k=1</code> 时，最优坐标是 <code>(1, 0)</code>。</p>

<p>当 <code>d=1</code>，<code>k=-1</code> 时，最优坐标是 <code>(0, 1)</code>。</p>

<p>因为 d=1 时，k 要么是 1，要么是 -1，当 d=2 时，表示在 d=1 的基础上再走一步，k 只有三个可能的取值，分别是 <code>-2</code>，<code>0</code>，<code>2</code>。</p>

<p>当 <code>d=2</code>，<code>k=-2</code> 时，最优坐标是 <code>(2, 4)</code>。</p>

<p>当 <code>d=2</code>，<code>k=0</code> 时，最优坐标是 <code>(2, 2)</code>。</p>

<p>当 <code>d=2</code>，<code>k=2</code> 时，最优坐标是 <code>(3, 1)</code>。</p>

<p>以此类推，直到我们找到一个 <code>d</code> 和 <code>k</code> 值，达到最终的目标坐标 <code>(7, 6)</code>。</p>

<p>下图横轴代表 d，纵轴代表 k，中间是最优坐标，从这张图可以清晰的看出，当 <code>d=5</code>，<code>k=1</code> 时，我们到达了目标坐标 (7, 6)，因此，”最短的直观的“路径就是 <code>(0, 0) -&gt; (1, 0) -&gt; (3, 1) -&gt; (5, 4) -&gt; (7, 5) -&gt; (7, 6)</code>，对应的 diff 如下。</p>

<pre><code class="language-text">- A
- B
  C
+ B
  A
  B
- B
  A
+ C
</code></pre>

<p><img src="http://asset.cjting.cn/9b85365dgy1ffjz1967znj20p20k9gmg.jpg" alt="" /></p>

<p>现在我们可以知道，其实 Myers 算法是一个典型的”动态规划“算法，也就是说，父问题的求解归结为子问题的求解。要知道 d=5 时所有 k 对应的最优坐标，必须先要知道 d=4 时所有 k 对应的最优坐标，要知道 d=4 时的答案，必须先求解 d=3，以此类推，和 01 背包问题很是相似。</p>

<h2 id="实现">实现</h2>

<p>算法原理知道以后，实现便是一件简单的事情了，<a href="https://github.com/cj1128/myers-diff">myers-diff</a> 仓库是我使用 Go 实现的一个版本，基本流程如下：</p>

<ol>
<li>迭代 d，d 的取值范围为 0 到 n+m，其中 n 和 m 分别代表源文本和目标文本的长度（这里我们选择以行为单位）</li>
<li>每个 d 内部，迭代 k，k 的取值范围为 -d 到 d，以 2 为步长，也就是 -d，-d + 2，-d + 2 + 2&hellip;</li>
<li>使用一个字典 v，以 k 值为索引，存储最优坐标的 x 值</li>
<li>将每个 d 对应的 v 字典存储起来，后面回溯的时候需要用</li>
<li>当我们找到一个 d 和 k，到达目标坐标 (n, m) 时就跳出循环</li>
<li>使用上面存储的 v 字典（每个 d 对应一个这样的字典），从终点反向得出路径</li>
</ol>

<p>最后补充一句，Git 真正用的是标准 Myers 算法的一个变体。标准的算法有一个很大的缺点，就是空间消耗很大，因为我们需要存储每一个 <code>d</code> 对应的 <code>v</code> 字典。如果输入文件比较大，这样的空间开销是不能接受的。因此 Myers 在他的 <a href="http://www.xmailserver.org/diff2.pdf">论文</a> 中，同时提供了一个算法变体，这个变体需要的空间开销要小得多。但是在某些情况下，变体产生的 diff 会和标准算法有所不同。也就是说，如果你按照上面的算法实现的程序，出来的结果和 <code>git diff</code> 的结果有所不同是正常的。</p>

<h2 id="参考资料">参考资料</h2>

<ul>
<li><a href="https://blog.jcoglan.com/2017/02/12/the-myers-diff-algorithm-part-1/">The Myers diff algorithm: part 1</a></li>
</ul>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>使用 Prometheus 监控服务器性能</title>
          <link>https://cjting.me/2017/03/12/use-prometheus-to-monitor-server/</link>
          <pubDate>Sun, 12 Mar 2017 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2017/03/12/use-prometheus-to-monitor-server/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/Fud1bDjGGvmZBEMsM5y_Crfg77Kb.jpeg" class="webfeedsFeaturedVisual">

            <p>最近一直在思考如何对线上服务做深度监控。基础的服务可用性监控很简单，定期 Ping 即可。但是怎样才能监控服务器的一些更加关键的数据呢？比如，每一个 API Point 的请求次数（QPS），最大响应时间，平均响应时间等。最终我希望实现的效果是有一个 Dashboard，我可以清楚地看到各种参数曲线，对服务器的运行情况了然于胸。</p>

<p>绘制 Dashboard 不难，目前提供数据可视化的工具很多，随便选一个都能满足需要。关键问题是，怎样将整个流程打通？</p>

<ul>
<li>服务器该以怎样的形式暴露出数据？</li>
<li>数据怎样被收集和存储起来？</li>
<li>存储起来的数据怎样提供给数据可视化工具？</li>
<li>怎样做到足够灵活，可以可视化自己感兴趣的任意数据？</li>
</ul>

<h2 id="prometheus">Prometheus</h2>

<p>像 QPS 和响应时间这些数据，外部工具是没办法直接拿到的，必须要服务器以某种方式将数据暴露出来。最常见的做法是写日志。比如 Nginx，每一条请求对应一个日志，日志中有响应时间这个字段。通过对日志分析，我们就可以得到 QPS，最大响应时间，平均响应时间等，再通过可视化工具即可绘制我们想要的 Dashboard。</p>

<p>日志这个方法固然是可行的，但是还有更好的方法。这个方法就是 <strong>时序数据库 (Time Series Database)</strong>。时序数据库简单来说就是存储随时间变化的数据的数据库。什么是随时间变化的数据呢？举个简单的例子，比如，CPU 使用率，典型的随时间变化的量，这一秒是 50%，下一秒也许就是 80% 了。或者是温度，今天是 20 度，明天可能就是 18 度了。</p>

<p><a href="https://prometheus.io/">Prometheus</a> 就是一个用 Go 编写的时序数据库，官网对其的优点介绍的很清楚，这里就不再赘述了。总之，使用简单，功能强大。</p>

<h3 id="安装">安装</h3>

<p>安装直接去官网下载对应的<a href="https://prometheus.io/download/">安装包</a>即可。当然，如果你是 Mac 用户的话，brew 永远不会让你失望：<code>brew install prometheus</code>。</p>

<h3 id="格式">格式</h3>

<p>Prometheus 获取数据的策略是 <strong>Pull</strong> 而不是 <strong>Push</strong>，也就是说，它会自己去抓取，而不用你来推送。抓取使用的是 HTTP 协议，在配置文件中指定目标程序的端口，路径及间隔时间即可。这也就意味着任何程序想要使用 Prometheus 存储数据都很简单，定义一个 HTTP 接口即可。</p>

<p>Prometheus 的数据格式是简单的文本格式，可以直接阅读。其中，<code>#</code>号开头的是注释，除此之外，每一行一个数据项，数据名在前，值在后。<code>{}</code>中是标签，一条数据可以有多个标签。</p>

<pre><code class="language-text"># HELP go_gc_duration_seconds A summary of the GC invocation durations.
# TYPE go_gc_duration_seconds summary
http_request_count{endpoint=&quot;/a&quot;} 10
http_request_count{endpoint=&quot;/b&quot;} 200
http_request_count(endpoint=&quot;/c&quot;) 3
</code></pre>

<h3 id="配置">配置</h3>

<p>Prometheus 使用 YAML 进行配置。<code>global</code> 配置一些全局信息，<code>scrape_configs</code> 配置具体想要抓取的目标。这段配置的含义是：启动一个叫做 <code>go-test</code> 的任务，每隔五秒钟，访问 <code>localhost:8888/metrics</code> 获取数据。</p>

<pre><code class="language-yaml">global:
  scrape_interval:     15s # By default, scrape targets every 15 seconds.

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: 'codelab-monitor'

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.
  - job_name: 'go-test'
    metrics_path: &quot;/metrics&quot;

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    static_configs:
      - targets: ['localhost:8888']
</code></pre>

<h3 id="测试程序">测试程序</h3>

<p>我们来写一个程序测试一下 Prometheus 的功能。虽然可以手动返回 Prometheus 需要的数据，但是使用开发好的客户端会更加方便。</p>

<p>这里我们使用 Go 语言，编写一个简单的服务器和客户端。客户端会以一个稳定的速度请求服务器的 <code>/test</code> 路径，但是每两分钟会加大流量，持续 30 秒再回到之前的水平。服务器 95% 的情况下会花费 50ms 进行响应，还有 5% 的情况下会花费 100ms。</p>

<p>这里我们定义了两个指标，<code>httpRequestCount</code> 记录 HTTP 的请求数，<code>httpRequestDuration</code> 记录响应时间，他们都有一个 <code>endpoint</code> 标签用于记录请求路径。这两个指标分别是 <code>Counter</code> 类型和 <code>Summary</code> 类型，Prometheus 定义了四种指标类型，基本涵盖了各种用例场景，具体可以去看<a href="https://prometheus.io/docs/concepts/metric_types/">相关文档</a>。简单来说，Counter 类型的数据表示一个只会向上增加的数据，比如请求数。而 Summary 类型的数据表示一个按区间分布的数据，比如响应时间或者请求体大小。</p>

<pre><code class="language-go">package main

import (
	&quot;log&quot;
	&quot;math/rand&quot;
	&quot;net/http&quot;
	&quot;time&quot;

	&quot;github.com/prometheus/client_golang/prometheus&quot;
	&quot;github.com/prometheus/client_golang/prometheus/promhttp&quot;
)

var httpRequestCount = prometheus.NewCounterVec(
	prometheus.CounterOpts{
		Name: &quot;http_request_count&quot;,
		Help: &quot;http request count&quot;,
	},
	[]string{&quot;endpoint&quot;},
)

var httpRequestDuration = prometheus.NewSummaryVec(
	prometheus.SummaryOpts{
		Name: &quot;http_request_duration&quot;,
		Help: &quot;http request duration&quot;,
	},
	[]string{&quot;endpoint&quot;},
)

func init() {
	prometheus.MustRegister(httpRequestCount)
	prometheus.MustRegister(httpRequestDuration)
}

func main() {
	http.Handle(&quot;/metrics&quot;, promhttp.Handler())
	http.HandleFunc(&quot;/test&quot;, handler)
	go func() {
		http.ListenAndServe(&quot;:8888&quot;, nil)
	}()
	startClient()
	doneChan := make(chan struct{})
	&lt;-doneChan
}

func handler(w http.ResponseWriter, r *http.Request) {
	start := time.Now()
	path := r.URL.Path
	httpRequestCount.WithLabelValues(path).Inc()

	n := rand.Intn(100)
	if n &gt;= 95 {
		time.Sleep(100 * time.Millisecond)
	} else {
		time.Sleep(50 * time.Millisecond)
	}

	elapsed := (float64)(time.Since(start) / time.Millisecond)
	httpRequestDuration.WithLabelValues(path).Observe(elapsed)
}

func startClient() {
	sleepTime := 1000

	go func() {
		ticker := time.NewTicker(2 * time.Minute)
		for {
			&lt;-ticker.C
			sleepTime = 200
			&lt;-time.After(30 * time.Second)
			sleepTime = 1000
		}
	}()

	for i := 0; i &lt; 100; i++ {
		go func() {
			for {
				sendRequest()
				time.Sleep((time.Duration)(sleepTime) * time.Millisecond)
			}
		}()
	}
}

func sendRequest() {
	resp, err := http.Get(&quot;http://localhost:8888/test&quot;)
	if err != nil {
		log.Println(err)
		return
	}
	resp.Body.Close()
}
</code></pre>

<p>启动 Prometheus <code>prometheus -config.file config.yml</code> 以后，再启动我们的测试程序 <code>go run test.go</code>。打开 Prometheus 控制台 <code>localhost:9090/targets</code> 就可以看到 Prometheus 正在抓取数据，一切正常。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1fdki1jpblnj21gk06mjs1.jpg" alt="" /></p>

<h3 id="控制台">控制台</h3>

<p>Prometheus 的一个强大之处在于可以使用各种函数和操作符来查询数据。在上面的测试程序中，每个数据都带有 <code>endpoint</code> 这个标签，表示请求的路径。打开 Prometheus 的控制台 <code>http://localhost:9090/graph</code>，点击 <code>console</code> 标签页，输入 <code>http_request_count{endpoint=&quot;/a&quot;}</code> 就可以查询路径为 <code>/a</code> 的 API Point 到目前为止的总请求数。如果想看 QPS 的话，可以使用自带的函数 <code>rate</code>，<code>rate(http_request_count[10s])</code> 表示以 10s 作为时间单元来统计 QPS。</p>

<p>Prometheus 的控制台自带一个简单的绘图系统，点击 <code>graph</code>标签页，输入表达式就可以看到图表。例如，输入 <code>rate(http_request_count{endpoint=&quot;/test&quot;}[10s])</code> 就可以看到我们测试程序中 <code>/test</code>路径的 QPS，从图中可以明显发现，每隔一段时间就会有一个波峰流量。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1fdkick67anj21ha0lw416.jpg" alt="" /></p>

<p><code>httpRequestDuration</code> 是一个 Summary 类型的指标，比简单的 Counter 要复杂，会生成三个数据项。分别是 <code>http_request_duration_sum</code> 表示响应时间加在一起的总和，<code>http_request_duration_count</code> 表示响应时间的总个数，以及<code>http_request_duration</code> 表示响应时间的分布情况，这个数据项会使用 <code>quantile</code> 标签对响应时间进行分组。</p>

<p>如下图所示，<code>quantile=0.5</code> 值为 50，表示 50% 的请求响应时间都在 50ms 以下。<code>quantile=0.9</code> 的值为 54，表示 90% 的请求响应时间都在 54ms 以下。但是，<code>quantile=0.99</code> 的值为 103，表示 99% 的请求响应时间在 103ms 以下。这就说明了一个问题，那就是极个别的请求耗费了大量时间。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1fdkikzfoyyj21gp0k8tat.jpg" alt="" /></p>

<p>通过使用表达式 <code>http_request_duration_sum / http_request_duration_count</code> 我们可以得到平均响应时间，如下图。当然，这个图的作用不大（平均数往往反映不了什么问题），不像上图那样，我们无法看出有部分请求花费了大量时间。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1fdkiurz15sj21h70kftap.jpg" alt="" /></p>

<p>以上只是对数据项的最简单利用，Prometheus 自带了很多函数和操作符，可以方便地对数据进行处理，具体可以参考<a href="https://prometheus.io/docs/querying/basics/">官方文档</a>。</p>

<h2 id="grafana">Grafana</h2>

<p>Prometheus 自带的图表是非常基础的，只能用来临时查看一下数据。如果要构建强大的 Dashboard，还是需要更加专业的工具才行。这个工具就是 <a href="http://grafana.org/">Grafana</a>。</p>

<h3 id="安装-1">安装</h3>

<p>同样是去官网下载相应的<a href="http://grafana.org/download/">安装包</a>。Mac 用户可以再次感受到 brew 的优越性。<code>brew install grafana</code>。</p>

<h3 id="启动">启动</h3>

<p>直接用默认配置就挺好的。在 Mac 上，启动指令如下。</p>

<pre><code class="language-bash">$ grafana-server --config=/usr/local/etc/grafana/grafana.ini --homepath /usr/local/share/grafana cfg:default.paths.logs=/usr/local/var/log/grafana cfg:default.paths.data=/usr/local/var/lib/grafana cfg:default.paths.plugins=/usr/local/var/lib/grafana/plugins
</code></pre>

<p>Grafana 默认监听在 3000 端口上，默认用户名和密码都是 <code>admin</code>。</p>

<h3 id="设置">设置</h3>

<p>输入用户名和密码以后，进入 Grafana 页面。第一件事是要设置数据源 (Data Source)，即 Grafana 从什么地方获取数据，选择 Prometheus 即可。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1fdll4hyc91j20sk0joaeg.jpg" alt="" /></p>

<p>数据源设置好以后，接下来就是创建 Dashboard 了。Dashboard 里面可以放置很多组件。比如，图表，状态值，表格，文字等等。这里我们选择 <code>Graph</code>图表，Grafana 会创建一个默认的空图表。</p>

<p>点击图表标题，选择 <code>Edit</code> 来编辑图表参数。最重要的参数就是 <code>Metrics</code> 标签里的 <code>Query</code>字段，这个字段定义了我们的图表到底要展示什么数据。输入 <code>rate(http_request_count{endpoint=&quot;/test&quot;}[10s])</code>，就可以看到 <code>/test</code> 路径的 QPS 曲线了。</p>

<p><img src="http://asset.cjting.cn/9b85365dgy1fdllazj0cvj20ya0k841q.jpg" alt="" /></p>

<p>同理，在 Query 中输入 <code>http_request_duration</code> 就可以得到响应时间曲线。通过使用 Prometheus 提供的操作符和函数，我们可以对数据进行我们想要的任意可视化，十分灵活。</p>

<p>在这两个工具的配合使用下，对服务器信息的监控变得非常简单。首先，服务器定义一个 HTTP 接口，暴露出想要监控的数据，然后使用 Prometheus 收集并存储这些数据，最后在 Grafana 中绘制这些数据。一个完整的监控方案就诞生了。</p>

<p>当然，在实际系统中，还缺少了一个环节，那就是报警。监控发现问题以后，需要马上报警通知相关的维护人员。这是另外一个话题了，以后再介绍。</p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>使用 Go 编写代码明信片生成器</title>
          <link>https://cjting.me/2017/02/18/write-a-code-post-generator-with-go/</link>
          <pubDate>Sat, 18 Feb 2017 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2017/02/18/write-a-code-post-generator-with-go/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/FpensV5yWTWbHKwENPRdEvUtEsYW.jpeg" class="webfeedsFeaturedVisual">

            <p>很早之前就看过到关于 <a href="http://commits.io">commits.io</a> 的一个帖子，这个站点专门制作代码明信片。什么是代码明信片呢？如下图。</p>

<p><img src="http://asset.cjting.cn/007FEWc7ly1g1f3o6zdtwj30sj0ee45m.jpg" alt="" /></p>

<p>背景是代码，然后中间印上指定的图案，就是一幅代码明信片了。看起来有点意思，将自己的得意作品做成一个代码明信片打印出来挂在办公室将是一个非常不错的装逼选择😉。</p>

<p>当时我就在想，这东西挺有意思，有空自己做一个，当然，事情一多也就忘记了。最近，我又看到了一个帖子，<a href="http://www.east5th.co/blog/2017/02/13/build-your-own-code-poster-with-elixir/">Build your own code poster with elixir</a>，是说怎样用 Elixir 来制作代码明信片的。Elixir 是我最近正在研究的语言，不过我觉得它不适合拿来干这个，这种程序，拿 Go 做一个 CLI 最爽，编译好了就可以发放给亲朋好友体验了。说干就干，再不能拖延了。</p>

<p>一个程序，无非是：输入、处理、输出。老话说的好，<strong>程序就是数据结构 + 算法</strong>。数据结构用来表示数据，算法用来处理数据。我们先来看看我们要开发的代码明信片程序的这三个方面分别是什么。</p>

<h2 id="输入">输入</h2>

<ul>
<li>首先我们需要代码，传递代码文件的路径是最为方便的，第一个确定，codePath，代码文件路径。</li>
<li>然后，我们需要图片，同样的道理，给一个图片路径是最为方便的，所以，第二个参数，imgPath，图片路径。</li>
</ul>

<p>光这两个参数行吗？当然不行。最终生成的代码明信片是多大？所以，又要加两个参数。width 表示代码明信片的宽度，height 表示代码明信片的高度。</p>

<p>这样就够了吗？看起来好像是够了。在程序开发过程中，一开始就将程序所需要的所有参数都定义完全的情况很少，一般在实现过程中发现不够了再补充。这里我们不妨先将思维转换到程序实现上。</p>

<p>程序的主要逻辑是遍历每个字符，计算字符的位置，然后得出这个位置在图片中的颜色即可，最终输出一个 HTML 文件由浏览器进行渲染。所以，问题来了，首先，每行有多少个字符？如果不知道这个，我们根本没法计算字符的坐标。所以，我们需要清楚的知道单个字符的宽度和高度，这就额外引出了四个参数：</p>

<ul>
<li>字符的字体（font），首先字体当然是要明确定义的，不同的字体下字符的宽度高度都不一样，而且代码明信片必须要等宽字体。</li>
<li>字符的字体大小（fontSize）。</li>
<li>单个字符的宽度（charWidth），这个只能手动去浏览器里测量，将字符放在 <code>span</code> 中，指定好字体和字体大小，用检查器就可以看到单个字符的宽度和高度。</li>
<li>单个字符的高度（charHeight），得出方法同字符宽度。</li>
</ul>

<p>这里，我使用 <code>Hack</code> 字体为例，可以看出，当字体选择 Hack，字体大小为 16.63px 像素时，单个字符的宽度是 10，高度是 19。</p>

<p><img src="http://asset.cjting.cn/007FEWc7ly1g1f3oef7bsj30mn0fgab6.jpg" alt="" /></p>

<p>最后，图片尺寸一般比代码明信片的尺寸要小，放在中央位置。所以，我们还需要一个背景颜色（bgColor），对于位置不在图片中的字符，应该填充背景色。</p>

<h2 id="输出">输出</h2>

<p>最终处理完毕后，以什么样的格式输出呢？作为一个整天和浏览器打交道的人，我觉得输出为一个 HTML 文件是最为方便的，直接交给浏览器去渲染。</p>

<p>输出为 HTML 也有多种选择。</p>

<ul>
<li>每一个字符放在一个元素中，然后给这个元素添加样式，也就是基于 DOM。</li>
<li>使用 Canvas 进行 2D 绘图。</li>
<li>使用 SVG。</li>
</ul>

<p>为什么要要先考虑输出呢？因为输出会影响程序的结构。在输入输出定义好的情况下，在去想程序实现是比较合理的，无论你怎么实现，只要输入输出不变，都不会影响用户的使用。</p>

<p>因为我们要支持输出多种格式，所以我们的核心程序一定是产生一个中间结果，然后再由不同的模块根据中间结果产生不同的输出。这就是输出对程序结构的影响。</p>

<h2 id="处理">处理</h2>

<p>最后，我们根据确定好的输入输出，来讨论程序具体的处理逻辑。</p>

<ol>
<li>根据代码路径（codePath），读取代码文件，压缩，去除掉所有的空白字符。</li>
<li>根据图片路径（imgPath），解析图片。</li>
<li>因为我们知道最终明信片的宽度（width）和高度（height），以及单个字符的宽度（charWidth）和高度（charHeight），我们可以得出一共有多少行字符以及每行多少列。</li>
<li>对于比明信片大的图片，需要对图片进行缩放。</li>
<li>从第一行开始遍历，根据字符的位置，得到字符的坐标，取出对应图片的颜色，如果字符不在图片范围内，则使用背景色（bgColor）。</li>
<li>将结果存入数组中保存，每一项的内容为：字符，颜色。</li>
<li>根据上面生成的数组，产生输出。</li>
</ol>

<p>到这里，程序的实现就很清楚了，借助于 Go 强大的标准库，需要我们编写的代码其实很少，作为一个周末项目练练手是非常不错的选择。</p>

<h2 id="结果">结果</h2>

<p>最终，程序在仓库在 Github 上，<a href="http://github.com/cj1128/codeposter">codeposter</a>。测试了几幅图片，效果还不错。默认使用的字体是 <code>Hack</code>，字体大小为 7 x 14，明信片宽度是 114 x 54。如果想提高字符的密度，也就是 <strong>分辨率</strong>，减少字体大小即可😜。</p>

<p><img src="http://asset.cjting.cn/007FEWc7ly1g1f3oqy7ldj30m80l4n55.jpg" alt="" /></p>

<p><img src="http://asset.cjting.cn/007FEWc7ly1g1f3ox5d2gj30m70l37ce.jpg" alt="" /></p>

<p><img src="http://asset.cjting.cn/007FEWc7ly1g1f3p3nf61j30m70l3wmc.jpg" alt="" /></p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>图床on七牛，简单好用的图床插件</title>
          <link>https://cjting.me/2017/01/23/build-an-img-bed-on-qiniu/</link>
          <pubDate>Mon, 23 Jan 2017 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2017/01/23/build-an-img-bed-on-qiniu/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/007FEWc7ly1g1f3uidzsqj31hc0goafm.jpg" class="webfeedsFeaturedVisual">

            <p>注：因为七牛 API 修改，编辑于 2019-03-25T16:20:00。</p>

<p>最近在使用过程中发现 <strong>图床on微博</strong> 出了点问题，响应体的 JSON 解析错误，不用想都知道肯定是微博修改了响应体的数据结构（微博图片上传接口响应体是 html 和 json 混在一起，十分专业）。简单修复了一下，测试的时候却发现，微博的图片上传接口变得不再稳定了，经常 404。看来微博图床是不能用了，正好我早就觉得微博不是个好图床，缺点如下：</p>

<ol>
<li>经常性的要重新登陆，麻烦死了</li>
<li>无法获取到完整的上传图片列表</li>
<li>无法删除上传的图片</li>
<li>服务状态不可控，指不定什么时候接口就不能用了</li>
</ol>

<p>要想对上传的图片拥有完全的控制权，那么图片一定要上传到自己能够控制的地方去。目前国内比较出名的免费存储空间提供商我所知的就是七牛了，简单看了看七牛的文档，做个图床没问题。用户可以创建免费空间，免费空间提供测试域名，限制如下：</p>

<ol>
<li>单 IP 每秒限制请求次数 10 次，大于 10 次禁止 5 秒</li>
<li>单 URL 限速 8 Mbps</li>
</ol>

<p>对于一个图床来说，这个限制完全够用了。</p>

<p>图床其实只需要两个核心接口：</p>

<ol>
<li>图片上传接口</li>
<li>图片获取接口</li>
</ol>

<p>至于图片删除什么的，当然七牛也提供，我个人觉得一个图床工具没必要这么麻烦了。</p>

<p>关于上传，七牛封装有现成的 SDK，比如 <a href="https://developer.qiniu.com/kodo/sdk/1283/javascript">JavaScript SDK</a>，这个 SDK 是基于 <a href="http://www.plupload.com/">Plupload</a> 做的，十分麻烦，提供了一大堆不需要的功能，我需要的就是简单的一个 POST 调用。</p>

<p>在文档中心里的 <a href="https://developer.qiniu.com/kodo/api/1731/api-overview">API 参考</a> 找了一下，找到了 <a href="https://developer.qiniu.com/kodo/api/1312/upload">直传文件 API</a>，接口定义如下。</p>

<pre><code class="language-bash">POST / HTTP/1.1
Host:           &lt;UpHost&gt;
Content-Type:   multipart/form-data; boundary=&lt;frontier&gt;
Content-Length: &lt;multipartContentLength&gt;
--&lt;frontier&gt;
Content-Disposition:       form-data; name=&quot;key&quot;
&lt;resource_key&gt;
--&lt;frontier&gt;
Content-Disposition:       form-data; name=&quot;x:&lt;custom_name&gt;&quot;
&lt;custom_value&gt;
--&lt;frontier&gt;
Content-Disposition:       form-data; name=&quot;token&quot;
&lt;upload_token&gt;
--&lt;frontier&gt;
Content-Disposition:       form-data; name=&quot;crc32&quot;
&lt;crc32&gt;
--&lt;frontier&gt;
Content-Disposition: form-data; name=&quot;x-qn-meta-&lt;metaKey&gt;&quot;
&lt;metaValue&gt;
--&lt;frontier&gt;
Content-Disposition:       form-data; name=&quot;accept&quot;
&lt;acceptContentType&gt;
--&lt;frontier&gt;
Content-Disposition:       form-data; name=&quot;file&quot;; filename=&quot;&lt;fileName&gt;&quot;
Content-Type:              application/octet-stream
Content-Transfer-Encoding: binary
&lt;fileBinaryData&gt;
</code></pre>

<p>一个使用 multipart 传参数的接口，虽然参数很多，但是必传参数只有 <code>upload_token</code>，<code>fileName</code> 以及 <code>fileBinaryData</code>。</p>

<p>关于上传凭证也就是 token 的生成，七牛的文档 <a href="https://developer.qiniu.com/kodo/manual/1208/upload-token">上传凭证</a> 说的很清楚，同时还提供了 <a href="http://jsfiddle.net/gh/get/extjs/4.2/icattlecoder/jsfiddle/tree/master/uptoken">JSFiddle 的在线示例</a>，真是业界良心，千言万语不如代码来的直接。</p>

<p>这里摘录一下最后我的实现。</p>

<pre><code class="language-javascript">function genUpToken(accessKey, secretKey, policy) {
  var policyStr = JSON.stringify(policy)
  var encoded = btoa(utf16to8(policyStr))
  var hash = CryptoJS.HmacSHA1(encoded, secretKey) // npm install crypto-js
  var encodedSign = hash.toString(CryptoJS.enc.Base64)
  var uploadToken = accessKey + &quot;:&quot; + safe64(encodedSign) + &quot;:&quot; + encoded
  return uploadToken
}

function utf16to8(str) {
  var out, i, len, c
  out = &quot;&quot;
  len = str.length
  for(i = 0; i &lt; len; i++) {
    c = str.charCodeAt(i)
    if ((c &gt;= 0x0001) &amp;&amp; (c &lt;= 0x007F)) {
      out += str.charAt(i)
    } else if (c &gt; 0x07FF) {
      out += String.fromCharCode(0xE0 | ((c &gt;&gt; 12) &amp; 0x0F))
      out += String.fromCharCode(0x80 | ((c &gt;&gt;  6) &amp; 0x3F))
      out += String.fromCharCode(0x80 | ((c &gt;&gt;  0) &amp; 0x3F))
    } else {
      out += String.fromCharCode(0xC0 | ((c &gt;&gt;  6) &amp; 0x1F))
      out += String.fromCharCode(0x80 | ((c &gt;&gt;  0) &amp; 0x3F))
    }
  }
  return out
}

function safe64(base64) {
  base64 = base64.replace(/\+/g, &quot;-&quot;)
  base64 = base64.replace(/\//g, &quot;_&quot;)
  return base64
}
</code></pre>

<p>好了，到此上传文件就搞定了。接下来我们看看该怎样获取所有上传的文件。七牛提供了 <a href="https://developer.qiniu.com/kodo/api/1284/list">资源列举</a> 这样的一个接口，听着名字应该就是我们要的，接口定义如下。</p>

<pre><code class="language-bash">GET /list?bucket=&lt;Bucket&gt;&amp;marker=&lt;Marker&gt;&amp;limit=&lt;Limit&gt;&amp;prefix=&lt;UrlEncodedPrefix&gt;&amp;delimiter=&lt;UrlEncodedDelimiter&gt; HTTP/1.1
Host:           rsf.qbox.me
Content-Type:   application/x-www-form-urlencoded
Authorization:  QBox &lt;AccessToken&gt;
</code></pre>

<p>这里又需要一个 token，放在 <code>Authorization</code> Header 里面的，叫做 <a href="https://developer.qiniu.com/kodo/manual/1201/access-token">管理凭证</a>。打开文档看了一下，不算麻烦。代码如下。</p>

<pre><code class="language-javascript">function genManageToken(accessKey, secretKey, pathAndQuery, body) {
  const str = pathAndQuery + &quot;\n&quot; + body
  const hash = CryptoJS.HmacSHA1(str, secretKey)
  const encodedSign = safe64(hash.toString(CryptoJS.enc.Base64))
  return accessKey + &quot;:&quot; + encodedSign
}
</code></pre>

<p>管理凭证生成好以后，将 bucket 参数携带上应该就可以了。最终图片获取的代码如下。</p>

<pre><code class="language-javascript">function fetch() {
  const path = &quot;/list?bucket=&quot; + getItem(&quot;bucket&quot;)
  return axios.post(&quot;http://rsf.qbox.me&quot; + path, null, {
    headers: {
      Authorization: &quot;QBox &quot; + genManageToken(
        getItem(&quot;accessKey&quot;),
        getItem(&quot;secretKey&quot;),
        path,
        &quot;&quot;,
      ),
    },
  })
}
</code></pre>

<p>到这里，核心功能就做好了，剩下的就是 UI 层面的事情，在 <em>图床on微博</em> 的基础上，将历史记录功能优化成了和 Unsplash 一样的三栏显示。最终效果如下所示，关于插件的安装使用仓库 README 中有详细说明，<a href="https://github.com/cj1128/pic-on-qiniu">仓库地址</a>。</p>

<p><img src="http://asset.cjting.cn/007FEWc7ly1g1f3v5j3f4g31810jcnpd.gif" alt="" /></p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>使用 pprof 优化 Golang 性能</title>
          <link>https://cjting.me/2016/11/14/use-pprof-to-optimize-go/</link>
          <pubDate>Mon, 14 Nov 2016 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2016/11/14/use-pprof-to-optimize-go/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/9b85365djw1f9xjicmnn713r0p178e.jpg" class="webfeedsFeaturedVisual">

            <p><em>Donald E.Knuth</em> 说过一句非常著名的话，<strong>过早的优化是万恶之源</strong>，原文如下：</p>

<blockquote>
<p>We should forget about small efficiencies, say about 97% of the time; premature optimization is the root of all evil.</p>
</blockquote>

<p>我是十分赞同这句话的，并且在开发过程中也深有体会。什么叫做 <em>过早的优化</em> 呢？即不需要考虑优化的时候你在考虑优化。这绝对不意味着可以任性地写代码，随意地选择数据结构和算法。这句话是告诉我们，在程序开发的早期阶段，程序员应该专注在程序的 <strong>逻辑实现</strong> 上，而不是专注在程序的 <strong>性能优化</strong> 上。用正确的数据结构和算法，优美合理的语句实现你要的功能。而不是满脑子在想：“这个函数是不是可以优化一下？”。</p>

<p>我们都知道，性能最好的代码往往并不是优美直观的代码，往往看起来非常晦涩。下图是 JS 转换字符串到数字的三个方法在 Chrome 下的性能对比。可以看出，<code>+</code> 是最快的方法。但是 <code>+str</code> 这种写法明显是不如 <code>parseInt(str)</code> 或者是 <code>Number(str)</code> 容易理解。<em>Donald E.Knuth</em> 的那句话，我的理解就是在提醒我们，不用使用 <code>+str</code>，而应该使用更加语义化的 <code>parseInt(str)</code>。</p>

<p><img src="http://asset.cjting.cn/9b85365dgw1f9xaluvkarj20qp0733zq.jpg" alt="" /></p>

<p>不应该过早的优化，那么应该做的就是在适当的时候进行优化。程序在功能开发完毕并且测试好以后，就可以进入优化环节了。所有的优化都应该基于性能分析（Profiling），凭空想象进行优化是一件很危险并且没有效率的事情。很多你觉得可以优化的点说不定编译器早替你做了，很多你觉得很慢的地方说不定非常快。</p>

<p>Golang 提供了非常棒的 Profiling 工具，可以很容易地得到 CPU 和内存的 Profiling 数据。更加赞的是，Golang 还提供了工具来可视化这些数据，一眼就可以看出程序的性能瓶颈在哪儿，调优从未如此轻松。</p>

<h2 id="package-pprof">Package pprof</h2>

<p>Golang 标准库里，有一个叫做 <code>pprof</code> 的包，通过这个包，我们可以 profiling 任意的程序，两个函数调用即可。</p>

<pre><code class="language-golang">func main() {
  ....
  f, err := os.Create(&quot;cpu-profile.prof&quot;)
  if err != nil {
    log.Fatal(err)
  }
  pprof.StartCPUProfile(f)
  ... // this is program you want to profile
  pprof.StopCPUProfile()
}
</code></pre>

<p>程序运行后，pprof 会将 Profiling 数据写到指定的文件当中，然后通过 <code>go tool pprof</code>就可以查看。</p>

<p>我们来 Profiling 一个简单的 Fibonacci 程序。</p>

<pre><code class="language-golang">package main

import (
	&quot;fmt&quot;
	&quot;log&quot;
	&quot;os&quot;
	&quot;runtime/pprof&quot;
)

func main() {
	f, err := os.Create(&quot;cpu-profile.prof&quot;)
	if err != nil {
		log.Fatal(err)
	}
	pprof.StartCPUProfile(f)
	fmt.Println(fibonacci(45))
	pprof.StopCPUProfile()
}

func fibonacci(n int) int {
	if n &lt; 2 {
		return n
	}
	return fibonacci(n-1) + fibonacci(n-2)
}
</code></pre>

<p>编译以后，运行程序便可以生成 <code>cpu-profile.prof</code> 文件。使用 <code>go tool pprof finabocci cpu-profile.prof</code> 进入 Profiling 控制台，输入<code>web</code> 指令跳入浏览器中查看 Golang 为我们生成的可视化性能数据。</p>

<p><img src="http://asset.cjting.cn/9b85365djw1f9xgcymlqpj20zo0h3jvw.jpg" alt="" /></p>

<h2 id="benchmark-test">Benchmark Test</h2>

<p>每一次都手动引入 <code>pprof</code> 包比较麻烦，也没有必要。一般 Golang 的性能测试我们会使用 Golang 提供的 Benchmark 功能，Golang 提供了命令行参数我们可以直接得到测试文件中 Benchmark 的 Profiling 数据。不需要添加任何代码。</p>

<p>下面我们来写一个 Benchmark 测试一下 Golang 的标准库函数 <code>rand.Intn</code> 的性能如何。</p>

<pre><code class="language-golang">package main

import (
	&quot;math/rand&quot;
	&quot;testing&quot;
)

func BenchmarkRandom(b *testing.B) {
	for i := 0; i &lt; b.N; i++ {
		random()
	}
}

func random() int {
	return rand.Intn(100)
}

</code></pre>

<p>因为 pprof 需要编译好的二进制文件以及 prof 文件一起才可以分析，所以先要编译这一段测试程序。</p>

<pre><code class="language-bash">$ go test -c go_test.go
$ ./main.test -test.bench=. -test.cpuprofile=cpu-profile.prof
testing: warning: no tests to run
BenchmarkRandom-8       50000000                30.5 ns/op
</code></pre>

<p>可以看出 Go 标准库的 <code>rand.Intn</code> 性能很好，测试运行完毕以后，我们也得到了相应的 CPU Profiling 数据。使用 <code>go tool pprof</code> 打开以后，使用 <code>top 5</code> 指令得到开销排名前五的函数。五个里面有两个是 <code>sync/atomic</code> 包的函数，很明显，<code>rant.Intn</code> 是并发安全的。</p>

<pre><code class="language-bash">$ go tool pprof main.test cpu-profile.prof
(pprof) top 5
780ms of 1370ms total (56.93%)
Showing top 5 nodes out of 35 (cum &gt;= 610ms)
      flat  flat%   sum%        cum   cum%
     270ms 19.71% 19.71%      270ms 19.71%  runtime.usleep
     170ms 12.41% 32.12%      840ms 61.31%  math/rand.(*Rand).Int31n
     150ms 10.95% 43.07%      150ms 10.95%  sync/atomic.AddUint32
     110ms  8.03% 51.09%      110ms  8.03%  sync/atomic.CompareAndSwapUint32
      80ms  5.84% 56.93%      610ms 44.53%  math/rand.(*Rand).Int63
</code></pre>

<h2 id="example-sudoku">Example Sudoku</h2>

<p>下面我用 <a href="https://github.com/paddie/godoku">Godoku</a> 这个项目为例，看看怎么具体优化一个程序。Godoku 是一个 Go 编写的暴力破解数独的程序，逻辑比较简单，从上到下从左到右扫描每一个空格，从 1 到 9 开始填写数字，一旦数字无效（行冲突，列冲突或者 9 宫格冲突），那么就换一个数字，如果所有数字都换了还无效，那么就退回上一个格子，继续这个过程。</p>

<h3 id="step1">Step1</h3>

<p>程序自带了测试和 Benchmark，所以我们先来生成一个 Profiling 文件，看看哪个地方开销最大。</p>

<p><img src="http://asset.cjting.cn/9b85365dgw1f9xhhnlv05j20s70mcafx.jpg" alt="" /></p>

<p>很明显，<code>ValidInSquare</code>这个函数开销很大，这个函数是检测一个数字在九宫格里面存不存在，作者的实现如下。</p>

<pre><code class="language-golang">func (s *Sudoku) ValidInSquare(row, col, val int) bool {
	row, col = int(row/3)*3, int(col/3)*3

	for i := row; i &lt; row+3; i++ {
		for j := col; j &lt; col+3; j++ {
			//fmt.Printf(&quot;row, col = %v, %v\n&quot;, i, j)
			if s.board[i][j] == val {
				return false
			}
		}
	}
	return true
}
</code></pre>

<p>循环判断有没有这个数，逻辑很简单，但是 Profiling 告诉我们，这里成了性能瓶颈，每一次测试数字都要调用这个方法，而这个方法内部是一个循环，调用如此频繁的方法采用循环肯定是不行的。</p>

<h3 id="step2">Step2</h3>

<p>这里我们采用经典的 <strong>空间换时间</strong> 思路，使用另外一个结构存储九宫格内的状态信息，使得查询一个数字在九宫格内有没有可以通过简单的数组访问得到。</p>

<pre><code class="language-golang">s.regionInfo = make([]int, s.dim * s.dim / 9)

func (s *Sudoku) updateRegion(row, col, val, delta int) {
	region := (row/3)*3 + col/3
	key := region*9 + val - 1
	s.regionInfo[key] += delta
}

func (s *Sudoku) checkRegion(row, col, val int) bool {
	region := (row/3)*3 + col/3
	key := region*9 + val - 1
	return s.regionInfo[key] == 1
}
</code></pre>

<p>我们使用一个额外的 <code>regionInfo</code> slice 来存储九宫格里的情况，每一次设置数独中格子的值时，我们更新一下 regionInfo 的信息。当要检查某个数在某个九宫格中是否已经存在时，直接查询 regionInfo 即可。</p>

<pre><code class="language-golang">func (s *Sudoku) ValidInSquare(row, col, val int) bool {
	return !s.checkRegion(row, col, val)
}
</code></pre>

<p>再运行一次测试，看看性能改善了多少。</p>

<p><img src="http://asset.cjting.cn/9b85365dgw1f9xhx008q9j212g0m3q8x.jpg" alt="" /></p>

<p>很好！CPU 开销已经由 9770ms 降低到了 5460ms，性能提高 79%。现在程序的性能瓶颈已经是 <code>ValidInColumnAndRow</code> 这个函数了。</p>

<h3 id="step3">Step3</h3>

<p>作者 <code>ValidInColumnAndRow</code> 函数的实现仍然是直观简单的循环。</p>

<pre><code class="language-golang">func (s *Sudoku) ValidInColumnAndRow(row, col, val int) bool {
	for i := 0; i &lt; 9; i++ {
		if s.board[row][i] == val ||
			s.board[i][col] == val {
			return false
		}
	}
	return true
}
</code></pre>

<p>我们使用同样的策略来优化 <code>ValidInColumnAndRow</code> 这个函数，使用额外的数据结构存储每一行和每一列的数字状态信息。这样查询时可以马上返回，而不需要做任何循环比较。</p>

<pre><code class="language-golang">func (s *Sudoku) updateRowAndCol(row, col, val, delta int) {
	rowKey := row*9 + val - 1
	colKey := col*9 + val - 1
	s.rowInfo[rowKey] += delta
	s.colInfo[colKey] += delta
}

func (s *Sudoku) checkRowOrCol(row, col, val int) bool {
	rowKey := row*9 + val - 1
	colKey := col*9 + val - 1
	return s.rowInfo[rowKey] == 1 || s.colInfo[colKey] == 1
}
func (s *Sudoku) ValidInColumnAndRow(row, col, val int) bool {
	return !s.checkRowOrCol(row, col, val)
}
</code></pre>

<p>我们再来看看 Profiling 数据。</p>

<p><img src="http://asset.cjting.cn/9b85365dgw1f9xi9qhf6uj211m0idjvs.jpg" alt="" /></p>

<p>性能再次得到了提升，由 5460ms 降低到了 3610ms。初步看来，已经没有了明显可以优化的地方了。到此为止，我们的程序性能已经得到了 170% 的提升！我们并没有怎么努力，只不过是生成了 Profiling 文件，一眼看出问题在哪儿，然后针对性地优化而已。</p>

<p>感谢 Golang 提供了这套超赞的 pprof 工具，性能调优变得如此轻松和愉悦。这里我所举的只是 pprof 功能的冰山一角，pprof 的强大功能远不止这些。比如可以使用 <code>list</code> 指令查看函数的源码中每一行代码的开销以及使用 <code>weblist</code> 指令查看函数汇编以后每一句汇编指令的开销等等。不仅是 CPU Profiling，pprof 同样支持 Memory Profiling，可以帮助你检查程序中内存的分配情况。总之，在 pprof 的帮助下，程序的开销信息变得一清二楚，优化自然变得轻而易举。</p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>使用 SVG Morphing 制作自己的加载动画</title>
          <link>https://cjting.me/2016/11/07/make-loading-animation-with-svg-morphing/</link>
          <pubDate>Mon, 07 Nov 2016 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2016/11/07/make-loading-animation-with-svg-morphing/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/9b85365djw1f9ji109m0jj21jk0rstb8.jpg" class="webfeedsFeaturedVisual">

            <p>每一个需要让用户等待的应用都应该有加载界面，可以是简单的文本，比如 <code>加载中…</code>，也可以是有趣的动画。当然，一个好玩的加载动画能够大大增加用户等待的耐心，谁喜欢枯燥的文字呢。所以，投入点时间寻找或者制作一个加载动画是很有意义的。感谢 SVG 和相关的动画技术，现在制作一款复杂的动画已经变得十分容易了。</p>

<p>这里我使用 SVG 的形变技术（Shape Morphing）来做一个简单的矩形、三角形、圆形变换的动画。</p>

<p><p data-height="500" data-theme-id="light" data-slug-hash="QGwMXP" data-default-tab="result" data-user="fatelovely" data-embed-version="2" data-pen-title="SVG Morphing Loading Animation" class="codepen">See the Pen <a href="http://codepen.io/fatelovely/pen/QGwMXP/">SVG Morphing Loading Animation</a> by fatelovely (<a href="http://codepen.io/fatelovely">@fatelovely</a>) on <a href="http://codepen.io">CodePen</a>.</p>
<script async src="https://production-assets.codepen.io/assets/embed/ei.js"></script></p>

<h2 id="svg-shape-morphing">SVG Shape Morphing</h2>

<p>上面的动画里，有三个量在变换。图形的形状，图形的位置以及颜色。位置和颜色都是比较简单的，CSS Transition 就可以搞定。问题就是形状的变化比较复杂。形变技术理解起来比较简单，图形从一个形状变换到另一个形状，无非就是构成图形的顶点位置发生了变化。所以，只要将开始图形和结束图形的顶点之间的对应关系找到，然后对顶点进行 transition 就行了。从这可以看出，SVG 的形变必须要求开始图形和结束图形的顶点数一定要相同，如下所示。</p>

<p><img src="http://asset.cjting.cn/9b85365dgw1f9jdl0i3e2g20a008gh6t.gif" alt="" /></p>

<p><p data-height="500" data-theme-id="light" data-slug-hash="XNJBOy" data-default-tab="result" data-user="fatelovely" data-embed-version="2" data-pen-title="SVG Morphing Demo" class="codepen">See the Pen <a href="http://codepen.io/fatelovely/pen/XNJBOy/">SVG Morphing Demo</a> by fatelovely (<a href="http://codepen.io/fatelovely">@fatelovely</a>) on <a href="http://codepen.io">CodePen</a>.</p>
<script async src="https://production-assets.codepen.io/assets/embed/ei.js"></script></p>

<h2 id="gsap">GSAP</h2>

<p>SVG 的形变有两种方式，第一是使用 *SMIL*，第二是使用 JS 库。SMIL 目前已经被废弃，这里我们使用大名鼎鼎的 <a href="http://greensock.com/gsap">GreenSock Animation Platform, GSAP</a> 动画库来实现。GSAP 是一个非常高级的动画库，功能强大接口简洁，我们使用 <a href="https://greensock.com/morphSVG">MorphSVGPlugin</a> 插件来完成 SVG 的形变功能。</p>

<p>上面我说过，SVG 的形变动画要求开始图形和结束图形顶点数一样，但这并不意味着我们提供给 GSAP 的开始图形和结束图形顶点数必须一致。GSAP 的一大特点便是允许我们提供顶点数完全不一样的图形来进行形状变换，GSAP 内部会自己计算顶点并进行 transition。</p>

<p>使用 GSAP 进行 SVG 形变非常简单，指定开始图形，指定结束图形以及顶点映射关系即可。顶点映射关系表示开始图形的哪一个顶点对应结束图形的第一个顶点，后面的顶点按顺序类推。</p>

<p>关于顶点映射关系的问题，可以使用 GSAP 官方提供的一个工具 <a href="http://codepen.io/GreenSock/pen/LpxOqR">findShapeIndex</a> 来查看效果，非常直观。</p>

<p>下面的代码表示从 <code>startShape</code> 形变到 <code>endShape</code> ，时间为 1 秒钟，同时开始图形的第三个顶点对应结束图形的第一个顶点。</p>

<pre><code class="language-javascript">var stratShape = document.getElementById(&quot;start&quot;)
var endShape = document.getElementById(&quot;end&quot;)

TweenLite.to(endShape, 1, {
  morphSVG: endShape,
  shapeIndex: 2,
})
</code></pre>

<h2 id="loading-animation">Loading Animation</h2>

<p>根据上面的知识，我们来制作一个矩形、三角形、圆形之间的形变动画就变得非常简单了。首先，定义这三个图形，这里图形的位置都在 <code>0,0,100,100</code> 之间。注意隐藏 <code>triangle</code> 以及 <code>circle</code> ，只显示 <code>rect</code>。</p>

<pre><code class="language-html"> &lt;path id=&quot;rect&quot; fill=&quot;#1EB287&quot; d=&quot;M 0,0
                   C 50,0 50,0 100,0
                   100,50 100,50 100,100
                   50,100 50,100 0,100
                   0,50 0,50 0,0
                   Z&quot;&gt;&lt;/path&gt;

&lt;path id=&quot;triangle&quot; fill=&quot;#188fc2&quot; d=&quot;M 25,50
                   C 37.5,25 37.5,25 50,0
                   75,50 75,50 100,100
                   50,100 50,100 0,100
                   12.5,75 12.5,75 25,50
                   Z&quot;&gt;&lt;/path&gt;
&lt;path id=&quot;circle&quot; fill=&quot;#bb625e&quot; d=&quot;M 50,0
                   C 77.6,0 100,22.4 100,50
                   100,77.6 77.6,100 50,100
                   22.4,100, 0,77.6, 0,50
                   0,22.4, 22.4,0, 50,0
                   Z&quot;&gt;&lt;/path&gt;
</code></pre>

<p>然后，使用 GSAP 进行变换即可，因为涉及到一系列变换，矩形到三角形，三角形到圆形，圆形到矩形，我们使用 GSAP 提供的 <code>TimelineLite</code> 来调度时间使这三个变换顺序进行。</p>

<pre><code class="language-javascript">var tl = new TimelineLite()
var duration = 1
tl.to(rect, duration, {
  morphSVG: triangle,
})
tl.to(rect, duration, {
  morphSVG: circle,
})
tl.to(rect, duration, {
  morphSVG: rect,
})
</code></pre>

<p>到了这里，形变就已经完成了。但是还缺少了颜色变换和位置变换。颜色和位置变换需要使用 GSAP 的 CSS 插件，增加一点代码即可，这里不再赘述了。</p>

<h2 id="导出为-gif">导出为 GIF</h2>

<p>SVG 的动画做好了，但并不是所有的平台都支持 SVG，并且每次使用动画都要加载一堆库和一堆代码也比较麻烦。最好的解决方案是导出为 GIF。</p>

<p>比较简单的方法是使用 <a href="http://www.cockos.com/licecap/">LICEcap</a> 软件直接录制浏览器屏幕生成 GIF，缺点是控制度不高，不好微调。</p>

<p>这里我使用 <a href="www.nightmarejs.org">Nightmare</a> 渲染我们的文档，然后自己截屏，最后合成为 GIF。</p>

<p>Nightmare 是类似 Phantom 的一个 Headless Browser，特别适合这种类型的任务，优点是代码比 Phantom 要简洁。</p>

<pre><code class="language-javascript">var Nightmare = require(&quot;nightmare&quot;)
var nightmare = new Nightmare({
  width: 400,
  height: 400,
  titleBarStyle: &quot;hidden&quot;, // 影藏标题栏，这样内容区和视口一样大
})
  .goto(&quot;http://localhost:8080&quot;) // 这是我们的动画页面
  .wait(1000)

for(var i = 0; i &lt; 60; i++) {
  nightmare.screenshot(&quot;loading/loading_&quot; + i + &quot;.png&quot;)
  nightmare.wait(16.6)
})

nightmare.run(function(err) {
  if(err) {
    console.log(err)
  } else {
    console.log(&quot;Done&quot;)
  }
})
</code></pre>

<p>运行以后，可以在 loading 文件夹里面看到所有截屏出来的图片，将多余的图片剔除掉以后，上传到 <a href="http://gifcreator.me/">gifcreator</a> 上，调整一下速度，然后导出即可。</p>

<p><img src="http://asset.cjting.cn/9b85365djw1f9jheun5t8j20rt0r60yg.jpg" alt="" /></p>

<p>最终，GIF 效果如下。</p>

<p><img width="100" src="http://asset.cjting.cn/9b85365djw1f9jhfdkgy8g20b40b4wfc.gif"></p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>从零开始搭建一个 ELKB 日志收集系统</title>
          <link>https://cjting.me/2016/10/21/build-log-system-with-elkb/</link>
          <pubDate>Fri, 21 Oct 2016 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2016/10/21/build-log-system-with-elkb/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/9b85365dgw1f8qjr6igesj21kw0w7ac4.jpg" class="webfeedsFeaturedVisual">

            <p>当今的软件开发 <strong>多核</strong> 以及 <strong>分布</strong> 已经成为了常态，基本上稍大型的应用都是多台机器分布式部署。分布式在提高性能的同时也带来了很多问题，今天我们只讨论一点，那就是如何处理多台机器线上系统的日志。</p>

<p>以我司的某个应用 T 为例，部署在了百度云 5 台机子上，其中一台拥有公网 IP，使用了百度云提供的负载均衡服务。每次想要在日志中检索某个关键字时，基本步骤如下：</p>

<ul>
<li>打开五个 SSH，登陆拥有公网 IP 的那台机器</li>
<li>在另外四个 SSH 中分别登陆其他的内网机器</li>
<li>对日志文件进行检索</li>
</ul>

<p>当然，我们可以写脚本来简化这个过程，或者使用类似 <em>cssh</em> 这样的工具。但是成功登陆到五台机器上只是任务的开始，接下来我们要手动选择我们希望检索的日志（日志按照日期进行存储），使用 grep 进行检索，然后还要在五个 SSH 上一个一个地看结果。如果有一个稍微高级的需求，比如检查某个关键词是否在昨天和今天的日志中都出现过，任务会变得十分麻烦，而且使用 Shell 非常容易出错。</p>

<p>从这个过程中就可以总结出分布式系统日志处理的需求，我希望有这么个日志处理系统，有以下几个功能：</p>

<ul>
<li>将多台机器上的日志收集到一台机器上。这样我在一个地方就可以看到所有的日志。</li>
<li>按照我指定的格式分析日志。日志肯定要解析的，最基本的日志也都要分为时间戳和内容。</li>
<li>有一个漂亮的界面能够让我查看日志和搜索日志。现在是 21 世纪了，谁也不想一天到晚用终端来完成任务。</li>
</ul>

<p>幸运地是，<a href="https://www.elastic.co/">Elastic</a> 提供了一套非常高级的工具 <code>ELKB</code> 来满足以上这几个需求。<code>ELKB</code> 指的是用于日志分析或者说数据分析的四个软件，各自拥有独立的功能又可以组合在一起。先来简单介绍一下这四个软件。</p>

<ul>
<li><code>Elastic Search</code>: 从名称可以看出，Elastic Search 是用来进行搜索的，提供数据以及相应的配置信息（什么字段是什么数据类型，哪些字段可以检索等），然后你就可以自由地使用 API 搜索你的数据。</li>
<li><code>Logstash</code>: 日志文件基本上都是每行一条，每一条里面有各种信息，这个软件的功能是将每条日志解析为各个字段。</li>
<li><code>Kibana</code>: 提供一套 Web 界面用来和 Elastic Search 进行交互，这样我们不用使用 API 来检索数据了，可以直接在 Kibana 中输入关键字，Kibana 会将返回的数据呈现给我们，当然，有很多漂亮的数据可视化图表可供选择。</li>
<li><code>Beats</code>: 安装在每台需要收集日志的服务器上，将日志发送给 Logstash 进行处理，所以 Beats 是一个“搬运工”，将你的日志搬运到日志收集服务器上。</li>
</ul>

<h2 id="安装">安装</h2>

<p>这里使用 CentOS 7 为例来说明怎么装这几个软件。其中 ELK 只需要安装在进行日志收集分析的服务器（server）上，而Beats是每一台产生日志的机器（client）都需要安装，当然也可能包括日志收集服务器本身。</p>

<h3 id="java">Java</h3>

<pre><code class="language-shell">$ yum install java-1.8.0
</code></pre>

<h3 id="ealstic-search">Ealstic Search</h3>

<pre><code class="language-shell">$ rpm --import http://packages.elastic.co/GPG-KEY-elasticsearch
$ echo '[elasticsearch-2.x]
name=Elasticsearch repository for 2.x packages
baseurl=http://packages.elastic.co/elasticsearch/2.x/centos
gpgcheck=1
gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch
enabled=1
' | tee /etc/yum.repos.d/elasticsearch.repo
$ yum install elasticsearch
</code></pre>

<h3 id="logstash">Logstash</h3>

<pre><code class="language-shell">$ vim /etc/yum.repos.d/logstash.repo
# 添加以下内容
[logstash-2.4]
name=logstash repository for 2.2 packages
baseurl=http://packages.elasticsearch.org/logstash/2.2/centos
gpgcheck=1
gpgkey=http://packages.elasticsearch.org/GPG-KEY-elasticsearch
enabled=1
# 安装
$ yum install logstash
</code></pre>

<h3 id="kibana">Kibana</h3>

<pre><code class="language-shell">$ vim /etc/yum.repos.d/kibana.repo
# 添加以下内容
[kibana-4.6]
name=Kibana repository for 4.4.x packages
baseurl=http://packages.elastic.co/kibana/4.4/centos
gpgcheck=1
gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch
enabled=1
# 安装
$ yum install kibana
</code></pre>

<h3 id="beats">Beats</h3>

<p>Beats 分为很多种，每一种收集特定的信息。常用的是 <code>Filebeat</code>，监听文件变化，传送文件内容。一般日志系统使用 Filebeat 就够了。</p>

<p>我们切换到 client 上。首先同样需要导入 <code>GPG KEY</code>。</p>

<pre><code class="language-shell">$ rpm --import http://packages.elastic.co/GPG-KEY-elasticsearch
</code></pre>

<p>创建新的 repo 并安装。</p>

<pre><code class="language-shell">$ vim /etc/yum.repos.d/elastic-beats.repo
# 添加以下内容
[beats]
name=Elastic Beats Repository
baseurl=https://packages.elastic.co/beats/yum/el/$basearch
enabled=1
gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearch
gpgcheck=1
# 安装
$ yum install filebeat
</code></pre>

<h2 id="elastic-search">Elastic Search</h2>

<p>Elastic Search 不需要太多配置，只需要阻止一下外网访问即可。修改配置文件 <code>/etc/elasticsearch/elasticsearch.yml</code>。</p>

<pre><code class="language-shell">network.host: localhost
</code></pre>

<p>启动 Elastic Search: <code>service elasticsearch start</code>。</p>

<p>Elastic Search 本身可以认为是一个 NoSQL 数据库，通过 REST API 来操作。数据存储在 <code>Index</code> 中，Index 在 Elastic Search 中就相当于 SQL 中的表。因为 Elastci Search 主要是用来对数据进行检索，所以 Index 有一个配置叫做 <code>mapping</code>。我们使用 mapping 来告诉 Elastic Search 数据的一些相关信息，比如，某个字段是什么数据类型，是否创建索引等。我们先来玩玩 Elastic Search，使用官方提供的<a href="https://www.elastic.co/guide/en/kibana/3.0/snippets/shakespeare.json">莎士比亚数据集</a>为例。</p>

<pre><code class="language-shell">$ curl localhost:9200/_cat/indices?v # 查看当前所有的 index
health status index pri rep docs.count docs.deleted store.size pri.store.size # 没有任何 index
# 创建 shakespeare 索引，并设置 mapping 信息
# speaker 字段和 play_name 不需要分析，Elastic Search 默认会拆分字符串中的每个词并进行索引
$ curl -XPUT http://localhost:9200/shakespeare -d '
{
 &quot;mappings&quot; : {
  &quot;_default_&quot; : {
   &quot;properties&quot; : {
    &quot;speaker&quot; : {&quot;type&quot;: &quot;string&quot;, &quot;index&quot; : &quot;not_analyzed&quot; },
    &quot;play_name&quot; : {&quot;type&quot;: &quot;string&quot;, &quot;index&quot; : &quot;not_analyzed&quot; },
    &quot;line_id&quot; : { &quot;type&quot; : &quot;integer&quot; },
    &quot;speech_number&quot; : { &quot;type&quot; : &quot;integer&quot; }
   }
  }
 }
}
';
$ curl localhost:9200/_cat/indices?v # 查看索引
health status index       pri rep docs.count docs.deleted store.size pri.store.size
yellow open   shakespeare   5   1          0            0       260b           260b
# 下载数据，并将数据集 load 进索引中
$ wget https://www.elastic.co/guide/en/kibana/3.0/snippets/shakespeare.json
$ curl -XPOST 'localhost:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json
# 以上操作完成后，Elastic Search 中就已经有了我们 load 的所有数据，并建立好了索引，我们可以开始查询了
# 查询一下含有 'man' 这个词的 text_entry
$ curl -s 'localhost:9200/shakespeare/_search?q=text_entry:man&amp;pretty=1&amp;size=20' | jq '.hits.hits | .[]._source.text_entry'
&quot;man.&quot;
&quot;Man?&quot;
&quot;man.&quot;
&quot;Why, man?&quot;
&quot;Worthy man!&quot;
&quot;Every man,&quot;
&quot;complete man.&quot;
&quot;married man?&quot;
&quot;melancholy man.&quot;
&quot;Speak, man.&quot;
&quot;Why, man?&quot;
&quot;What, man?&quot;
&quot;prave man.&quot;
&quot;Speak, man.&quot;
&quot;Why, man?&quot;
&quot;So man and man should be;&quot;
&quot;O, the difference of man and man!&quot;
&quot;The young man is an honest man.&quot;
&quot;A gross fat man.&quot;
&quot;plain-dealing man?&quot;
</code></pre>

<p>下面我们通过解析 Nginx 的访问日志来说明怎么配合使用 ELKB。</p>

<h2 id="解析-nginx-访问日志">解析 Nginx 访问日志</h2>

<p>整个过程的流程比较简单，Filebeat 收集日志传送给 Logstash，Logstash 解析好了以后，写入到 Elastic Search 中，最后我们使用 Kibana 来查看这些日志并进行检索。</p>

<h3 id="filebeat">Filebeat</h3>

<p>首先切换到 client 上，我们来配置 Filebeat。</p>

<pre><code class="language-shell">$ vim /etc/filebeat/filebeat.yml
...
prospectors:
  -
    paths:
      - /var/log/nginx/access.log
    # 找到 document_type 字段，取消注释，这个字段会告诉 Logstash 日志的类型，对应 Logstash 中的 type 字段
    document_type: nginx
...
# 默认输出为 Elastic Search，注释掉，使用 Logstash
logstash:
  hosts: [&quot;IP:5044&quot;] # 注意更改这里的 IP
</code></pre>

<h3 id="logstash-1">Logstash</h3>

<p>Logstash 的配置相对麻烦一下，因为 Logstash 需要接受输入，进行处理然后产生输出。Logstash 采用 <code>input</code>, <code>filter</code>, <code>output</code> 的三段配置法。input 配置输入源，filter 配置对输入源中的信息怎样进行处理，而 output 配置输出位置。</p>

<p>一般情况下，input 为 beat，filter 中我们解析 input 获取到的日志，得到我们想要的字段，而output 为 Elastic Search。这里我们以 Nginx 的访问日志为例。filter 中有一个关键的东西叫做 <code>grok</code>，我们使用这个东西来解析日志结构。Logstash 提供了一些默认的 <a href="https://github.com/elastic/logstash/blob/v1.4.2/patterns/grok-patterns">Pattern</a>，方便我们解析用。当然，我们也可以自己用正则来自定义 pattern 匹配日志内容。</p>

<pre><code class="language-shell">$ vim /etc/logstash/conf.d/nginx.conf
input {
  beats {
    port =&gt; 5044
  }
}

filter {
  if [type] == &quot;nginx&quot; { # 这里的type是日志类型，我们在后面的filebeat中设定
    grok {
      match =&gt; { &quot;message&quot; =&gt; &quot;%{COMBINEDAPACHELOG} %{QS:gzip_ratio}&quot; } # 使用自带的pattern即可，注意空格
      remove_field =&gt; [&quot;beat&quot;, &quot;input_type&quot;, &quot;message&quot;, &quot;offset&quot;, &quot;tags&quot;] # filebeat添加的字段，我们不需要
    }
    
    # 更改匹配到的字段的数据类型
    mutate {
      convert =&gt; [&quot;response&quot;, &quot;integer&quot;]
      convert =&gt; [&quot;bytes&quot;, &quot;integer&quot;]
      convert =&gt; [&quot;responsetime&quot;, &quot;float&quot;]
    }
    
    # 指定时间戳字段以及具体的格式
    date {
      match =&gt; [&quot;timestamp&quot;, &quot;dd/MMM/YYYY:HH:mm:ss Z&quot;]
      remove_field =&gt; [&quot;timestamp&quot;]
    }
  }
}

outpugst {
  elasticsearch {
    hosts =&gt; [ &quot;localhost:9200&quot; ]
    index =&gt; &quot;%{type}-%{+YYYY.MM.dd}&quot; # index 中含有时间戳
  }
}
</code></pre>

<p><code>service logstash start</code> 启动 Logstash 即可，注意，他的启动速度很慢。</p>

<h3 id="elastcisearch">Elastcisearch</h3>

<p>上面的 Logstash 配置中，我们可以看到最终写入 Elastic Search 的 Index 含有时间戳，这是比较推荐的做法。因为可以方便我们按天对数据进行分析。关于 Elastic Search 我们只要配置一下 Index 的 Mapping 信息即可。因为我们的 Index 是按天生成的，每天都是一个新的 Index，那当然不可能每天都配置一次 Index 的 Mapping。这里需要使用 Elastic Search 的一个功能，<code>Index Template</code>，我们可以创建一个 Index 的配置模板，使用这个模板来配置所有匹配的 Index。</p>

<pre><code class="language-shell">curl -XPUT localhost:9200/_template/nginx -d '
{
  &quot;template&quot;: &quot;nginx*&quot;,
  &quot;mappings&quot;: {
    &quot;_default_&quot;: {
      &quot;properties&quot;: {
        &quot;clientip&quot;: {
          &quot;type&quot;: &quot;string&quot;,
          &quot;index&quot;: &quot;not_analyzed&quot;
        },
        &quot;ident&quot;: {
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;auth&quot;: {
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;verb&quot;: {
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;request&quot;: {
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;httpversion&quot;: {
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;rawrequest&quot;: {
          &quot;type&quot;: &quot;string&quot; 
        },
        &quot;response&quot;: {
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;bytes&quot;: {
          &quot;type&quot;: &quot;integer&quot;
        },
        &quot;referrer&quot;: {
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;agent&quot;: {
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;gzip_ratio&quot;: {
          &quot;type&quot;: &quot;string&quot;
        }
      }
    }
  }
}
'
</code></pre>

<p>上面的代码创建了一个名为 <code>nginx</code> 的模板，匹配所有以 nginx 开头的 Index。</p>

<h3 id="kibana-1">Kibana</h3>

<p>Kibana 不需要什么配置，直接启动即可。<code>service kibana start</code>，默认运行在 5601 端口。如果考虑到安全性，也可以将 Kibana 配置为只监听本机，然后使用 Nginx 进行反向代理并控制权限，这里就不再赘述了。</p>

<p>接下来我们需要产生点日志，然后在 Kibana 中能查看到就说明系统工作正常了。我们用 curl 随便请求一下 client 上的 Nginx 来产生一点日志。然后，打开 Kibana，<code>http://[server ip]:5601</code>。刚进去的时候，我们先要配置一下 Kibana 的 <code>Index Pattern</code>，告诉 Kibana 我们想看哪个 Index 的数据，输入 <code>nginx*</code> 即可，然后点击 <code>Discover</code> 浏览数据。</p>

<p>最终效果如下，我们可以在 Kibana 中浏览我们的 Nginx 日志，并进行任意搜索。</p>

<p><img src="http://asset.cjting.cn/9b85365djw1f8zwhs3j5vj21h50mijxx.jpg" alt="" /></p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>从零开始搭建一个 HTTPS 网站</title>
          <link>https://cjting.me/2016/09/05/build-a-https-site-from-scratch/</link>
          <pubDate>Mon, 05 Sep 2016 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2016/09/05/build-a-https-site-from-scratch/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/9b85365djw1f7fb60zgzaj21kw11xgyy.jpg" class="webfeedsFeaturedVisual">

            <p>我们都知道 HTTP 是非常不安全的，不安全的根源在于 HTTP 是明文传输。你在谷歌搜索了一个关键词（假设 Google 使用 HTTP），HTTP 数据包从你的计算机传送到服务器的过程中，中间经过的任意一个设备都可以轻松解析你的数据包，获取你的关键词，你的隐私毫无保障。</p>

<p>你的信息被人获取只是明文传输的其中一个问题。总体来说，明文传输有三个问题：</p>

<ul>
<li>窃听：第三方可以获取你的信息</li>
<li>篡改：第三方可以修改你的信息</li>
<li>冒充：第三方可以冒充你的身份</li>
</ul>

<p>不仅是 HTTP，所有明文传输的协议，都有这三个问题。那解决方案自然也是围绕着这三点进行，我们需要有一个协议，能够保证：</p>

<ul>
<li>第三方无法获取通信内容，这意味着通信内容肯定是要加密的。</li>
<li>第三方无法修改通信内容，这意味着通信内容需要有校验机制（加密和校验是两回事，虽然信息加密了，第三方无法读取，但是一样可以修改你的内容，比如，把加密的内容拷贝一份贴在后面），如果通信数据被修改了，通信双方能够立刻知道。</li>
<li>第三方无法冒充身份，这就意味着需要有一个身份校验机制。</li>
</ul>

<p>这个协议就是 <code>SSL/TLS</code>。</p>

<h2 id="ssl-tls">SSL/TLS</h2>

<h3 id="历史">历史</h3>

<p><code>SSL</code> 协议起源很早。1994 年，网景公司就设计了 SSL 协议 1.0 版，但是因为设计上有很多严重的问题，这个版本并没有对外公布（这一年网景推出了著名的网景浏览器并迅速获得成功）。1995 年，网景公司发布了 SSL 协议的 2.0 版，但是很快被发现有严重的漏洞从而导致了 SSL 协议 3.0 版的诞生。1996 年，经过彻底的重新设计，SSL 协议 3.0 版发布，并得到了大规模应用。目前广泛使用使用的 <code>SSL/TLS</code> 协议就是基于 SSL 协议的 3.0 版。</p>

<p>1999 年，互联网标准化组织 ISOC 接替网景公司，发布了 SSL 的升级版 <code>TLS</code> 协议 1.0。之后，TLS 协议又经历了几次升级，目前最新的为 TLS 1.3（草案）。</p>

<h3 id="工作原理">工作原理</h3>

<p>SSL/TLS 协议的核心是 <code>RSA 非对称加密</code>。RSA 是一个伟大的发明，简单来说，通过 RSA，我们可以生成两把钥匙，一把公钥，一把私钥。公钥加密以后私钥可以解开，而私钥加密以后公钥可以解开。这就避免了对称加密系统（加密解密使用同一把密钥）的一个重大缺陷：需要传输密钥。</p>

<p>那么 SSL/TLS 协议的基本原理就是，客户端获取服务器的公钥，加密信息以后传送给服务器，然后服务器使用私钥解密。这个方案有两个问题。</p>

<ol>
<li>服务器传输公钥的时候，是明文的，第三方可以篡改。</li>
<li>RSA 加密的计算量较大，如果每次通信都使用 RSA 加密的话，会对性能产生负担。</li>
</ol>

<p>针对第一个问题，我们需要一个办法来保证服务器传输的公钥确实是服务器的，而不是第三方的。这个时候，我们需要使用 *数字证书*。数字证书由权威机构 (CA, Certificate Authority) 颁发，里面包含有服务器的公钥，证书文件使用 CA 私钥进行加密。当客户端与服务器建立加密通信的时候，服务器不再返回公钥，而是返回他的数字证书。客户端拿到证书，使用对应的 CA 的公钥解密，然后获取到服务器的公钥。这里有一个问题，客户端怎么拿到 CA 的公钥呢？如果还是去CA 服务器获取的话，那么我们又会回到问题的原点即怎样保证 CA 公钥不被人篡改。因此，大部分浏览器中，权威 CA 的公钥都是内置的，不需要去获取。这就保证了 CA 公钥的正确性。第三方没有办法伪造证书，因为第三方没有 CA 的私钥（当然，CA 被入侵的例子的也是有的，技术永远解决不了人的问题）。</p>

<p>针对第二个问题，SSL/TLS 协议在通信过程中，并不是使用 RSA 加密，而是使用对称加密，对称加密的密钥（对话密钥）由双方协商生成。</p>

<p>因此，SSL/TLS 协议的基本流程如下：</p>

<ol>
<li>客户端索取服务器的数字证书，从而获得服务器公钥</li>
<li>双方协商生成对话密钥</li>
<li>使用对话密钥进行加密通信</li>
</ol>

<h3 id="具体流程">具体流程</h3>

<p>根据上面的论述，SSL/TLS 协议的核心便是怎样安全的生成一个 <em>对话密钥</em> 来加密之后的通信。这个过程称之为 *握手*。</p>

<p><img src="http://asset.cjting.cn/9b85365dgw1f7fdsr6gbzj20tv0m3q7r.jpg" alt="" /></p>

<p>握手一共有四次请求，注意，这些请求都是明文的（也没法加密）。</p>

<h4 id="客户端请求-clienthello">客户端请求 (ClientHello)</h4>

<p>首先，客户端（通常是浏览器）先向服务器发送请求，这一步叫做 <code>ClientHello</code>，
请求携带以下信息：</p>

<pre><code class="language-text">1. 客户端支持的协议版本（这是为了和服务器协商使用什么版本的 SSL/TLS 进行通信）
2. 客户端生成的一个随机数 n1
3. 客户端支持的加密方法，比如 RSA（这是为了和服务器协商使用什么加密方法）
</code></pre>

<h4 id="服务器响应-serverhello">服务器响应 (ServerHello)</h4>

<p>服务器收到客户端请求之后，向客户端发送响应，这一步叫做 <code>ServerHello</code>，
响应携带以下信息：</p>

<pre><code class="language-text">1. 确认通信使用的 SSL/TLS 版本
2. 服务器生成的一个随机数 n2
3. 服务器的数字证书
4. 确认加密方法，比如 RSA
</code></pre>

<h4 id="客户端回应">客户端回应</h4>

<p>客户端收到浏览器的响应后，首先验证服务器的证书时候有效。如果证书不是由权威结构颁发 (比如 12306)，证书包含的域名和实际域名不一致或者证书已经过期，那么浏览器会警告用户，由用户决定是否继续访问。</p>

<p>如果证书没有问题，客户端便会从证书中取出服务器的公钥，然后发送一个请求，携带以下信息。</p>

<pre><code class="language-text">1. 一个随机数 n3，这个随机数用服务器公钥加密，防止被窃听
2. 编码改变通知，表示之后所有的信息都将会使用双方商定的加密方法加密发送
3. 客户端握手结束通知，表示客户端的握手阶段已经结束
</code></pre>

<p>客户端此时有三个随机数，n1，n2，n3，根据这个三个随机数，客户端使用一定的算法生成通信所需的对话密钥。</p>

<h4 id="服务器最后响应">服务器最后响应</h4>

<p>服务器收到客户端的随机数之后，使用私钥将其解密，这时，服务器也拥有了 n1，n2，n3 这三个随机数，服务器便可以生成和客户端一致的对话密钥。然后向客户端发送最后的响应。信息如下：</p>

<pre><code class="language-text">1. 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送
2. 服务器握手结束通知，表示服务器端的握手阶段已经结束
</code></pre>

<p>到了这里，客户端和服务器就可以使用对话密钥加密之后所有的通信过程。第三方无法窃听，都是乱码看不懂。也无法篡改，SSL 使用 MAC(Message Authentication Code) 来校验信息。更无法冒充，因为没有对话密钥。</p>

<h2 id="https">HTTPS</h2>

<p>HTTPS 便是 <code>HTTP Over SSL</code>，使用 SSL 协议来加密 HTTP 通讯过程。SSL 协议本质上是提供了一个加密通道，我们在这个通道中传输 HTTP，便是 HTTPS 协议。</p>

<h3 id="证书">证书</h3>

<p>从前面的描述中可以看出，要想进行 SSL 通信，服务器需要有一个权威机构认证的证书。证书是一个二进制文件，里面包含有一些信息（服务器的公钥，域名，有效时间等）。和域名一样，证书需要购买，并且价格不菲。下面是三个常用的购买证书的网站。</p>

<ul>
<li><a href="https://www.gogetssl.com">GoGetSSL</a></li>
<li><a href="https://www.ssls.com">SSLs.com</a></li>
<li><a href="https://www.sslmate.com">SSLmate.com</a></li>
</ul>

<p>证书分为很多类型，首先分为三级认证：</p>

<ul>
<li><p>域名认证（Domain Validation, DV）：最低级的认证，CA 只检查申请者拥有某个域名，对于这种证书，浏览器会在地址栏显示一把绿色的小锁。</p></li>

<li><p>组织认证（Organization Validation, OV)：CA 除了检查域名所有权以外，还会审核组织信息。对于这类认证，浏览器会在地址栏中显示公司信息。</p></li>

<li><p>扩展认证（Extended Validation, EV)：最高级别的认证，相比于组织认证，CA 会对组织信息进行更加严格的审核。</p></li>
</ul>

<p>除了三个级别以外，证书还分为三个覆盖范围：</p>

<ul>
<li><p>单域名证书：只能用于单一域名，a.com 的证书不能用于 www.a.com</p></li>

<li><p>通配符证书：可以用于域名下的所有子域名，*.a.com 的证书可以用于 a.com，也可以用于 www.a.com</p></li>

<li><p>多域名证书，可以用于多个域名，比如 a.com，b.com</p></li>
</ul>

<p>很显然，认证级别越高，覆盖范围越广，证书价格越贵。好消息是，为了推广 HTTPS 协议，电子前哨基金会 EFF 成立了 <a href="https://letsencrypt.org/">Let&rsquo;s Encrypt</a>，可以提供免费证书。So, Let&rsquo;s Encrpyt~</p>

<h3 id="let-s-encrpyt">Let&rsquo;s Encrpyt</h3>

<p>这里，我使用一台新的 <code>CentOS 7</code> VPS 来演示怎样从头搭建一个 HTTPS 网站。</p>

<h4 id="安装客户端">安装客户端</h4>

<p>先安装基础工具。</p>

<pre><code class="language-bash">yum update
yum install -y git vim
</code></pre>

<p>然后，我们来安装 <code>letsencrypt</code> 客户端。目前，安装 <code>letsencrpyt</code> 客户端最好的方式便是直接克隆代码仓库。我们登录到服务器上，将 <code>letsencrypt</code> 的仓库克隆到本地。</p>

<pre><code class="language-bash">git clone https://github.com/letsencrypt/letsencrypt /opt/letsencrypt
</code></pre>

<p>最后，我们安装 <code>nginx</code> 作为我们的 web server。<code>yum install -y nginx</code>，安装好之后，<code>systemctl start nginx</code> 启动。默认情况下，<code>CentOS 7</code> 只开放了 <code>DHCP</code> 和 <code>SSH</code> 的端口，我们需要手动把端口开放一下。</p>

<pre><code class="language-bash">firewall-cmd --permanent --add-service=http 
firewall-cmd --permanent --add-service=https
firewall-cmd --reload
</code></pre>

<p>将自己的域名配置到这台 VPS 上。这里，我使用 <code>leaningmoon.io</code> 为例。访问网站，可以看到默认的 nginx 页面。</p>

<h4 id="生成证书">生成证书</h4>

<p>我们使用 <code>letsencrypt</code> 来生成 HTTPS 所需的证书。作为一个免费的解决方案，<code>letsencrypt</code> 只提供域名认证证书（这很合理，组织机构可以自己购买高级证书）。所以，我们只要能证明域名是自己所有即可。最简单的方式是用 <code>letsencrypt</code> 的 <code>webroot</code> 验证方式，在 VPS 上告诉 <code>letsencrypt</code> nginx 的 <code>webroot</code> 和你的域名，<code>letsencrypt</code> 会在 <code>webroot</code> 的 <code>.well-known</code> 文件夹中放置一个特别的文件，然后使用域名去访问这个文件，如果可以访问到，当然能够证明域名是你的了。</p>

<p>默认的 Nginx 配置不用任何修改，Nginx 默认的 <code>webroot</code> 是 <code>/usr/share/nginx/html</code>。</p>

<pre><code class="language-bash">cd /opt/letsencrypt
./letsencrypt-auto certonly -a webroot --webroot-path=/usr/share/nginx/html -d leaningmoon.io # 可以使用多个 -d 添加多个域名
</code></pre>

<p>回车之后，<code>letsencrypt</code> 会进行一系列操作生成所需的证书文件，最后会有一个弹窗，提示你输入电子邮件地址，如果证书丢了，可以恢复。</p>

<p><img src="http://asset.cjting.cn/9b85365djw1f7hzf480y7j20sp0ap3zk.jpg" alt="" /></p>

<p>最后，<code>letsencrypt</code> 的输出结果如下。</p>

<p><img src="http://asset.cjting.cn/9b85365djw1f7hzfmf062j20v60bj456.jpg" alt="" /></p>

<p>可以看到，最为关键的证书文件存放在 <code>/etc/letsencrypt/live/leaningmoon.io/fullchain.pem</code>。</p>

<h4 id="配置-nginx">配置 Nginx</h4>

<p>最后一步便是配置 Nginx 采用我们的证书文件并开启 HTTPS。这里推荐一个网站，<a href="https://cipherli.st/">cipherli.st</a>，这个网站提供了当前主流的 Web 服务器怎样开启 HTTPS 的推荐配置，很值得参考。这里我们直接复制他提供的 Nginx 配置。</p>

<pre><code class="language-nginx">server {
  listen       80 default_server;
  server_name  leaningmoon.io;
  return 301 https://$server_name$request_uri;
}

server {
  # SSL Configuration
  listen 443 ssl default_server;
  root         /usr/share/nginx/html;

  # copy from https://cipherli.st
  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
  ssl_prefer_server_ciphers on;
  ssl_ciphers &quot;EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH&quot;;
  ssl_ecdh_curve secp384r1; # Requires nginx &gt;= 1.1.0
  ssl_session_cache shared:SSL:10m;
  ssl_session_tickets off; # Requires nginx &gt;= 1.5.9
  ssl_stapling on; # Requires nginx &gt;= 1.3.7
  ssl_stapling_verify on; # Requires nginx =&gt; 1.3.7
  resolver 8.8.8.8 8.8.4.4 valid=300s;
  resolver_timeout 5s;
  add_header Strict-Transport-Security &quot;max-age=63072000; includeSubDomains; preload&quot;;
  add_header X-Frame-Options DENY;
  add_header X-Content-Type-Options nosniff;

  # specify cert files
  ssl_certificate /etc/letsencrypt/live/leaningmoon.io/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/leaningmoon.io/privkey.pem;
}
</code></pre>

<p>重启 Nginx，<code>systemctl reload nginx</code>。再次访问网站，我们可以看到，我们的网站也多了一把可爱的小绿锁~</p>

<p><img src="http://asset.cjting.cn/9b85365dgw1f7hzuvhh4jj212h0bqgpx.jpg" alt="" /></p>

<p><strong>参考链接</strong></p>

<ul>
<li><a href="http://www.ruanyifeng.com/blog/2016/08/migrate-from-http-to-https.html">HTTPS 升级指南</a></li>
<li><a href="http://www.ruanyifeng.com/blog/2014/02/ssl_tls.html">SSL/TLS 协议运行机制的概述</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-16-04">How To Secure Nginx with Let&rsquo;s Encrypt on Ubuntu 16.04</a></li>
</ul>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>使用 Dnsmasq 搭建内网 DNS 服务器</title>
          <link>https://cjting.me/2016/08/20/use-dnsmasq-to-build-own-dns-server/</link>
          <pubDate>Sat, 20 Aug 2016 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2016/08/20/use-dnsmasq-to-build-own-dns-server/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/9b85365djw1f7bjp0tf5dj21jk0ikq95.jpg" class="webfeedsFeaturedVisual">

            <p>在日常开发过程中，我们经常要配置各种
 host，比如公司内部的各种服务，或者测试项目的时候暂时把生产环境 URL 配置到本地上等等。一般采取的方法都是每个人手动编辑自己的 <code>/etc/hosts</code> 文件。这个做法有两个缺点：</p>

<ul>
<li>手动编辑 <code>/etc/hosts</code> 文件非常麻烦，需要 <code>sudo</code></li>
<li>工作量重复，团队内每个人都要配置一遍</li>
</ul>

<p>第一个缺点只是有点麻烦，问题还不大。在团队中，怎样解决第二个问题才是关键。试想，有一个新的项目 <code>test</code> 要开始开发了，内部搭建了 Sandbox 环境和 Staging 环境，这时候，参与项目的所有人（包括开发人员，测试人员，PM 等）都要手动添加 <code>sandbox.test.dev</code> 以及 <code>staging.test.dev</code> 这两条记录到 <code>/etc/hosts</code> 文件中。这实在是无比繁琐。和非开发人员说怎么配 host 也是一件很痛苦的事情。</p>

<p>解决这个问题的思路也很简单，我们需要一个内部的 DNS 服务器能够控制 DNS 查询就行，然后把所有的 <code>host</code> 配置在这台 DNS 服务器上，从而实现一次配置，所有人都可以使用。</p>

<p>这里我们使用的是 <code>Dnsmasq</code>，一个轻量的支持 <code>DNS</code>, <code>DHCP</code> 以及 <code>TFTP</code> 协议的小工具。功能很多，有兴趣可以自己研究，这里我们主要关心他的 DNS 功能。</p>

<h2 id="安装">安装</h2>

<p>Mac 上很简单，<code>brew install dnsmasq</code> 即可。Linux 上可以使用相应的包管理器来装。</p>

<h2 id="配置">配置</h2>

<p>在 Mac 上，<code>Dnsmasq</code> 使用的配置文件是 <code>/usr/local/etc/dnsmasq.conf</code> 文件。Linux 上是 <code>/etc/dnsmasq.conf</code>。</p>

<p>默认配置文件中列举了所有的配置和解释，所以很容易看懂。这里我们使用以下的配置。</p>

<pre><code class="language-text"># 所有没有 `.`` 的域名 (plain names) 都不会向上游 DNS Server 转发，只查询 hosts 文件
domain-needed
# 所有保留 IP 地址段内的反向查询都不会向上游 DNS Server 转发，只查询 hosts 文件
bogus-priv
# 不要读取 /etc/resolver 中的 DNS Server 的配置
no-resolv
# 不要 poll /etc/resolver 文件的更新
no-poll
# 下面这两个配置我们的上游 DNS 服务器
server=8.8.8.8
server=8.8.4.4
</code></pre>

<p>配置完了以后，在 <code>/etc/hosts</code> 中添加我们的内部 hosts。启动 <code>Dnsmasq</code> 就行了。</p>

<h2 id="配置路由器">配置路由器</h2>

<p>默认情况下，每一台新进入网络的计算机，默认 DNS Server 是路由器，而路由器的默认 DNS Server 是自动根据 ISP 获取。我们最后一步是把路由器的 DNS 服务器设置为启动了 Dnsmasq 的机器即可。每一台路由器修改 DNS Server 不一样，找一找可以很容易找到。</p>

<h2 id="最后">最后</h2>

<p>到这里，我们的目标就实现了，以后所有的 host 只需要配置在 Dnsmasq 服务器上的 <code>/etc/hosts</code> 文件中（每一次修改 /etc/hosts 文件以后，需要重启 Dnsmasq）。网络中的每一台主机都可以访问配置的域名，再也不用自己手动配置了。同时，Dnsmasq 还默认提供 DNS Cache 功能，可以一定程度上加速网站访问。</p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>使用 Ngrok 实现内网穿透</title>
          <link>https://cjting.me/2016/05/21/ngrok-tutorial/</link>
          <pubDate>Sat, 21 May 2016 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2016/05/21/ngrok-tutorial/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/9b85365djw1f7bk8tdwtej21kw0w0gry.jpg" class="webfeedsFeaturedVisual">

            <p>很多时候，我们都有这样的需求：需要将本地正在开发的服务暴露在公网上，也就是从外网直接访问我们本机上的服务。正常情况下，这是办不到的，因为我们的本机并没有公网 IP，我们的本机处在内网当中。</p>

<p>这里需要顺手提及一个知识：NAT 穿透。我们的机器一般都在路由器的内网当中，IP 地址基本上都是 <code>192.168.x.x</code> 系列，我们并没有公网 IP，那么如何访问外网呢？我们打开浏览器访问 Google，Google 与我们主机之间如何通信？假设我们主机 IP 为 <code>192.168.0.100</code>，路由器 LAN IP 为 <code>192.168.0.1</code>，WAN IP 为 <code>211.22.145.234（这是一个公网IP）</code>，Google 服务器 IP 为 <code>74.125.204.101</code>，详细通信流程如下。</p>

<ol>
<li>主机构建 HTTP 请求数据包，目标 IP 为 74.125.204.101，目标端口 80，源 IP 为 192.168.0.100，源端口随机生成，假定为 5000。</li>
<li>主机检查目标 IP 地址，发现不在一个网段，数据包丢给默认网关（192.168.0.1）。</li>
<li>路由器 LAN 口收到数据包，构建 NAT 映射，随机生成端口，假定为 5500，这样映射就是 :5500 -&gt; 192.168.0.100:5000。WAN 口收到的数据包，如果目标端口是 5500，则转发给内网 IP 为 192.168.0.100 的机器的 5000 端口。</li>
<li>路由器修改数据包的源端口为 5500，源 IP 地址为 211.22.145.234，使用 WAN 口将数据包发送出去。</li>
<li>Google 服务器收到请求，构建响应 HTTP 数据包，目标 IP 地址 211.22.145.234，目标端口为 5500。</li>
<li>路由器 WAN 口收到数据包，目标端口为 5500，查询 NAT 表，发现对应的机器是 192.168.0.100:5000，所以修改目标 IP 为 192.168.0.100，目标端口为 5000，并通过 LAN 口发送给主机。</li>
<li>主机接收到数据包，完成这一次通信。</li>
</ol>

<p>从上面可以看出，内网机器能够和外网通信，全靠拥有公网 IP 的路由器做交通枢纽。路由器通过查询 NAT 表，来确定数据包该发送给内网哪台机器。所以内网多台机器都可以通过这一台路由器和外网进行通信，这极大的节省了宝贵的公网 IP 资源。</p>

<p>NAT 表项是在内网主动和外网通信的过程中构建的，如果外网主动访问内网，那么自然没有表项，也就访问不到。如果想要从外网访问内网，根据上面的原理我们可以有两种做法。</p>

<p>首先，我们可以手动添加 NAT 表项，大部分路由器里面都有这个设置项。我的 NETGEAR 路由器的设置页面如图所示。</p>

<p><img src="http://asset.cjting.cn/9b85365dgw1f43dxm3ux6j21gz0jo78u.jpg" alt="" /></p>

<p>另一种办法，是找一个公网服务器做中介。比如服务器 A，流程如下。</p>

<ul>
<li>开发主机和服务器 A 构建一条连接</li>
<li>用户访问服务器 A</li>
<li>服务器 A 联系开发主机获取内容</li>
<li>服务器 A 将获取到的内容发送给用户</li>
</ul>

<p>通过上面的流程，就实现了用户访问到了我们内网的内容。那么帮助我们实现这个功能的程序就是 Ngrok。通过在服务器上安装 Ngrok，我们就可以和本地主机构建一条隧道，来让外网用户访问本地主机的内容。</p>

<p>以下是安装 Ngrok 的详细步骤。</p>

<p>首先，下载代码。</p>

<pre><code class="language-bash">git clone https://github.com/inconshreveable/ngrok.git
cd ngrok
</code></pre>

<p>第二步，生成我们自己的证书。我们首先要想好一个基础域名（NGROK_BASE_DOMAIN)。比如我选择 <code>tunnel.cjting.me</code>，那么我之后就会使用 <code>*.tunnel.cjting.me</code> 来访问相应的本地服务。</p>

<pre><code class="language-bash">openssl genrsa -out base.key 2048
openssl req -new -x509 -nodes -key base.key -days 10000 -subj &quot;/CN=[NGROK_BASE_DOMAIN]&quot; -out base.pem
openssl genrsa -out server.key 2048
openssl req -new -key server.key -subj &quot;/CN=[NGROK_BASE_DOMAIN]&quot; -out server.csr
openssl x509 -req -in server.csr -CA base.pem -CAkey base.key -CAcreateserial -days 10000 -out server.crt
</code></pre>

<p><img src="http://asset.cjting.cn/9b85365djw1f439iat2lpj20qi0g5grx.jpg" alt="" /></p>

<p>第三步，拷贝证书文件，然后编译相应的客户端和服务器程序。</p>

<pre><code class="language-bash">cp base.pem assets/client/tls/ngrokroot.crt
GOOS=linux make release-linux # 服务器是 linux，我们需要交叉编译
make release-client # 客户端运行在我们自己的机器上
</code></pre>

<p>第四步，将相应的文件传送到服务器上，并启动服务器程序。服务器程序需要第二部生成的 <code>server.crt</code> 和 <code>server.key</code>。</p>

<pre><code class="language-bash">mkdir release
cp bin/linux_amd64/ngrokd release/
cp server.crt server.key release/
scp -r release/ root@[host]:~/ngrok
ssh root@[host]
cd ~/ngrok
./ngrokd -tlsKey=server.key -tlsCrt=server.crt -domain=&quot;[NGROK_BASE_DOMAIN]&quot; -httpAddr=&quot;:80&quot; -httpsAddr=&quot;:443&quot;
</code></pre>

<p>第五步，配置域名解析。解析 <code>[NGROK_BASE_DOMAIN]</code> 以及 <code>*.[NGROK_BASE_DOMAIN]</code> 地址到服务器上。我使用的是 DNSPOD，截图如下。</p>

<p><img src="http://asset.cjting.cn/9b85365djw1f43rtmytwvj20nn0bqwgl.jpg" alt="" /></p>

<p>最后一步，配置客户端，启动客户端程序。客户端的默认配置文件位置是 <code>$HOME/.ngrok</code>，填入以下配置。</p>

<pre><code class="language-yaml">server_addr: [NGROK_BASE_DOMAIN]:4443
trust_host_root_certs: false
</code></pre>

<p>然后启动客户端。</p>

<pre><code class="language-bash">./ngrok -subdomain test 8080
</code></pre>

<p>客户端会转发本地 8080 端口的服务到 <code>test.[NGROK_BASE_DOMAIN]</code> 上。以我为例，只要我访问 <code>test.tunnel.cjting.me</code>，就可以看到开发主机上 8080 端口的内容。实现了外网访问内容的目标。</p>

<p><img src="http://asset.cjting.cn/9b85365dgw1f43t9r2wshj20iq06i74v.jpg" alt="" /></p>

<p>最后提一点：客户端和服务器连接是需要验证证书的。只有我们同时编译的客户端和服务器才能连接上。在新的电脑上重新编译客户端去连接一个已部署的服务器，是无法连接的。因此建议存档一份客户端程序。</p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>编写第一个 Chrome 插件 —— 图床on微博</title>
          <link>https://cjting.me/2016/04/06/first-chrome-extension-image-bed-on-weibo/</link>
          <pubDate>Wed, 06 Apr 2016 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2016/04/06/first-chrome-extension-image-bed-on-weibo/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/9b85365djw1f7bm61rer2j21hc0u0q58.jpg" class="webfeedsFeaturedVisual">

            <p>之前写博客需要的图片全部都是本地存储，非常麻烦。流程如下：先用截图工具截图（QQ 截图就很好用），然后移动到目标文件夹，然后在 Markdown 中输入绝对路径（Jekyll 生成站点以后路径会变化，所以不能使用相对路径）。除了麻烦以外，在 Markdown 中编写时还是看不到图的，因为路径不对。</p>

<p>上次花点时间把所有的图片全部迁移到微博图床了。在 Chrome Web Store 中搜索了一下，选了<a href="https://chrome.google.com/webstore/detail/%E6%96%B0%E6%B5%AA%E5%BE%AE%E5%8D%9A%E5%9B%BE%E5%BA%8A/fdfdnfpdplfbbnemmmoklbfjbhecpnhf?utm_source=chrome-ntp-icon">新浪微博图床</a>。功能是可以用的，不过有一些问题，最让我无法忍受的就是一点击按钮就会弹出一个 Chrome 的空白窗口，无法关闭，只有重启 Chrome 才行，这个实在是忍无可忍。</p>

<p>闲话不说了，总之我发现这是一次绝佳的自己造轮子的机会。自己造自己用多好玩，所以我准备自己写一个 Chrome 插件，来实现微博图床的功能。起什么名字好呢，恩，这真是一个世界难题。想了半天，决定叫做“图床on微博”吧，是的，我是 RoR 粉丝。</p>

<h2 id="项目分析">项目分析</h2>

<p>首先，实现微博图床最核心的便是图片的上传接口。通过阅读 <code>新浪微博图床</code> 的源码，可以发现接口是<a href="http://picupload.service.weibo.com/interface">这个</a>，只要登陆了微博就可以使用，非常简单。知道了接口，剩下的事情就简单了。</p>

<p>第二，这个接口在 <code>picupload.service.weibo.com</code> 域下，我们本地开发测试的时候怎样跨域需要解决。打包成 Chrome 插件以后怎样跨域也需要解决。关于这个问题可以参考最终项目的 <a href="https://github.com/cj1128/pic-on-weibo">README</a>。</p>

<h2 id="功能设计">功能设计</h2>

<p>有了核心的文件上传接口，其他的功能就看我们自己发挥了。如果要成为一个好用的图床，我想到了以下几个基本功能：</p>

<ul>
<li>拖拽上传：现在谁还通过 Dialog 来选择文件呀</li>
<li>复制上传：这个一定要有，这样用 QQ 截图好了直接粘贴就可以上传了</li>
<li>批量上传：偶尔还是很实用的</li>
<li>上传记录：之前上传过什么还是需要知道的</li>
</ul>

<h2 id="实现">实现</h2>

<h3 id="chrome-插件">Chrome 插件</h3>

<p>首先，我们要做的是 Chrome 插件，先去看看 <a href="https://developer.chrome.com/extensions/getstarted">chrome extension get started</a>，可以发现，Chrome 插件其实很简单，提供一个 Manifest 指定一些元信息，其他就是用 Web 技术和 Chrome 提供的一些 api 来完成功能了。基本上都是我们熟悉并喜爱的东西。这里我们要用的就是最简单的 <code>Browser Actions</code>，提供一个按钮，然后点击以后跳转到我们的应用页面就行了，先来看看 <code>manifest.json</code>。</p>

<pre><code class="language-json">{
  &quot;manifest_version&quot;: 2,
  &quot;name&quot;: &quot;图床on微博&quot;,
  &quot;description&quot;: &quot;支持拖拽上传，复制上传，批量上传以及浏览上传历史记录&quot;,
  &quot;version&quot;: &quot;1.0&quot;,
  &quot;icons&quot;: {
    &quot;16&quot;: &quot;icon16.png&quot;,
    &quot;48&quot;: &quot;icon128.png&quot;,
    &quot;128&quot;: &quot;icon128.png&quot;
  },
  &quot;browser_action&quot;: {
    &quot;default_icon&quot;: {
      &quot;19&quot;: &quot;icon19.png&quot;,
      &quot;38&quot;: &quot;icon38.png&quot;
    },
   &quot;default_title&quot;: &quot;图床on微博&quot;
  },
  &quot;background&quot;:{
    &quot;scripts&quot;:[&quot;background.js&quot;],
    &quot;persistent&quot;: false
  },
  &quot;permissions&quot;: [
    &quot;http://*/&quot;
   ]
}
</code></pre>

<p><code>background</code> 指定插件的 background script，在这个 js 中，我们监听按钮的点击事件，当按钮点击的时候，打开我们的应用页面。</p>

<pre><code class="language-javascript">chrome.browserAction.onClicked.addListener(function() {
  var url = chrome.extension.getURL(&quot;app.html&quot;)
  chrome.tabs.create({ url: url })
})
</code></pre>

<p><code>permissions</code> 用于申请权限，我们设置为 <code>http://*/</code> 意味着我们可以请求任意的网址（HTTP 协议），解决了跨域问题。剩下来的就是开发 app.html 了，到这里，Chrome 插件的部分已经全部完成了。</p>

<h3 id="app">app</h3>

<p>习惯了使用 React 开发的我，决定还是使用 React 来开发，虽然会引入 React 这个庞大的库（大约 140kb），但是 Chrome 插件是打包安装的，不会影响加载速度。</p>

<p>关于拖拽功能的实现，网上有很多插件，我粗略找了一下，都非常复杂，比如 <a href="http://www.dropzonejs.com/">Dropzone.js</a>，不仅实现了拖拽，还帮你实现了文件上传、上传进度等一些列功能。并不需要，我们需要的是一个最简单的拖拽插件，当用户拖拽文件进入的时候，调用我们的回调函数并且传递 file 参数就行了。幸运的是，我找到了 <a href="https://github.com/okonet/react-dropzone">react-dropzone</a>，好用到不行。</p>

<p>关于复制上传，我们直接监听浏览器的 <code>paste</code> 事件就行了。</p>

<p>关于存储上传记录，localStorege 可以轻松搞定。</p>

<p>剩下的便是编码了~大家有兴趣可以自己作为周末项目练练手~</p>

<p>最后，这是完整项目的 <a href="https://github.com/cj1128/pic-on-weibo">Github Repo</a>，这是插件的<a href="https://chrome.google.com/webstore/detail/%E5%9B%BE%E5%BA%8Aon%E5%BE%AE%E5%8D%9A/opblldeehobgiedgjgamaklagilmkagc/related">地址</a>。欢迎大家使用和评分，需要什么功能或者有什么不满，都可以去 GitHub 吐槽。</p>

<p>PS：如果翻墙不方便的话，可以 clone 仓库，<code>npm install &amp;&amp; npm run build</code>，接着进入 <code>Chrome Extensions</code> 选项，打开开发者模式，然后把 <code>chrome</code> 目录拖进去就可以使用插件了（GIF 如下，有图床了就是任性~）。</p>

<p><img src="http://asset.cjting.cn/9b85365djw1f2twd1698tg21a90p51ky.gif" alt="" /></p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>Functional Reactive Programming 简介</title>
          <link>https://cjting.me/2016/03/20/intruduction-to-functional-reactive-programming/</link>
          <pubDate>Sun, 20 Mar 2016 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2016/03/20/intruduction-to-functional-reactive-programming/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/9b85365dgw1f7bmcscnvij21jk112496.jpg" class="webfeedsFeaturedVisual">

            <p>推荐阅读：</p>

<ul>
<li><a href="https://www.youtube.com/watch?v=XRYN2xt11Ek">Netflix JavaScript Talks - Async JavaScript with Reactive Extensions</a></li>
<li><a href="https://gist.github.com/staltz/868e7e9bc2a7b8c1f754">The introduction to Reactive Programming you&rsquo;ve been missing</a></li>
</ul>

<p>HTML5Rocks 有一篇关于 <a href="http://www.html5rocks.com/en/tutorials/es6/promises/">Promise</a> 的经典文章，通过引入这样一个问题来说明 Promise 的优越性，问题如下：</p>

<blockquote>
<p>我们需要渲染一个故事，首先我们获取故事的 json，渲染标题 (story.heading)，然后再根据其中的 charpter url，获取每一章的内容，并显示。中间出了任何问题，显示错误信息。</p>
</blockquote>

<p>这个问题乍一看好像很容易，不就是 ajax 拿几个数据嘛。但是我们可以想想怎么做才是最高效的方式，程序优化的点有时候很难想到，有时候却是显而易见的。这个问题要高效解决我们至少需要做以下两点：</p>

<ul>
<li>故事的每一章内容我们应该并行获取</li>
<li>显示的时候，不能等到所有章节内容都获取到再显示，而应该在保持顺序的情况下尽快显示。比如第一章内容来了，我们立刻显示第一章，但是我们要等第二章内容，即便第三章先来，我们也不能显示。</li>
</ul>

<p>再考虑到我们需要追踪每个 ajax 的错误信息，一旦有错误立刻显示错误页面，这个问题似乎没有那么好解决。传统的解决方法我们不可避免的要跟踪状态，比如当前有没有错误？内容已经到第几章了？这种代码写出来很容易出错而且很难看。</p>

<p>作者在这个 <a href="https://gist.github.com/jakearchibald/0e652d95c07442f205ce">gist</a> 上面贴出了文中问题的一些解法对比，包括使用 Promise，使用传统的状态追踪等。这个 gist 下面有个评论中使用了 RxJS，代码十分简洁优美，很是引人注目。</p>

<p><a href="https://github.com/Reactive-Extensions/RxJS">RxJS</a> 指的是 <strong>Functional Reactive Programming extensions for JavsScript</strong>，Functional Reactive Programming 是一种编程思想，并不局限于某一个语言。这种思想的核心就是流，RxJS 中的使用的术语是 <code>Observable</code>，但是我觉得这个词不好理解，用流也就是 <code>Stream</code> 更好理解。流代表的是一个随着时间而变化的序列，在这过程中，它可以产生值，或者错误，或者终止信号，只有这三种情况。</p>

<p><img src="http://asset.cjting.cn/9b85365djw1f238lhm2c4j20e807974m.jpg" alt="" /></p>

<p>流的引入最大的优点是我们有了一个手段来表示“无尽”的东西，并且可以对它们进行各种变换，就像我们处理数组那样。处理数组我们有 <code>map</code>, <code>filter</code>，<code>reduce</code> 这几个核心方法。对于流我们也有类似这些的基本方法，这里推荐一个好用的网站 <a href="http://rxmarbles.com/">RxMarbles</a>，非常直观的显示一些方法是怎样操作流的。</p>

<p>面向流的编程基本过程就是，创建代表原始输入的流，对它们进行组合、过滤等各种操作，最后生成我们感兴趣的结果流，监听结果流（subscribe）并进行相应操作即可，监听的时候提供三个函数，分别用于处理流产生了值，流产生了错误以及流结束这三种情况。</p>

<p>这里用 RxJS 首页的自动补全（auto completion）例子来看一看怎么使用 RxJS。自动补全是搜索框中很常见的一个功能，随着用户的输入，系统会自动在下拉框中显示相关的词汇供用户选择，也可以起到给用户一些提示的作用，这是一个很方便的功能。实现思路也比较简单，根据用户目前输入的词汇去获取词汇列表，然后显示。但是这里面有几个细节：</p>

<ul>
<li>用户的输入需要 debounce，否则会发送太多无意义的请求。</li>
<li>只有用户输入的字符串大于一个长度我们才请求。否则返回的结果太模糊并且数量也大。</li>
<li>考虑到网络延迟，需要追踪后台返回的数据是否匹配用户当前的输入。比如用户输入 &ldquo;ABC&rdquo;，系统发了一次请求，用户又改输入为 &ldquo;DEF&rdquo;，此时 ABC 的结果返回，我们就不能显示了，因为这个结果已经过时了。</li>
</ul>

<p>首先，我们来构建原始流：</p>

<pre><code class="language-javascript">var $input = $('#input') //输入框
var originInputStream = Rx.Observable.fromEvent($input, 'keyup')
</code></pre>

<p>这里，我们使用 RxJS 提供的 <code>fromEvent</code> 方法来构建原始事件流，<code>originInputStream</code> 代表的是每一个 <code>keyup</code> 事件，用户每输入一个字符，<code>originInputStream</code> 便会产生一个值，值的内容为对应的事件对象。现在来想想怎么变换这个原始流，首先，我们需要 debounce，然后我们 map 拿到用户输入的字符串，接下来需要过滤长度比较小的字符串，最后，如果后面的值和前面的值一样，我们就丢弃它。</p>

<pre><code class="language-javascript">var resultInputStream = originInputStream
  .debounce(500 /* ms */)
	.map(evt =&gt; evt.target.value)
  .filter(text =&gt; text.length &gt; 2 )
  .distinctUntilChanged()
</code></pre>

<p><code>resultInputStream</code> 代表的便是每一个需要请求后台的用户输入值，这个还不是最终的 Stream。最终的 <code>suggestionStream</code> 应该代表的是后台返回的结果，我们监听然后显示 suggestions，就大功告成了。现在剩下的任务便是怎么由 <code>resultInputStream</code> 得到 <code>suggestionStream</code>。</p>

<p>这里我们要介绍两个重要的方法，分别是 <code>flatMap</code> 以及 <code>flatMapLatest</code>。<code>map</code> 方法是根据流（mainStream）里面的值，产生一个新的值，如果这个新的值是一个流（subStream）怎么办呢？大部分情况下，我们会希望这个新的流（subStream）它的值出现在 mainStream 中，这样我们可以直接监听 mainStream 而不用去监听每一个 subStream，如图所示：</p>

<p><img src="http://asset.cjting.cn/9b85365djw1f23ftn0686j208z04cdg4.jpg" alt="" /></p>

<p><code>flatMap</code> 就是这样一个方法，<code>flatMapLatest</code> 顾名思义，他只会处理最新的 subStream，之前的 subStream 的值全部丢掉。这非常吻合我们的需求，因为当用户输入新的字符串时，之前的字符串的返回结果我们不再需要了。</p>

<p>有了 <code>flatMapLatest</code> 这个方法，我们接下来需要做的便是写一个方法，根据 <code>resultInputStream</code> 的每个值，请求后台，返回一个 subStream（返回 romise 便可，RxJS 会自动帮我们转换为 Stream)。</p>

<pre><code class="language-javascript">function searchWikipedia (term) {
  return $.ajax({
    url: 'https://en.wikipedia.org/w/api.php',
    dataType: 'jsonp',
    data: {
      action: 'opensearch',
      format: 'json',
      search: term
    }
  })
}

var suggestionStream = resultInputStream.flatMapLatest(searchWikipedia)
</code></pre>

<p>得到 <code>suggestionStream</code> 以后，我们监听并显示结果就行了。至此，任务大功告成。</p>

<pre><code class="language-javascript">var $results = $(&quot;#results&quot;) // ul to hold the results
suggestionStream.subscribe(
  data =&gt; {
    $results
      .empty()
      .append($.map(data[1], value =&gt;  $('&lt;li&gt;').text(value)))
  },
  error=&gt; {
    $results
      .empty()
      .append($('&lt;li&gt;'))
        .text('Error:' + error);
  })
</code></pre>

<p>最终的代码可以看<a href="https://jsbin.com/luvamizavo/1/edit?html,js,output">这里</a>。</p>

<p>上面是一个使用 RxJS 的经典例子，下面我们再来看一个例子。</p>

<p><img src="http://asset.cjting.cn/9b85365djw1f23koqhfbmj20n10603yk.jpg" alt="" /></p>

<p>这是一个十分常见的用户注册表单，几乎每一个网站都要实现的功能。实现起来也比较简单，用户点击 Submit 的时候提交内容到后台就行了，根据后台的结果再进行反馈，比如后台返回成功，则告诉用户注册成功，跳转到个人中心，后台返回“用户名已存在”，则告诉用户注册失败，重新输入。</p>

<p>但是，我们也可以做一些事情来提高这个简单表单的用户体验，包括但不限于：</p>

<ul>
<li>用户输入用户名的时候，就进行用户名可用性检测，当然，我们需要 debounce</li>
<li>进行用户名可用性检测的时候，显示相应的信息告知用户我们正在检测用户名可用性</li>
<li>告知用户用户名可用性检测的结果</li>
<li>如果用户名或者密码为空，禁用提交按钮</li>
<li>如果用户名不可用，禁用提交按钮</li>
<li>当用户点击提交按钮以后，立刻禁用提交按钮，防止二次提交</li>
</ul>

<p>我们先来看看使用 jQuery 怎么解决。</p>

<pre><code class="language-javascript">var $username = $(&quot;[name=username]&quot;)
var $password = $(&quot;[name=password]&quot;)
var $btn = $(&quot;button&quot;)

$btn.click(function(evt) {
  evt.preventDefault()
  btnClicked = true
  setButtonState()

  $.ajax({
    type: &quot;POST&quot;,
    url: &quot;/register&quot;,
    data: {
      username: $username.val(),
      password: $password.val(),
    },
    success: function() {
      alert(&quot;Success!&quot;)
    },
  })
})

// Status variables
var usernameAvailable, 
    checkingUsername, 
    prevUsername, 
    timeout, 
    btnClicked, 
    counter = 0

$username.keyup(function(evt) {
  var username = $username.val()
  if(username === prevUsername) return
  usernameAvailable = false
  setButtonState()
  clearAllInfo()

  if(username.length === 0) return

  if(timeout) clearTimeout(timeout)
  prevUsername = username
  timeout = setTimeout(function() {
    checkingUsername = true
    toggleCheckingIndicator()
    var id = ++counter
    $.ajax({
      url: &quot;/check&quot;,
      data: {
        username: $username.val(),
      },
      success: function(res) {
        if(id !== counter) return
        checkingUsername = false
        usernameAvailable = res.available
        setButtonState()
        toggleCheckingIndicator()
        showResult()
      },
    })
  }, 500)
})

$password.keyup(function(evt) {
  setButtonState()
})

function setButtonState() {
  var enabled = $username.val().length &gt; 0 &amp;&amp;
    $password.val().length &gt; 0 &amp;&amp;
    usernameAvailable &amp;&amp;
    !btnClicked
  $btn.prop(&quot;disabled&quot;, !enabled)
}

function toggleCheckingIndicator() {
  $(&quot;#result-ok&quot;).hide()
  $(&quot;#result-bad&quot;).hide()
  if(checkingUsername) {
    $(&quot;#indicator&quot;).show()
  } else {
    $(&quot;#indicator&quot;).hide()
  }
}

function showResult(available) {
  usernameAvailable ? $(&quot;#result-ok&quot;).show() : $(&quot;#result-bad&quot;).show()
}

function clearAllInfo() {
  $(&quot;#result-ok&quot;).hide()
  $(&quot;#result-bad&quot;).hide()
  $(&quot;#indicator&quot;).hide()
}

setButtonState()

</code></pre>

<p>代码不需要太多解释，逻辑很直接，使用几个变量来追踪我们想要追踪的状态来实现上述的几个功能。这样的代码有一个问题，那就是随着需求的增加，会变来越来越复杂，引入越来越多的状态，直到最后无法控制。</p>

<p>我们再来看看 RxJS 怎么解决这个问题。</p>

<pre><code class="language-javascript">var $username = $(&quot;[name=username]&quot;)
var $password = $(&quot;[name=password]&quot;)
var $btn = $(&quot;button&quot;)

function getStream($ele) {
  return Rx.Observable.fromEvent($ele, &quot;keyup&quot;)
  	.pluck(&quot;target&quot;, &quot;value&quot;)
  	.distinctUntilChanged().startWith(&quot;&quot;)
}

var usernameStream = getStream($username)
var passwordStream = getStream($password)
var btnClickedStream = Rx.Observable.fromEvent($btn, &quot;click&quot;)

var enteredStream = usernameStream
	.combineLatest(passwordStream, (username, password) =&gt; {
  		return username.length &gt; 0 &amp;&amp; password.length &gt; 0
	})

var ajaxStream = usernameStream
  .debounce(500)
  .filter(s =&gt; s.length &gt; 0)
  .flatMapLatest(s =&gt; {
    setIndicator(true)
    return $.getJSON(&quot;/check&quot;, {username: s})
  })
  .map(res =&gt; {
    setIndicator(false)
    setResult(res.available)
    return res.available
  })

var availabilityStream = ajaxStream.merge(usernameStream.map(s =&gt; false))
availabilityStream.subscribe(clearResult)

var buttonStateStream = enteredStream
	.combineLatest(availabilityStream, (a, b) =&gt; a &amp;&amp; b)
	.merge(btnClickedStream.map(s =&gt; false))

btnClickedStream.flatMap(register).subscribe(
  d =&gt; {
    if(d.success) {
      alert(&quot;Success!&quot;)
    }
  },
  jqXHR =&gt; {
    console.error(jqXHR.statusText)
  }
)

buttonStateStream.subscribe(
  function(enabled) {
    $btn.prop(&quot;disabled&quot;, !enabled)
  }
)

function register(evt) {
  evt.preventDefault()
  return $.ajax({
    url: &quot;/register&quot;,
    method: &quot;POST&quot;,
    data: {
      username: $username.val(),
      password: $password.val(),
    },
  })
}


function setIndicator(enabled) {
  clearResult()
  enabled ? $(&quot;#indicator&quot;).show() : $(&quot;#indicator&quot;).hide()
}

function clearResult() {
  $(&quot;#result-ok,#result-bad&quot;).hide()
}

function setResult(ok) {
  ok ? $(&quot;#result-ok&quot;).show() : $(&quot;#result-bad&quot;).show()
}

</code></pre>

<p>还是一样的思路，首先构建原始的 Stream，变换得到我们想要监听的 Stream，除了辅助的 UI 函数以外，剩下的代码都在操作 Stream，没有任何状态的跟踪，代码变得简洁清楚明了。</p>

<p>最后，用户注册的完整代码包括 UI 和一个 Express 的服务器可以在 <a href="https://github.com/cj1128/frp-demo)">frp-demo</a> 下载。</p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>JavaScript Infinite Currying</title>
          <link>https://cjting.me/2016/01/17/javascript-infinite-currying/</link>
          <pubDate>Sun, 17 Jan 2016 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2016/01/17/javascript-infinite-currying/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/9b85365dgw1f7bmdt86ltj21kw0w0wgf.jpg" class="webfeedsFeaturedVisual">

            <p>很久之前曾看到一个很有意思的 JS 问题，</p>

<pre><code class="language-javascript">// 定义一个函数 add，满足如下性质：
add(1) == 1
add(1)(2) == 3
add(1)(2)(3) == 6
...

var g = add(1)(2)
g(100) == 103
g(200) == 203
...
</code></pre>

<p>乍一看，这应该是需要用到柯里化（Curry）的知识，但是好像又不够。当时忙别的事情就没管了，现在想起来，便认真研究了一下。</p>

<p>首先我们需要来说一下柯里化，柯里化是一个在函数编程中十分重要的概念，如果大家熟悉 <code>Haskell</code> 的话就知道 <code>Haskell</code> 中的函数都是默认柯里化的。JS 随便找一个函数编程库（比如 Ramda）肯定也会有柯里化，因为他实在是太重要了。这里我们用一个简单的例子来看看什么是柯里化。</p>

<pre><code class="language-javascript">// f 是一个普通函数，接受两个参数，并返回他们相加的结果
function f(x, y) {
  return x + y
}

// g 是一个柯里化函数，接受一个参数，返回一个新的函数
function g(x) {
  return function(y) {
  	return x + y
  }
}

// 传统函数调用是接收多个参数返回一个值，而柯里化函数则是接收参数返回新的函数，新的函数又可以接受参数再返回新的函数，直至最后返回结果值
// 使用柯里化函数的优势是我们可以&quot;部分应用&quot; (Partial Application)函数的参数，生成新的函数，这在函数编程中是至关重要的
// g(1)(2) == 3
// var add1 = g(1)
// add1(100) == 101
// var add100 = g(100)
// add100(100) == 200
</code></pre>

<p>现在我们来分析上面的问题。</p>

<p>首先，<code>add(1) == 1</code>，说明 <code>add</code> 函数应该返回一个整数。但是 <code>add(1)(2) == 3</code> 表明毫无疑问 <code>add(1)</code> 返回的值应该是一个函数。所以现在我们的问题就变成了，有没有可能让一个函数等于一个整数呢？（注意比较操作符是松散的<code>==</code>，而不是严格<code>===</code>）。</p>

<p>答案是有可能的。这里需要我们了解 JS 的一个小知识。那就是 <code>valueOf</code> 属性。当我们将一个对象和一个 Primitive 进行比较的时候，JS 会调用对象的 <code>valueOf</code> 方法获取一个 Primitive 值，然后再进行比较。</p>

<pre><code class="language-javascript">var a = {}
a.valueOf = function(){ return &quot;hello world!&quot; }
a == &quot;hello world!&quot; // true
a === &quot;hello world!&quot; // false，严格等于操作符会比较数据类型
</code></pre>

<p>从这里就可以看出，只要我们定义了对象 a 的 <code>valueOf</code> 方法，我们可以让他和任意的 Primitive 值相等。</p>

<p>函数也是一个对象，所以这个问题的解决方法就很清楚了。每次返回的都是一个函数。这个函数的 <code>valueOf</code> 会返回传入参数的和。</p>

<p>大家可以试试看自己实现，下面是我的实现～</p>

<pre><code class="language-javascript">function total(args) {
  return [].slice.call(args).reduce((t, c) =&gt; t + c, 0)
}

function add() {
  function factor(value) {
    var result = function(){
      return factor(value + total(arguments))
    }
    result.value = value
    result.valueOf = function(){ return this.value }

    return result
  }

  return factor(total(arguments))
}
</code></pre>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>Underhanded C, 有猫腻的 C</title>
          <link>https://cjting.me/2015/06/16/underhanded-c/</link>
          <pubDate>Tue, 16 Jun 2015 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2015/06/16/underhanded-c/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/9b85365djw1f7bmw01i31j21hc0zkgr3.jpg" class="webfeedsFeaturedVisual">

            <p>这一切，都要从这篇文章说起，<a href="http://www.codersnotes.com/notes/being-sneaky-in-c">being-sneaky-in-c</a>。</p>

<p>通过这篇文章，我了解到，原来外国有一种比赛，叫做 *Underhanded C*（中文翻译：有猫腻的 C），完成规定的题目，要求是写出看起来毫无问题的代码，但是却偷偷的藏有 Bug 或者说后门。</p>

<p>这篇文章说的就是作者参与了这个比赛，以及他的解决方案。</p>

<p>我先来解释一下这道题目：</p>

<blockquote>
<p>题目的要求是写一个类似 Twitter 的服务，接受一条消息（称为一个 piu），然后需要做决定是否 surveil（监视）这条 piu，这个决策过程是秘密的。不可以让用户知道。现在编码者的任务是：需要写出看起来没有任何问题的代码，但是偷偷的将决策结果泄露出来给用户知道。</p>

<p>The contest challenge is that you, as a vigilante programmer fighting for the common man, wants to actually leak that logging decision out to the user even though your boss instructed you not to. So your code needs to look perfectly innocent even though it’s doing something underhanded.</p>
</blockquote>

<p>这是整个程序的<a href="http://www.underhanded-c.org/_p_26.html">源代码</a>，推荐下载下来学习一下。</p>

<p>现在来分析作者的解决方案，作者利用的核心漏洞是 <strong>malloc 不清除被释放的内存，并且二次分配很有可能得到上次被释放的内存块</strong>。</p>

<p>示例如下：</p>

<pre><code class="language-c">uint8 *block1 = (uint8 *)malloc(1000);
*block1 = 100;
free(block1);
uint8 *block2 = (uint8 *)malloc(1000); // this time, it's very likely that block2 == block1
assert(*block2 == 100); // we can get previous value 
</code></pre>

<p><code>malloc</code> 是一个常用的堆内存管理函数，不过却有一些非常严重的问题，以上就是一个例子。安全问题往往都在细微之处，但是却都非常致命，上一次非常著名的 HeartBleed 心脏滴血漏洞也是一个细微的问题导致的。</p>

<p>作者利用这个 bug，巧妙的将 surveil 的信息保留了下来。每一个决定需要被 surveil 的 piu，都被加密（异或 0x69）然后写入文件（加密是在一个 copy 上完成的）。</p>

<p>当决策过程结束以后，接下来就会做关键词过滤（比如 fuck -&gt; love, shit -&gt; stuff，哈哈）在这个过程中，又会分配内存复制 piu 进行操作，此时得到的内存块就是决策过程中使用的内存块，内存中的信息都被保留在那里没有清除。因为被监视（surveiled）的 piu 会和 0x69 异或，所以最后一个字节会是 0x69（C 的字符串最后一个字节都是 0），而没有被监视的最后一个字节则是 0。</p>

<p>下面是一些关键的代码：</p>

<pre><code class="language-c">typedef struct piu_struct {
    int piu_id;
    int piu_id_of_repiu, user_id_of_repiu;    /* zero if not a re-Piu */

    int user_id_of_poster;
    user * poster;

    char piu_text_utf8[140*4+1];
    unsigned char piu_length;   /* UTF8 characters, not bytes */
    unsigned char visible_only_to_followers;
} piu;

typedef struct {
    char buffer[140*4+1];
    time_t stamp;
    int count;
} filter_data;
</code></pre>

<p>注意 piu 结构体中 <code>piu_text_uft8</code> 是 641 个字节，而 <code>filter_data</code> 中则是 640 个字节。所以复制的时候，最后一个字节复制到 <code>filter_data</code> 中属于 stamp 的字段，覆盖其最低位的字节。所以最后，用户通过观察时间字段的最低位是否是0x69就可以判断消息有没有被监听。</p>

<p>下载源代码，运行 test，会发现，得到的时间比当前时间稍微慢了一点，大概几分钟，那是因为时间字段最后一个字节要么被清零，要么被设置为 0x69 了。这个 bug 真是巧妙。</p>

<p>这真是一个有意思的比赛，官网上 <a href="http://www.underhanded-c.org">UnderhandedC</a> 还有很多其他的解答，大家有兴趣可以自己去看看。</p>
          ]]>
          </description>

        </item>
      
    
      
        <item>
          <title>关于字符编码</title>
          <link>https://cjting.me/2014/04/24/about-string-encoding/</link>
          <pubDate>Thu, 24 Apr 2014 00:00:00 +0800</pubDate>
          

          <guid>https://cjting.me/2014/04/24/about-string-encoding/</guid>

          <description><![CDATA[
            
            <img src="http://asset.cjting.cn/9b85365dgw1f7bo2l69u3j21jk111gui.jpg" class="webfeedsFeaturedVisual">

            <p>很早之前就碰到过&rdquo;乱码&rdquo;这个现象，当时非常困惑，完全不能理解发生了什么。</p>

<p>上大学以后，虽然开始接触计算机，不过我就没看到过具体讲解字符编码的内容。对这个领域始终是感到非常模糊。</p>

<p>不过，最近好像豁然开朗了一下，感觉突然就明白了这个问题。</p>

<p>下面我来解释一下我所理解的字符编码。</p>

<p>首先，所有的字符（或者说所有的信息）都是以二进制的形式存储在计算机中。所谓的编码就是 <strong>映射字符与相应的二进制之间的规则</strong>。这样的映射可以任意定义，只要大家都遵守就行了。</p>

<p>比如非常经典的 ASCII 码，就将英文中的字符映射为一个字节。比如，<code>A</code> 这个字符编码为 65，存储在计算机中为 <code>01000001</code>，占据一个字节。</p>

<p>其他的所有字符编码都是同理，比如汉字的经典编码 GBK。</p>

<p>以 丁 这个汉字为例，GBK 编码为 <code>0xB6A1</code>，存储为二进制是 <code>10110110 10100001</code>（直接将 B6A1 换成二进制），两个字节。</p>

<p>用工具查看内部字节可以看出，如图：</p>

<p><img src="http://asset.cjting.cn/9b85365djw1f23cmmpfu1j20ex01qaa9.jpg" alt="" /></p>

<p>同样的道理，如果使用 utf-8 编码，丁在 Unicode 字符集中的编号为 <code>0x4E01</code>，但它存储在计算机中并不是简单的将 <code>0x4E01</code> 翻译为对应的二进制。</p>

<p>这里就要分清楚两个概念，字符集和字符编码。字符集是定义字符的，每一个字符在字符集中都有一个唯一的编号，Unicode 就是一个字符集，丁这个字符在 Unicode 字符集的编号是 0x4E01。</p>

<p>字符编码是指将字符编号变换成二进制的方法。一个字符编号，有很多种方式可以存储在计算机中。例如，我想存储编号 10，我可以存储为二进制的 20，每次在计算机中取得数字后除以二就得到了我的编号。至于为什么不直接存储编号，大多是出于兼容性和方便解码的考虑。</p>

<p>理解了这两个概念的不同，就能明白 utf-8，utf-16 的区别，他们都指的是 Unicode 字符集，但是代表的是不同的编码方法，同样的一个 Unicode 字符，经 utf-8 编码产生的二进制和 utf-16 编码产生的是不一样的。</p>

<p>utf-8 的编码机制不算很复杂，<a href="https://zh.wikipedia.org/wiki/UTF-8">wiki</a> 里说的很清楚，这里就不在赘述了。</p>

<p>现在来说说为什么要有乱码。</p>

<p>当计算机打开一个文本文件的时候，他必须要知道这个是什么编码的。否则无法解码，因为在计算机眼中，一切都是二进制字节（我想起了 CSAPP 中的一句话：*Information Is Bits + Context*）。但是不同的编码下相同的字节有不同的含义。同样是 0xABCD，在某一个编码下可能表示“丁“，在另一个编码下可能表示的就是“王”了。</p>

<p>打开文本文件的时候，如果不手动指定编码，大部分程序都会自动推测编码（怎么推测是另外一个话题了）。如果计算机推测的编码或者用户手动指定的编码和实际编码不符，那么自然就会出现“乱码”现象，也就是内容看上去乱七八糟，实际上在计算机看来，只是用特定的编码方式解码字符而已，只不过解码出来的字符不是你想要的。</p>
          ]]>
          </description>

        </item>
      
    
  </channel>
</rss>
